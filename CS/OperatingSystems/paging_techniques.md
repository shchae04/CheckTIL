# 페이징 기법 (Paging Techniques)

페이징은 운영체제에서 가상 메모리를 관리하는 중요한 메모리 관리 기법입니다. 이 문서에서는 다양한 페이징 기법과 그 특징에 대해 설명합니다.

## 1. 기본 페이징 (Basic Paging)

### 설명
페이징은 물리적 메모리를 고정된 크기의 블록(프레임)으로 나누고, 프로세스의 가상 주소 공간도 같은 크기의 블록(페이지)으로 나누어 관리하는 기법입니다. 각 페이지는 물리적 메모리의 어느 프레임에나 위치할 수 있으며, 이를 추적하기 위해 페이지 테이블을 사용합니다.

### 주요 개념
- **페이지(Page)**: 가상 메모리를 일정한 크기로 나눈 블록
- **프레임(Frame)**: 물리적 메모리를 일정한 크기로 나눈 블록
- **페이지 테이블(Page Table)**: 가상 페이지와 물리적 프레임 간의 매핑 정보를 저장하는 자료구조

### 주소 변환 과정
1. CPU가 가상 주소를 생성
2. 가상 주소를 페이지 번호와 오프셋으로 분리
3. 페이지 테이블을 통해 페이지 번호에 해당하는 프레임 번호 조회
4. 프레임 번호와 오프셋을 결합하여 물리적 주소 생성

#### 예시 (16비트 시스템)
```
페이지 크기: 4KB (2^12 바이트)
가상 주소 공간: 64KB (2^16 바이트)
물리적 메모리: 32KB (2^15 바이트)

가상 주소 0x3A4C의 경우:
- 페이지 번호: 0x3A (상위 8비트, 페이지 크기가 4KB이므로 하위 12비트는 오프셋)
- 오프셋: 0x4C (하위 12비트)

페이지 테이블 내용:
페이지 0: 프레임 3
페이지 1: 프레임 7
페이지 2: 디스크에 스왑됨
...
페이지 58 (0x3A): 프레임 5
...

1. 가상 주소 0x3A4C에서 페이지 번호 0x3A 추출
2. 페이지 테이블에서 페이지 0x3A가 프레임 5에 매핑됨을 확인
3. 프레임 번호(5)와 오프셋(0x4C)을 결합: 물리적 주소 = 5 * 4KB + 0x4C = 0x504C
```

### 특징
- 외부 단편화(External Fragmentation) 문제 해결
- 내부 단편화(Internal Fragmentation) 발생 가능
- 메모리 할당이 간단하고 효율적

## 2. 다단계 페이징 (Multi-level Paging)

### 설명
기본 페이징의 문제점 중 하나는 페이지 테이블이 매우 클 수 있다는 것입니다. 다단계 페이징은 페이지 테이블을 여러 레벨로 나누어 메모리 사용을 최적화합니다.

### 구조
```
가상 주소 = [1단계 페이지 번호][2단계 페이지 번호]...[n단계 페이지 번호][오프셋]
```

#### 예시 (32비트 시스템의 2단계 페이징)
```
32비트 가상 주소 = [10비트: 1단계 페이지 번호][10비트: 2단계 페이지 번호][12비트: 오프셋]

가상 주소 0x3F5D2C1B의 경우:
- 1단계 페이지 번호: 0x3F5 (상위 10비트)
- 2단계 페이지 번호: 0x14B (중간 10비트)
- 오프셋: 0xC1B (하위 12비트)

1. 0x3F5를 사용하여 1단계 페이지 테이블에서 2단계 페이지 테이블의 주소를 찾음
2. 0x14B를 사용하여 2단계 페이지 테이블에서 프레임 번호를 찾음
3. 프레임 번호와 오프셋 0xC1B를 결합하여 물리적 주소 생성
```

### 주소 변환 과정
1. 가상 주소에서 1단계 페이지 번호 추출
2. 1단계 페이지 테이블에서 2단계 페이지 테이블의 주소 조회
3. 2단계 페이지 번호를 사용하여 2단계 페이지 테이블에서 다음 레벨 조회
4. 마지막 레벨에서 실제 프레임 번호 조회
5. 프레임 번호와 오프셋을 결합하여 물리적 주소 생성

### 특징
- 실제로 사용되는 페이지 테이블만 메모리에 유지
- 주소 변환 시간 증가 (여러 메모리 접근 필요)
- 대용량 가상 메모리 지원에 효과적

## 3. 역페이징 (Inverted Page Table)

### 설명
역페이징은 기존 페이징 방식과 달리 물리적 메모리의 각 프레임에 대해 어떤 프로세스의 어떤 페이지가 저장되어 있는지를 기록하는 방식입니다.

### 구조
- 시스템에 하나의 페이지 테이블만 존재
- 각 항목은 (프로세스 ID, 페이지 번호) 쌍으로 구성
- 테이블 인덱스가 프레임 번호를 나타냄

### 주소 변환 과정
1. 프로세스 ID와 가상 페이지 번호로 역페이지 테이블 검색
2. 일치하는 항목을 찾으면 해당 인덱스가 프레임 번호
3. 프레임 번호와 오프셋을 결합하여 물리적 주소 생성

#### 예시
```
시스템 상태:
- 물리적 메모리: 8개의 프레임 (프레임 크기: 4KB)
- 실행 중인 프로세스: P1, P2, P3

역페이지 테이블:
프레임 0: (P1, 페이지 5)
프레임 1: (P3, 페이지 2)
프레임 2: (P2, 페이지 8)
프레임 3: (P1, 페이지 10)
프레임 4: (P2, 페이지 4)
프레임 5: (P3, 페이지 7)
프레임 6: (P1, 페이지 3)
프레임 7: (P2, 페이지 1)

프로세스 P2의 가상 주소 0x8123 (페이지 8, 오프셋 0x123)에 접근하는 경우:
1. (P2, 페이지 8)을 역페이지 테이블에서 검색
2. 프레임 2에서 일치하는 항목 발견
3. 물리적 주소 = 프레임 2의 시작 주소 + 오프셋 = 0x2000 + 0x123 = 0x2123
```

### 특징
- 메모리 사용량 감소 (프로세스별 페이지 테이블 불필요)
- 주소 변환 시간 증가 (테이블 전체 검색 필요)
- 해시 테이블 등을 사용하여 검색 속도 개선 가능

## 4. 페이지 교체 알고리즘 (Page Replacement Algorithms)

페이지 폴트(Page Fault)가 발생했을 때 어떤 페이지를 교체할지 결정하는 알고리즘입니다.

### FIFO (First-In-First-Out)
가장 오래된 페이지를 교체하는 방식입니다.

#### 예시
```
물리적 메모리: 3개의 프레임
페이지 참조 순서: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5

초기 상태: 모든 프레임이 비어 있음

1 참조: [1, -, -] (페이지 1을 프레임 0에 로드)
2 참조: [1, 2, -] (페이지 2를 프레임 1에 로드)
3 참조: [1, 2, 3] (페이지 3을 프레임 2에 로드)
4 참조: [4, 2, 3] (페이지 4가 페이지 1을 교체 - 1이 가장 오래됨)
1 참조: [4, 1, 3] (페이지 1이 페이지 2를 교체 - 2가 가장 오래됨)
2 참조: [4, 1, 2] (페이지 2가 페이지 3을 교체 - 3이 가장 오래됨)
5 참조: [5, 1, 2] (페이지 5가 페이지 4를 교체 - 4가 가장 오래됨)
...

페이지 폴트 발생 횟수: 9회
```

#### 특징
- 구현이 간단
- 성능이 좋지 않을 수 있음 (Belady의 모순 발생 가능)
- 페이지의 중요도를 고려하지 않음

### LRU (Least Recently Used)
가장 오랫동안 사용되지 않은 페이지를 교체하는 방식입니다.

#### 예시
```
물리적 메모리: 3개의 프레임
페이지 참조 순서: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5

초기 상태: 모든 프레임이 비어 있음

1 참조: [1, -, -] (페이지 1을 프레임 0에 로드)
2 참조: [1, 2, -] (페이지 2를 프레임 1에 로드)
3 참조: [1, 2, 3] (페이지 3을 프레임 2에 로드)
4 참조: [4, 2, 3] (페이지 4가 페이지 1을 교체 - 1이 가장 오래 사용되지 않음)
1 참조: [4, 1, 3] (페이지 1이 페이지 2를 교체 - 2가 가장 오래 사용되지 않음)
2 참조: [4, 1, 2] (페이지 2가 페이지 3을 교체 - 3이 가장 오래 사용되지 않음)
5 참조: [5, 1, 2] (페이지 5가 페이지 4를 교체 - 4가 가장 오래 사용되지 않음)
1 참조: [5, 1, 2] (페이지 1이 이미 메모리에 있음 - 페이지 폴트 없음)
2 참조: [5, 1, 2] (페이지 2가 이미 메모리에 있음 - 페이지 폴트 없음)
3 참조: [3, 1, 2] (페이지 3이 페이지 5를 교체 - 5가 가장 오래 사용되지 않음)

페이지 폴트 발생 횟수: 8회 (FIFO보다 적음)
```

#### 특징
- 시간 지역성(Temporal Locality)을 활용
- 구현이 복잡하고 오버헤드가 큼
- 좋은 성능을 보이는 경우가 많음

### LFU (Least Frequently Used)
사용 빈도가 가장 낮은 페이지를 교체하는 방식입니다.

#### 예시
```
물리적 메모리: 3개의 프레임
페이지 참조 순서: 1, 2, 1, 3, 1, 4, 5, 1, 2, 3, 4, 5

초기 상태: 모든 프레임이 비어 있음, 모든 페이지의 참조 횟수는 0

1 참조: [1(1), -, -] (페이지 1을 로드, 참조 횟수 1)
2 참조: [1(1), 2(1), -] (페이지 2를 로드, 참조 횟수 1)
1 참조: [1(2), 2(1), -] (페이지 1의 참조 횟수 증가)
3 참조: [1(2), 2(1), 3(1)] (페이지 3을 로드, 참조 횟수 1)
1 참조: [1(3), 2(1), 3(1)] (페이지 1의 참조 횟수 증가)
4 참조: [1(3), 4(1), 3(1)] (페이지 4가 페이지 2를 교체 - 2와 3의 참조 횟수가 같지만 2가 먼저 로드됨)
5 참조: [1(3), 4(1), 5(1)] (페이지 5가 페이지 3을 교체 - 3과 4의 참조 횟수가 같지만 3이 먼저 로드됨)
1 참조: [1(4), 4(1), 5(1)] (페이지 1의 참조 횟수 증가)
2 참조: [1(4), 2(1), 5(1)] (페이지 2가 페이지 4를 교체 - 4와 5의 참조 횟수가 같지만 4가 먼저 로드됨)

페이지 폴트 발생 횟수: 7회
```

#### 특징
- 사용 빈도를 카운터로 관리
- 최근에 로드된 페이지가 교체될 가능성이 높음
- 카운터 오버플로우 문제 발생 가능

### Clock (Second Chance)
FIFO의 변형으로, 각 페이지에 참조 비트를 두어 최근에 참조된 페이지에 두 번째 기회를 주는 방식입니다.

#### 예시
```
물리적 메모리: 3개의 프레임
페이지 참조 순서: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5
시계 포인터: 초기에 첫 번째 프레임을 가리킴

초기 상태: 모든 프레임이 비어 있음, 모든 참조 비트는 0

1 참조: [1(1), -, -] (페이지 1을 로드, 참조 비트 1)
2 참조: [1(1), 2(1), -] (페이지 2를 로드, 참조 비트 1)
3 참조: [1(1), 2(1), 3(1)] (페이지 3을 로드, 참조 비트 1)
4 참조: 시계 포인터가 페이지 1을 가리킴
        - 페이지 1의 참조 비트가 1이므로 0으로 변경하고 다음으로 이동
        - 페이지 2의 참조 비트가 1이므로 0으로 변경하고 다음으로 이동
        - 페이지 3의 참조 비트가 1이므로 0으로 변경하고 다음으로 이동
        - 다시 페이지 1로 돌아와서 참조 비트가 0이므로 교체
        [4(1), 2(0), 3(0)] (페이지 4가 페이지 1을 교체, 참조 비트 1)
1 참조: 시계 포인터가 페이지 2를 가리킴
        - 페이지 2의 참조 비트가 0이므로 교체
        [4(1), 1(1), 3(0)] (페이지 1이 페이지 2를 교체, 참조 비트 1)

페이지 폴트 발생 횟수: 5회 (첫 3개 + 4 + 1)
```

#### 특징
- 구현이 비교적 간단
- LRU에 근접한 성능
- 하드웨어 지원 필요 (참조 비트)

### 최적 페이지 교체 (Optimal Page Replacement)
앞으로 가장 오랫동안 사용되지 않을 페이지를 교체하는 이론적인 알고리즘입니다.

#### 예시
```
물리적 메모리: 3개의 프레임
페이지 참조 순서: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5

초기 상태: 모든 프레임이 비어 있음

1 참조: [1, -, -] (페이지 1을 로드)
2 참조: [1, 2, -] (페이지 2를 로드)
3 참조: [1, 2, 3] (페이지 3을 로드)
4 참조: 앞으로의 참조 순서: 1, 2, 5, 1, 2, 3, 4, 5
        - 페이지 1은 곧 참조됨
        - 페이지 2는 곧 참조됨
        - 페이지 3은 나중에 참조됨
        [1, 2, 4] (페이지 4가 페이지 3을 교체 - 3이 가장 나중에 참조됨)
1 참조: [1, 2, 4] (페이지 1이 이미 메모리에 있음 - 페이지 폴트 없음)
2 참조: [1, 2, 4] (페이지 2가 이미 메모리에 있음 - 페이지 폴트 없음)
5 참조: 앞으로의 참조 순서: 1, 2, 3, 4, 5
        - 페이지 1은 곧 참조됨
        - 페이지 2는 곧 참조됨
        - 페이지 4는 나중에 참조됨
        [1, 2, 5] (페이지 5가 페이지 4를 교체 - 4가 가장 나중에 참조됨)

페이지 폴트 발생 횟수: 5회 (다른 알고리즘보다 적음)
```

#### 특징
- 이론적으로 최적의 성능
- 미래 참조 정보를 알아야 하므로 실제 구현 불가능
- 다른 알고리즘의 성능 평가 기준으로 사용

## 5. 페이지 버퍼링 기법 (Page Buffering Techniques)

### 설명
페이지 교체 시 성능을 향상시키기 위한 추가적인 기법들입니다.

### 프리 프레임 버퍼링 (Free Frame Buffering)
미리 비어있는 프레임 목록을 유지하여 페이지 폴트 발생 시 즉시 할당할 수 있게 합니다.

#### 예시
```
시스템 상태:
- 물리적 메모리: 총 100개의 프레임
- 현재 프로세스들이 사용 중인 프레임: 85개
- 프리 프레임 풀: 10개의 프레임 (86-95)
- 나머지 5개 프레임: 운영체제 예약

페이지 폴트 발생 시:
1. 프리 프레임 풀에서 프레임 86을 즉시 할당
2. 페이지 교체 알고리즘을 통해 교체할 페이지 결정 (예: 페이지 X)
3. 페이지 X를 디스크에 기록 (필요한 경우)
4. 프레임 풀에 새로운 프레임 추가 (X가 있던 프레임)

이 방식으로 페이지 폴트 처리 시간을 단축:
- 기존 방식: 교체 페이지 선택 → 디스크 기록 → 새 페이지 로드
- 버퍼링 방식: 즉시 새 프레임 할당 → 백그라운드에서 교체 작업 수행
```

### 수정 비트 활용 (Modified Bit Utilization)
페이지가 수정되었는지를 나타내는 비트를 활용하여, 수정되지 않은 페이지를 우선적으로 교체합니다.

#### 예시
```
물리적 메모리의 페이지 상태:
페이지 1: 수정됨 (dirty bit = 1)
페이지 2: 수정되지 않음 (dirty bit = 0)
페이지 3: 수정됨 (dirty bit = 1)
페이지 4: 수정되지 않음 (dirty bit = 0)

페이지 교체 필요 시:
1. 수정되지 않은 페이지(2, 4) 중에서 선택
   - 이유: 수정되지 않은 페이지는 디스크에 기록할 필요가 없어 교체 비용이 적음
2. 수정되지 않은 페이지가 없다면, 수정된 페이지(1, 3) 중에서 선택

이 방식으로 디스크 I/O 감소:
- 수정되지 않은 페이지: 디스크 읽기만 필요
- 수정된 페이지: 디스크 읽기 + 쓰기 필요
```

### 페이지 풀링 (Page Pooling)
자주 사용되는 페이지들을 별도의 풀에 유지하여 빠르게 접근할 수 있게 합니다.

#### 예시
```
시스템 상태:
- 일반 페이지 풀: 대부분의 페이지 저장
- 자주 사용되는 페이지 풀: 최근에 자주 접근된 페이지 저장

페이지 접근 시:
1. 자주 사용되는 페이지 풀에서 먼저 검색
2. 발견되면 즉시 접근 (빠른 접근 시간)
3. 발견되지 않으면 일반 풀에서 검색
4. 일반 풀에서 자주 접근되는 페이지는 자주 사용되는 페이지 풀로 이동

이 방식으로 자주 사용되는 페이지에 대한 접근 시간 단축
```

## 6. 세그먼테이션과의 결합 (Segmentation with Paging)

### 설명
세그먼테이션과 페이징을 결합하여 각각의 장점을 활용하는 기법입니다.

### 구조
- 프로세스의 주소 공간을 논리적 단위(세그먼트)로 분할
- 각 세그먼트를 다시 페이지로 분할
- 세그먼트 테이블과 페이지 테이블을 모두 사용

#### 예시
```
프로세스 구조:
- 코드 세그먼트: 64KB
- 데이터 세그먼트: 128KB
- 스택 세그먼트: 32KB
페이지 크기: 4KB

세그먼트 테이블:
세그먼트 0 (코드): 기준 주소 = 페이지 테이블 0의 주소, 크기 = 64KB
세그먼트 1 (데이터): 기준 주소 = 페이지 테이블 1의 주소, 크기 = 128KB
세그먼트 2 (스택): 기준 주소 = 페이지 테이블 2의 주소, 크기 = 32KB

페이지 테이블 0 (코드 세그먼트):
페이지 0 → 프레임 10
페이지 1 → 프레임 15
...
페이지 15 → 프레임 30

페이지 테이블 1 (데이터 세그먼트):
페이지 0 → 프레임 45
페이지 1 → 프레임 33
...
페이지 31 → 프레임 62

페이지 테이블 2 (스택 세그먼트):
페이지 0 → 프레임 77
페이지 1 → 프레임 90
...
페이지 7 → 프레임 88

가상 주소 변환 과정 (예: 데이터 세그먼트의 주소 0x1A5C):
1. 세그먼트 번호 추출: 1 (데이터 세그먼트)
2. 세그먼트 내 오프셋 계산: 0xA5C
3. 페이지 번호 계산: 0xA5C / 4KB = 2 (오프셋: 0x5C)
4. 세그먼트 테이블에서 페이지 테이블 1의 주소 찾기
5. 페이지 테이블 1에서 페이지 2의 프레임 번호 찾기: 프레임 50
6. 최종 물리적 주소: (프레임 50 * 4KB) + 0x5C = 0x3205C
```

### 특징
- 논리적 분할과 효율적인 메모리 관리를 동시에 제공
- 복잡한 주소 변환 과정
- 현대 운영체제에서 널리 사용됨

## 페이징 기법 비교

| 기법 | 장점 | 단점 | 적용 사례 |
|------|------|------|-----------|
| 기본 페이징 | 구현 간단, 외부 단편화 없음 | 내부 단편화 발생, 큰 페이지 테이블 | 초기 가상 메모리 시스템 |
| 다단계 페이징 | 페이지 테이블 크기 감소, 메모리 효율성 | 주소 변환 복잡, 접근 시간 증가 | 대부분의 현대 OS (Windows, Linux) |
| 역페이징 | 시스템 전체 메모리 사용량 감소 | 검색 시간 증가, 공유 페이지 처리 복잡 | IBM의 일부 시스템 |
| TLB 활용 | 주소 변환 속도 향상 | 하드웨어 비용 증가 | 모든 현대 프로세서 |

## 결론

페이징은 현대 운영체제의 메모리 관리에 필수적인 기술입니다. 
다양한 페이징 기법들은 각각 고유한 장단점을 가지고 있으며, 실제 시스템에서는 이러한 기법들을 조합하여 최적의 성능을 달성합니다. 
메모리 관리 요구사항, 하드웨어 지원, 워크로드 특성 등을 고려하여 적절한 페이징 기법을 선택하는 것이 중요합니다.
