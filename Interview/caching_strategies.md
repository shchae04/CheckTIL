# 캐싱 전략

캐싱은 자주 사용되는 데이터를 빠르게 접근할 수 있는 임시 저장소에 보관하여 시스템의 성능을 향상시키는 기술입니다. 적절한 캐싱 전략을 선택하고 구현하는 것은 애플리케이션의 성능, 확장성 및 사용자 경험에 큰 영향을 미칩니다.

## 1. 캐싱의 기본 원리

캐싱은 다음과 같은 기본 원리를 바탕으로 작동합니다:

1. **시간적 지역성(Temporal Locality)**: 최근에 접근한 데이터는 가까운 미래에 다시 접근할 가능성이 높습니다.
2. **공간적 지역성(Spatial Locality)**: 특정 데이터 주변의 데이터도 곧 접근할 가능성이 높습니다.
3. **빈도(Frequency)**: 자주 접근하는 데이터는 캐시에 저장하는 것이 유리합니다.

## 2. 주요 캐싱 전략

### 2.1 캐시 배치 전략(Cache Placement Strategies)

#### 2.1.1 Look-Aside 캐시(읽기 중심)

```
클라이언트 -> 캐시 확인 -> 캐시 히트 -> 데이터 반환
                  |
                  v
             캐시 미스 -> 데이터베이스 조회 -> 캐시 업데이트 -> 데이터 반환
```

- **특징**: 클라이언트가 먼저 캐시를 확인하고, 캐시 미스 시 데이터베이스에서 조회합니다.
- **장점**: 구현이 간단하고, 캐시 장애 시 데이터베이스로 폴백(fallback)이 가능합니다.
- **단점**: 캐시 미스 시 지연 시간이 증가합니다.
- **사용 사례**: Redis, Memcached를 사용한 읽기 중심 애플리케이션

#### 2.1.2 Write-Through 캐시(쓰기 중심)

```
클라이언트 -> 데이터베이스 쓰기 -> 캐시 업데이트
                  |
                  v
             클라이언트에 응답
```

- **특징**: 데이터베이스에 쓰기 작업 후 즉시 캐시를 업데이트합니다.
- **장점**: 캐시와 데이터베이스의 일관성을 유지하기 쉽습니다.
- **단점**: 쓰기 작업이 두 번 발생하여 지연 시간이 증가할 수 있습니다.
- **사용 사례**: 데이터 일관성이 중요한 금융 시스템

#### 2.1.3 Write-Behind/Write-Back 캐시

```
클라이언트 -> 캐시 쓰기 -> 클라이언트에 응답
                 |
                 v
            비동기적으로 데이터베이스에 쓰기
```

- **특징**: 캐시에 먼저 쓰고 나중에 비동기적으로 데이터베이스에 기록합니다.
- **장점**: 쓰기 작업의 지연 시간이 감소하고, 데이터베이스 부하를 분산시킬 수 있습니다.
- **단점**: 캐시 장애 시 데이터 손실 가능성이 있습니다.
- **사용 사례**: 로그 데이터, 분석 데이터 처리

#### 2.1.4 Refresh-Ahead 캐시

```
캐시 -> 만료 시간 접근 -> 백그라운드에서 데이터 미리 갱신
```

- **특징**: 캐시 항목이 만료되기 전에 미리 갱신합니다.
- **장점**: 캐시 미스를 줄이고 일관된 성능을 제공합니다.
- **단점**: 예측이 부정확할 경우 불필요한 리소스를 소비할 수 있습니다.
- **사용 사례**: 예측 가능한 접근 패턴을 가진 데이터(일일 보고서, 정기 통계 등)

### 2.2 캐시 교체 정책(Cache Eviction Policies)

#### 2.2.1 LRU(Least Recently Used)

- **원리**: 가장 오랫동안 사용되지 않은 항목을 먼저 제거합니다.
- **장점**: 시간적 지역성을 활용하여 효율적입니다.
- **단점**: 최근에 한 번만 사용된 항목이 자주 사용되는 항목보다 우선순위가 높을 수 있습니다.

#### 2.2.2 LFU(Least Frequently Used)

- **원리**: 사용 빈도가 가장 낮은 항목을 먼저 제거합니다.
- **장점**: 인기 있는 항목을 효과적으로 캐시에 유지합니다.
- **단점**: 과거에 인기 있었지만 현재는 사용되지 않는 항목이 캐시에 남을 수 있습니다.

#### 2.2.3 FIFO(First In First Out)

- **원리**: 가장 먼저 캐시에 들어온 항목을 먼저 제거합니다.
- **장점**: 구현이 간단합니다.
- **단점**: 사용 패턴을 고려하지 않아 효율성이 떨어질 수 있습니다.

#### 2.2.4 TTL(Time To Live)

- **원리**: 각 항목에 만료 시간을 설정하고, 만료된 항목을 제거합니다.
- **장점**: 데이터의 신선도를 보장합니다.
- **단점**: 여전히 유용한 데이터가 만료될 수 있습니다.

## 3. 다중 레벨 캐싱(Multi-Level Caching)

현대 시스템에서는 여러 레벨의 캐시를 사용하여 성능을 최적화합니다:

1. **L1 캐시**: CPU 내부에 위치한 가장 빠른 캐시
2. **L2, L3 캐시**: CPU와 메인 메모리 사이의 중간 캐시
3. **애플리케이션 캐시**: 애플리케이션 내부에 구현된 캐시(예: Spring Cache)
4. **분산 캐시**: 여러 서버에 걸쳐 공유되는 캐시(예: Redis, Memcached)
5. **CDN(Content Delivery Network)**: 정적 콘텐츠를 위한 글로벌 캐시 네트워크

## 4. 캐싱 관련 문제와 해결책

### 4.1 캐시 일관성(Cache Coherence)

여러 캐시 간에 동일한 데이터의 일관성을 유지하는 문제입니다.

**해결책**:
- **캐시 무효화(Cache Invalidation)**: 데이터가 변경되면 관련 캐시 항목을 무효화합니다.
- **버전 관리(Versioning)**: 데이터에 버전 번호를 부여하여 최신 버전을 추적합니다.
- **TTL 설정**: 적절한 TTL을 설정하여 오래된 데이터가 자동으로 만료되도록 합니다.

### 4.2 캐시 폭발(Cache Stampede)

많은 요청이 동시에 캐시 미스를 경험하여 데이터베이스에 과부하가 발생하는 현상입니다.

**해결책**:
- **캐시 워밍(Cache Warming)**: 시스템 시작 시 미리 캐시를 채웁니다.
- **세마포어 잠금(Semaphore Locking)**: 첫 번째 요청만 데이터베이스에 접근하고 나머지는 대기합니다.
- **확률적 조기 갱신(Probabilistic Early Recomputation)**: 만료 시간 전에 확률적으로 캐시를 갱신합니다.

### 4.3 캐시 관통(Cache Penetration)

존재하지 않는 키에 대한 반복적인 요청으로 캐시를 우회하여 데이터베이스에 부하를 주는 현상입니다.

**해결책**:
- **Null 결과 캐싱**: 존재하지 않는 키에 대해서도 null 값을 캐시합니다.
- **블룸 필터(Bloom Filter)**: 키의 존재 여부를 빠르게 확인할 수 있는 확률적 자료구조를 사용합니다.

## 5. 주요 캐싱 기술 및 도구

### 5.1 인메모리 캐시

- **Redis**: 다양한 데이터 구조를 지원하는 인메모리 데이터 스토어
- **Memcached**: 단순하고 빠른 키-값 저장소
- **Caffeine**: 자바 기반의 고성능 인메모리 캐시 라이브러리
- **Ehcache**: 자바 기반의 널리 사용되는 캐시 라이브러리

### 5.2 웹 캐싱

- **브라우저 캐시**: 웹 브라우저에 저장되는 로컬 캐시
- **HTTP 캐시 헤더**: Cache-Control, ETag, Last-Modified 등
- **CDN(Content Delivery Network)**: Cloudflare, Akamai, AWS CloudFront 등

### 5.3 데이터베이스 캐싱

- **쿼리 캐시**: 데이터베이스 엔진 내부의 쿼리 결과 캐시
- **버퍼 풀(Buffer Pool)**: 데이터베이스 페이지를 메모리에 캐싱
- **ORM 캐시**: Hibernate의 1차, 2차 캐시 등

## 6. 캐싱 전략 선택 가이드

적절한 캐싱 전략을 선택하기 위한 고려사항:

1. **데이터 접근 패턴**: 읽기 중심인지, 쓰기 중심인지에 따라 전략이 달라집니다.
2. **데이터 변경 빈도**: 자주 변경되는 데이터는 TTL을 짧게 설정하거나 무효화 메커니즘이 필요합니다.
3. **일관성 요구사항**: 강한 일관성이 필요한 경우 Write-Through나 즉시 무효화 전략이 적합합니다.
4. **시스템 리소스**: 사용 가능한 메모리, CPU, 네트워크 대역폭에 따라 캐시 크기와 전략을 조정합니다.
5. **장애 허용성**: 캐시 장애 시 시스템 동작 방식을 고려합니다.

## 결론

캐싱은 시스템 성능을 크게 향상시킬 수 있는 강력한 기술이지만, 적절한 전략 선택과 구현이 중요합니다. 애플리케이션의 특성과 요구사항을 고려하여 최적의 캐싱 전략을 선택하고, 캐시 일관성, 폭발, 관통과 같은 잠재적 문제에 대한 해결책을 마련해야 합니다. 효과적인 캐싱 전략은 사용자 경험을 개선하고 시스템 리소스를 효율적으로 활용하는 데 큰 도움이 됩니다.