# CS 관련

## 1. 운영체제
- **프로세스(Process)와 스레드(Thread)**

  **프로세스(Process)란?**
  - 운영체제로부터 **독립적인 실행 환경**을 제공받는 실행 단위
  - OS가 할당하는 자원들:
    - **독립적인 메모리 공간**: 코드, 데이터, 힙, 스택 영역을 각각 할당
    - **CPU 시간**: 스케줄러에 의한 CPU 시간 할당
    - **파일 디스크립터**: 파일, 소켓 등 I/O 자원에 대한 핸들
    - **프로세스 ID(PID)**: 시스템 내 고유 식별자
    - **환경 변수**: 프로세스별 독립적인 환경 설정

  **스레드(Thread)란?**
  - 프로세스 내에서 실행되는 **경량 실행 단위(Light Weight Process)**
  - 같은 프로세스 내 스레드들이 공유하는 자원:
    - **메모리 공간**: 코드, 데이터, 힙 영역 공유
    - **파일 디스크립터**: 열린 파일, 소켓 등 공유
    - **환경 변수**: 프로세스의 환경 변수 공유
  - 스레드별 독립적 자원:
    - **스택**: 각 스레드마다 독립적인 스택 공간
    - **레지스터**: CPU 레지스터 상태
    - **프로그램 카운터(PC)**: 현재 실행 중인 명령어 위치

  **핵심 차이점 심화 분석**

  **1. 자원 할당 및 독립성**
  - **프로세스**: OS로부터 완전히 독립적인 메모리 공간과 자원을 할당받음
    - 각 프로세스는 가상 메모리 공간을 통해 물리 메모리에 매핑
    - 프로세스 간 메모리 접근 불가 (메모리 보호 기능)
    - 한 프로세스의 오류가 다른 프로세스에 영향을 주지 않음 (격리성)
  - **스레드**: 같은 프로세스 내에서 CPU 시간만을 독립적으로 할당받음
    - 프로세스의 메모리 공간을 공유하므로 다른 스레드의 메모리에 직접 접근 가능
    - 한 스레드의 오류(예: Segmentation Fault)가 전체 프로세스에 영향
    - 메모리 공유로 인한 데이터 일관성 문제 발생 가능

  **2. 통신 방식의 차이**
  - **프로세스 간 통신(IPC: Inter-Process Communication)**
    - **파이프(Pipe)**: 단방향 통신, 부모-자식 프로세스 간
    - **명명된 파이프(Named Pipe/FIFO)**: 관련 없는 프로세스 간 통신
    - **메시지 큐(Message Queue)**: 구조화된 메시지 전달
    - **공유 메모리(Shared Memory)**: 가장 빠른 IPC, 동기화 필요
    - **세마포어(Semaphore)**: 동기화 및 상호 배제
    - **소켓(Socket)**: 네트워크를 통한 프로세스 간 통신
  - **스레드 간 통신**
    - **공유 메모리**: 힙 영역의 변수를 직접 공유
    - **동기화 메커니즘**: 뮤텍스(Mutex), 세마포어, 조건 변수(Condition Variable)
    - **스레드 로컬 스토리지**: 스레드별 독립적 데이터 저장

  **3. 컨텍스트 스위칭 오버헤드**
  - **프로세스 컨텍스트 스위칭**
    - **무거운 작업**: 메모리 관리 단위(MMU) 설정 변경 필요
    - **TLB(Translation Lookaside Buffer) 플러시**: 가상-물리 주소 매핑 캐시 초기화
    - **캐시 미스 증가**: 새 프로세스의 데이터가 캐시에 없어 메모리 접근 증가
    - **페이지 테이블 교체**: 가상 메모리 매핑 정보 전환
    - **시간 복잡도**: 마이크로초(μs) 단위의 오버헤드
  - **스레드 컨텍스트 스위칭**
    - **가벼운 작업**: 레지스터와 스택 포인터만 교체
    - **메모리 공간 유지**: 동일 프로세스 내이므로 메모리 매핑 변경 불필요
    - **캐시 효율성**: 공유 데이터로 인한 캐시 히트율 향상
    - **시간 복잡도**: 나노초(ns) 단위의 오버헤드

  **4. 생성 및 소멸 비용**
  - **프로세스**: fork() 시스템 콜로 생성, 메모리 복사 또는 COW(Copy-On-Write) 적용
  - **스레드**: pthread_create() 등으로 생성, 스택 공간만 할당하므로 빠름

  **5. 확장성 및 성능**
  - **프로세스**: 멀티 코어 활용 우수, 안정성 높음, 메모리 사용량 많음
  - **스레드**: 동시성 처리 우수, 자원 효율적, 동기화 복잡성 증가

- **뮤텍스(Mutex)와 세마포어(Semaphore)**

  **뮤텍스(Mutex: Mutual Exclusion)란?**
  - **정의**: 상호 배제를 위한 동기화 프리미티브로, **단일 자원에 대한 배타적 접근**을 보장
  - **핵심 특징**:
    - **소유권(Ownership)**: 락을 획득한 스레드만이 해당 락을 해제할 수 있음
    - **재귀적 락킹**: 동일 스레드가 여러 번 락을 획득할 수 있는 재귀 뮤텍스 존재
    - **우선순위 상속**: 높은 우선순위 스레드가 대기 중일 때, 락을 보유한 낮은 우선순위 스레드의 우선순위를 일시적으로 상승
  - **구현 메커니즘**:
    - **스핀락(Spinlock)**: CPU가 계속 폴링하며 대기 (짧은 대기 시간에 효율적)
    - **슬립락(Sleep Lock)**: 대기 중인 스레드를 블록 상태로 전환 (긴 대기 시간에 효율적)
    - **하이브리드**: 짧은 시간 스핀 후 슬립으로 전환

  **세마포어(Semaphore)란?**
  - **정의**: **카운팅 기반 동기화 메커니즘**으로, 제한된 수의 자원에 대한 동시 접근을 제어
  - **핵심 구성 요소**:
    - **카운터(Counter)**: 사용 가능한 자원의 개수를 나타내는 정수 값
    - **대기 큐(Wait Queue)**: 자원을 기다리는 스레드들의 대기열
  - **연산**:
    - **P 연산(Wait/Down)**: 카운터 감소, 0이면 대기
    - **V 연산(Signal/Up)**: 카운터 증가, 대기 중인 스레드 깨움
  - **유형**:
    - **바이너리 세마포어**: 카운터가 0 또는 1 (뮤텍스와 유사하지만 소유권 없음)
    - **카운팅 세마포어**: 카운터가 N개 자원 수를 나타냄

  **심화 비교 분석**

  **1. 소유권과 책임**
  - **뮤텍스**: 
    - 락을 획득한 스레드만이 해제 가능 (소유권 존재)
    - 데드락 감지 및 복구 메커니즘 구현 가능
    - 스레드 종료 시 자동으로 락 해제 (일부 구현체)
  - **세마포어**: 
    - 어떤 스레드든 시그널 가능 (소유권 없음)
    - 더 유연하지만 잘못된 사용 시 예측 불가능한 동작
    - 스레드 간 시그널링 메커니즘으로도 활용

  **2. 성능 특성**
  - **뮤텍스**:
    - **컨텍스트 스위칭**: 락 경합 시 스레드 블로킹으로 인한 오버헤드
    - **캐시 일관성**: 단일 자원 보호로 캐시 라인 경합 최소화
    - **우선순위 역전 방지**: 우선순위 상속 프로토콜 적용 가능
  - **세마포어**:
    - **스케줄링 오버헤드**: 여러 스레드 동시 깨움으로 인한 스케줄링 복잡성
    - **메모리 사용량**: 대기 큐 관리를 위한 추가 메모리 필요
    - **확장성**: 다중 자원 관리에 효율적

  **3. 사용 사례 및 패턴**
  - **뮤텍스 적용 사례**:
    - **임계 영역 보호**: 공유 데이터 구조 (연결 리스트, 해시 테이블)
    - **싱글톤 패턴**: 인스턴스 생성 시 동기화
    - **파일 I/O**: 동시 쓰기 방지
  - **세마포어 적용 사례**:
    - **리소스 풀 관리**: 데이터베이스 커넥션 풀, 스레드 풀
    - **생산자-소비자 패턴**: 버퍼 크기 제한
    - **동기화 신호**: 스레드 간 작업 완료 알림

  **4. 구현 복잡도 및 디버깅**
  - **뮤텍스**:
    - **데드락 감지**: 소유권 정보를 통한 순환 대기 감지 가능
    - **디버깅 용이성**: 락 소유자 추적으로 문제 지점 식별 용이
    - **타임아웃 지원**: 일정 시간 후 락 획득 포기 가능
  - **세마포어**:
    - **복잡한 상태 관리**: 카운터와 대기 큐 상태 동기화 필요
    - **디버깅 어려움**: 소유권 없어 문제 발생 지점 추적 어려움
    - **잘못된 사용 위험**: P/V 연산 불균형으로 인한 자원 누수 또는 무한 대기

- **시스템 콜(System Call)**

  **시스템 콜이란?**
  - **정의**: 사용자 공간(User Space) 애플리케이션이 **커널 공간(Kernel Space)의 서비스**에 접근하기 위한 **프로그래밍 인터페이스**
  - **핵심 목적**: 하드웨어 자원과 시스템 서비스에 대한 **통제된 접근** 제공
  - **보안 모델**: 사용자 프로그램이 직접 하드웨어에 접근하는 것을 방지하고, 커널을 통한 안전한 접근 보장

  **시스템 콜 실행 메커니즘**

  **1. 권한 레벨 전환 (Privilege Level Transition)**
  - **사용자 모드(User Mode)**: Ring 3, 제한된 권한, 하드웨어 직접 접근 불가
  - **커널 모드(Kernel Mode)**: Ring 0, 모든 하드웨어 자원 접근 가능
  - **모드 전환 과정**:
    1. 사용자 프로그램이 시스템 콜 호출
    2. **소프트웨어 인터럽트(Software Interrupt)** 발생 (x86: INT 0x80, x86_64: SYSCALL)
    3. CPU가 커널 모드로 전환
    4. 커널이 시스템 콜 핸들러 실행
    5. 작업 완료 후 사용자 모드로 복귀

  **2. 시스템 콜 테이블과 디스패칭**
  - **시스템 콜 번호**: 각 시스템 콜마다 고유한 번호 할당
  - **시스템 콜 테이블**: 번호와 해당 커널 함수의 매핑 테이블
  - **매개변수 전달**: 레지스터(빠름) 또는 스택(많은 매개변수)을 통한 전달
  - **반환값**: 성공 시 결과값, 실패 시 음수 에러 코드

  **3. 컨텍스트 스위칭 오버헤드**
  - **레지스터 저장/복원**: 사용자 컨텍스트 보존
  - **메모리 매핑 전환**: 사용자 페이지 테이블에서 커널 페이지 테이블로
  - **캐시 무효화**: TLB(Translation Lookaside Buffer) 플러시 가능성
  - **성능 비용**: 일반 함수 호출 대비 100-1000배 느림

  **시스템 콜 분류 및 심화 분석**

  **1. 파일 시스템 관련**
  - **파일 조작**: `open()`, `read()`, `write()`, `close()`, `lseek()`
    - **파일 디스크립터**: 커널이 관리하는 파일 핸들, 프로세스별 FD 테이블
    - **버퍼링**: 커널 버퍼를 통한 I/O 최적화, `fsync()`로 강제 플러시
    - **원자성**: `write()` 호출의 원자성 보장 범위와 한계
  - **디렉토리 조작**: `mkdir()`, `rmdir()`, `opendir()`, `readdir()`
  - **파일 속성**: `stat()`, `chmod()`, `chown()`, `utime()`

  **2. 프로세스 및 스레드 관리**
  - **프로세스 생성**: `fork()`, `exec()` 계열, `clone()`
    - **fork() 구현**: Copy-On-Write(COW) 메커니즘으로 메모리 효율성 확보
    - **exec() 동작**: 현재 프로세스 이미지를 새 프로그램으로 교체
    - **vfork()**: 부모 프로세스 일시 정지로 성능 최적화
  - **프로세스 종료**: `exit()`, `wait()`, `waitpid()`
  - **시그널 처리**: `signal()`, `sigaction()`, `kill()`, `sigprocmask()`

  **3. 메모리 관리**
  - **동적 할당**: `brk()`, `sbrk()` (힙 확장), `mmap()`, `munmap()` (메모리 매핑)
    - **mmap() 활용**: 파일을 메모리에 매핑, 공유 메모리 구현
    - **가상 메모리**: 페이지 단위 할당, 지연 할당(Lazy Allocation)
    - **메모리 보호**: `mprotect()`로 페이지 권한 설정
  - **공유 메모리**: `shmget()`, `shmat()`, `shmdt()`, `shmctl()`

  **4. 네트워크 통신**
  - **소켓 생성**: `socket()`, `bind()`, `listen()`, `accept()`, `connect()`
    - **소켓 타입**: SOCK_STREAM(TCP), SOCK_DGRAM(UDP), SOCK_RAW
    - **주소 체계**: AF_INET(IPv4), AF_INET6(IPv6), AF_UNIX(로컬)
  - **데이터 전송**: `send()`, `recv()`, `sendto()`, `recvfrom()`
  - **I/O 멀티플렉싱**: `select()`, `poll()`, `epoll()` (Linux), `kqueue()` (BSD)

  **5. 시간 및 타이머**
  - **시간 조회**: `time()`, `gettimeofday()`, `clock_gettime()`
  - **프로세스 대기**: `sleep()`, `usleep()`, `nanosleep()`
  - **타이머 설정**: `alarm()`, `setitimer()`, `timer_create()`

  **성능 최적화 기법**

  **1. 시스템 콜 최소화**
  - **배치 처리**: 여러 작업을 한 번의 시스템 콜로 처리 (`readv()`, `writev()`)
  - **버퍼링**: 사용자 공간에서 버퍼링하여 시스템 콜 횟수 감소
  - **메모리 매핑**: `mmap()`을 통한 파일 I/O 최적화

  **2. 비동기 I/O**
  - **AIO (Asynchronous I/O)**: `aio_read()`, `aio_write()` 등
  - **io_uring** (Linux): 고성능 비동기 I/O 인터페이스
  - **이벤트 기반**: `epoll()`, `kqueue()` 등을 통한 논블로킹 I/O

  **3. VDSO (Virtual Dynamic Shared Object)**
  - **커널 바이패스**: 자주 사용되는 시스템 콜을 사용자 공간에서 직접 실행
  - **예시**: `gettimeofday()`, `clock_gettime()` 등
  - **성능 향상**: 모드 전환 없이 커널 데이터 접근

  **디버깅 및 모니터링**
  - **strace**: 시스템 콜 추적 도구
  - **perf**: 시스템 콜 성능 분석
  - **ftrace**: 커널 함수 추적
  - **에러 처리**: `errno` 변수를 통한 에러 코드 확인

- **동기식 vs 비동기식 요청 처리**

  **동기식 처리(Synchronous Processing)**

  **핵심 개념**
  - **정의**: 요청을 보낸 후 **응답을 받을 때까지 호출자가 블로킹**되어 대기하는 처리 방식
  - **실행 흐름**: 순차적, 예측 가능한 실행 순서
  - **스레드 상태**: 요청 처리 중 스레드가 **BLOCKED** 또는 **WAITING** 상태로 전환

  **구현 메커니즘**
  - **블로킹 I/O**: `read()`, `write()` 등의 시스템 콜이 완료될 때까지 대기
  - **스레드 풀 모델**: 각 요청마다 스레드 할당, 요청 완료 시까지 스레드 점유
  - **컨텍스트 스위칭**: 블로킹된 스레드 대신 다른 스레드로 CPU 할당

  **성능 특성**
  - **장점**:
    - **단순한 프로그래밍 모델**: 직관적인 코드 작성, 디버깅 용이
    - **예측 가능한 실행 흐름**: 순차적 처리로 인한 명확한 제어 흐름
    - **강한 일관성**: 트랜잭션 처리에 적합
    - **에러 처리 단순화**: try-catch 블록으로 직접적인 예외 처리
  - **단점**:
    - **자원 비효율성**: 대기 중인 스레드가 CPU와 메모리 자원 점유
    - **확장성 제한**: 스레드 수 증가 시 컨텍스트 스위칭 오버헤드 급증
    - **응답성 저하**: 느린 작업이 전체 시스템 성능에 영향
    - **C10K 문제**: 동시 연결 수 증가 시 성능 급격히 저하

  **비동기식 처리(Asynchronous Processing)**

  **핵심 개념**
  - **정의**: 요청을 보낸 후 **즉시 제어권을 반환**하고, 결과는 나중에 콜백, 이벤트, 또는 Future를 통해 처리
  - **실행 흐름**: 비순차적, 이벤트 기반 실행
  - **스레드 상태**: 요청 후 스레드가 다른 작업을 계속 수행 가능

  **구현 메커니즘**

  **1. 콜백 기반 (Callback-based)**
  - **원리**: 작업 완료 시 호출될 함수를 미리 등록
  - **장점**: 메모리 효율적, 빠른 응답
  - **단점**: 콜백 지옥(Callback Hell), 에러 처리 복잡
  - **예시**: Node.js의 이벤트 루프, JavaScript의 setTimeout

  **2. Promise/Future 기반**
  - **원리**: 미래에 완료될 작업의 결과를 나타내는 객체
  - **상태**: Pending → Fulfilled/Rejected
  - **장점**: 체이닝 가능, 에러 처리 개선
  - **예시**: JavaScript Promise, Java CompletableFuture

  **3. 이벤트 루프 (Event Loop)**
  - **구조**: 단일 스레드 + 이벤트 큐 + 논블로킹 I/O
  - **동작 과정**:
    1. 이벤트 큐에서 이벤트 폴링
    2. I/O 작업을 커널에 위임
    3. 완료된 작업의 콜백 실행
    4. 다음 이벤트 처리
  - **예시**: Node.js, Python asyncio

  **4. 리액티브 스트림 (Reactive Streams)**
  - **원리**: 데이터 스트림과 변화 전파에 기반한 비동기 처리
  - **백프레셔(Backpressure)**: 생산자-소비자 속도 차이 제어
  - **예시**: RxJava, Spring WebFlux

  **성능 특성**
  - **장점**:
    - **높은 동시성**: 적은 스레드로 많은 요청 처리
    - **자원 효율성**: CPU와 메모리 사용량 최적화
    - **확장성**: C10K 문제 해결, 수만 개 동시 연결 처리 가능
    - **응답성**: 논블로킹으로 인한 빠른 응답 시간
  - **단점**:
    - **복잡한 프로그래밍 모델**: 콜백, Promise 체인 등 복잡한 제어 흐름
    - **디버깅 어려움**: 스택 트레이스 추적 복잡, 비순차적 실행
    - **에러 처리 복잡성**: 예외가 다른 컨텍스트에서 발생
    - **메모리 누수 위험**: 콜백 참조로 인한 가비지 컬렉션 방해

  **심화 비교 분석**

  **1. 처리량(Throughput) vs 지연시간(Latency)**
  - **동기식**: 낮은 처리량, 예측 가능한 지연시간
  - **비동기식**: 높은 처리량, 가변적인 지연시간

  **2. 메모리 사용 패턴**
  - **동기식**: 스레드 스택 메모리 (보통 1-8MB per thread)
  - **비동기식**: 힙 메모리의 콜백 객체들 (KB 단위)

  **3. CPU 사용률**
  - **동기식**: 컨텍스트 스위칭으로 인한 CPU 오버헤드
  - **비동기식**: 이벤트 루프의 효율적인 CPU 활용

  **4. 적용 사례**
  - **동기식 적합 사례**:
    - **트랜잭션 처리**: 은행 시스템, 결제 처리
    - **배치 처리**: 대용량 데이터 순차 처리
    - **CPU 집약적 작업**: 복잡한 계산, 암호화
  - **비동기식 적합 사례**:
    - **웹 서버**: HTTP 요청 처리
    - **채팅 시스템**: 실시간 메시징
    - **IoT 데이터 수집**: 센서 데이터 스트리밍
    - **마이크로서비스**: 서비스 간 통신

  **하이브리드 접근법**
  - **스레드 풀 + 비동기**: CPU 집약적 작업은 스레드 풀, I/O는 비동기
  - **가상 스레드(Virtual Threads)**: Java 21의 Project Loom, 경량 스레드로 동기식 코드의 단순함과 비동기식의 확장성 결합
  - **코루틴(Coroutines)**: Kotlin, Go의 경량 스레드, 동기식 코드 스타일로 비동기 처리

- **멀티플렉스 I/O (Multiplexed I/O)**

  **멀티플렉스 I/O란?**
  - **정의**: **단일 스레드**가 **다수의 I/O 디스크립터**를 동시에 모니터링하여, 준비된 디스크립터에 대해서만 I/O 작업을 수행하는 기법
  - **핵심 목적**: **블로킹 I/O의 비효율성**을 해결하고, **스레드 수를 최소화**하면서 높은 동시성 달성
  - **동작 원리**: I/O 준비 상태를 **커널이 감시**하고, 애플리케이션은 준비된 디스크립터에 대해서만 논블로킹 I/O 수행

  **전통적인 I/O 모델의 한계**
  - **블로킹 I/O**: 각 연결마다 스레드 필요, 스레드 수 증가 시 메모리 부족과 컨텍스트 스위칭 오버헤드
  - **논블로킹 I/O**: 폴링 방식으로 CPU 낭비, 준비되지 않은 디스크립터 반복 확인
  - **C10K 문제**: 10,000개 동시 연결 처리 시 기존 모델의 한계 노출

  **주요 구현 방식 심화 분석**

  **1. select() 시스템 콜**

  **구현 메커니즘**
  - **파일 디스크립터 집합**: `fd_set` 비트마스크 사용 (최대 1024개 제한)
  - **이벤트 타입**: 읽기(readfds), 쓰기(writefds), 예외(exceptfds) 집합 분리
  - **타임아웃**: 지정된 시간 내에 이벤트 없으면 반환

  **동작 과정**
  ```
  1. fd_set 구조체에 모니터링할 디스크립터 설정
  2. select() 호출로 커널에 감시 요청
  3. 커널이 디스크립터 상태 변화 감시
  4. 준비된 디스크립터가 있으면 해당 비트 설정 후 반환
  5. 애플리케이션이 준비된 디스크립터에 대해 I/O 수행
  ```

  **성능 특성**
  - **장점**: 이식성 우수 (POSIX 표준), 구현 단순
  - **단점**: 
    - **FD_SETSIZE 제한**: 보통 1024개 디스크립터 제한
    - **선형 스캔**: 준비된 디스크립터 찾기 위해 전체 집합 스캔 (O(n))
    - **커널-사용자 공간 복사**: fd_set 구조체 복사 오버헤드
    - **재설정 필요**: 매 호출마다 fd_set 재설정 필요

  **2. poll() 시스템 콜**

  **구현 메커니즘**
  - **pollfd 구조체 배열**: 각 디스크립터별 이벤트와 결과 저장
  - **이벤트 마스크**: POLLIN(읽기), POLLOUT(쓰기), POLLERR(에러) 등
  - **동적 크기**: 배열 크기 제한 없음

  **select() 대비 개선사항**
  - **크기 제한 해제**: 디스크립터 수 제한 없음
  - **이벤트 분리**: 입력 이벤트와 결과 이벤트 분리로 재설정 불필요
  - **더 많은 이벤트 타입**: POLLPRI(긴급 데이터), POLLHUP(연결 종료) 등

  **성능 특성**
  - **장점**: select()의 제한사항 해결, 더 정교한 이벤트 제어
  - **단점**: 여전히 O(n) 복잡도, 대량 디스크립터 처리 시 성능 저하

  **3. epoll() 시스템 콜 (Linux)**

  **구현 메커니즘**
  - **epoll 인스턴스**: `epoll_create()`로 커널 내 이벤트 테이블 생성
  - **이벤트 등록**: `epoll_ctl()`로 디스크립터와 이벤트 등록/수정/삭제
  - **이벤트 대기**: `epoll_wait()`로 준비된 이벤트만 반환

  **핵심 혁신**
  - **O(1) 복잡도**: 준비된 이벤트만 반환, 전체 디스크립터 스캔 불필요
  - **커널 내 상태 유지**: 디스크립터 상태를 커널이 지속적으로 관리
  - **Edge-Triggered vs Level-Triggered**:
    - **Level-Triggered (기본)**: 데이터가 있는 동안 계속 이벤트 발생
    - **Edge-Triggered**: 상태 변화 시점에만 이벤트 발생, 더 효율적이지만 구현 복잡

  **동작 과정**
  ```
  1. epoll_create()로 epoll 인스턴스 생성
  2. epoll_ctl(EPOLL_CTL_ADD)로 디스크립터 등록
  3. epoll_wait()로 이벤트 대기
  4. 준비된 이벤트 배열 반환 (O(1))
  5. 각 이벤트에 대해 I/O 처리
  ```

  **성능 특성**
  - **장점**: 
    - **확장성**: 수십만 개 동시 연결 처리 가능
    - **효율성**: CPU 사용률 최적화, 메모리 사용량 감소
    - **유연성**: Edge/Level 트리거 선택 가능
  - **단점**: Linux 전용, 복잡한 프로그래밍 모델

  **4. 기타 플랫폼별 구현**
  - **kqueue** (FreeBSD, macOS): epoll과 유사한 성능, 더 일반화된 이벤트 시스템
  - **IOCP** (Windows): Completion Port 기반, 비동기 I/O와 결합
  - **io_uring** (Linux): 최신 고성능 비동기 I/O 인터페이스

  **성능 비교 및 벤치마크**

  **연결 수별 성능 특성**
  - **소규모 (< 100 연결)**: select/poll도 충분한 성능
  - **중규모 (100-1000 연결)**: poll이 select보다 우수
  - **대규모 (> 1000 연결)**: epoll이 압도적 성능 우위

  **메모리 사용량**
  - **select**: fd_set 크기 고정 (128 bytes)
  - **poll**: pollfd 배열 크기에 비례
  - **epoll**: 등록된 디스크립터 수에 비례, 효율적인 커널 자료구조

  **CPU 사용률**
  - **select/poll**: 디스크립터 수에 선형 비례
  - **epoll**: 활성 연결 수에만 비례, 유휴 연결은 오버헤드 없음

  **실제 적용 사례**
  - **웹 서버**: Nginx (epoll), Apache (select/poll)
  - **데이터베이스**: Redis (epoll), PostgreSQL (select/poll)
  - **메시지 큐**: RabbitMQ, Apache Kafka
  - **프록시 서버**: HAProxy, Envoy

  **프로그래밍 모델과 라이브러리**
  - **Reactor 패턴**: 이벤트 기반 아키텍처의 핵심 패턴
  - **이벤트 루프**: libevent, libev, libuv 등의 추상화 라이브러리
  - **고수준 프레임워크**: Node.js, Netty, Twisted 등

## 2. 네트워크
- **VPC와 서브네팅**

  **VPC (Virtual Private Cloud) 심화 분석**

  **핵심 개념**
  - **정의**: 클라우드 환경에서 **논리적으로 격리된 가상 네트워크 공간**으로, 사용자가 완전히 제어할 수 있는 네트워크 환경
  - **격리 메커니즘**: **소프트웨어 정의 네트워킹(SDN)**을 통해 물리적 인프라 위에 논리적 네트워크 계층 구축
  - **멀티 테넌시**: 동일한 물리적 인프라에서 여러 VPC가 완전히 격리되어 운영

  **VPC 아키텍처 구성 요소**

  **1. CIDR 블록 (Classless Inter-Domain Routing)**
  - **IP 주소 범위 정의**: VPC 생성 시 사용할 IP 주소 범위 지정
  - **RFC 1918 사설 IP 대역**:
    - **Class A**: 10.0.0.0/8 (10.0.0.0 ~ 10.255.255.255)
    - **Class B**: 172.16.0.0/12 (172.16.0.0 ~ 172.31.255.255)  
    - **Class C**: 192.168.0.0/16 (192.168.0.0 ~ 192.168.255.255)
  - **서브넷 마스크**: /16 ~ /28 범위에서 선택, 더 작은 값일수록 더 많은 IP 주소
  - **확장성 고려**: 향후 확장을 위해 충분한 IP 주소 공간 확보 필요

  **2. 서브넷(Subnet) 설계 전략**

  **서브넷 유형**
  - **퍼블릭 서브넷**: 인터넷 게이트웨이로 직접 라우팅, 공인 IP 할당 가능
  - **프라이빗 서브넷**: NAT 게이트웨이를 통해서만 외부 접근, 내부 통신 전용
  - **격리된 서브넷**: 외부 인터넷 접근 불가, 데이터베이스 등 민감한 자원 배치

  **서브네팅 계산 및 설계**
  - **가용 영역(AZ) 분산**: 고가용성을 위해 여러 AZ에 서브넷 분산 배치
  - **IP 주소 계산**: 2^(32-서브넷마스크) - 5 (AWS 예약 IP 제외)
  - **계층별 분리**: 웹 계층, 애플리케이션 계층, 데이터베이스 계층별 서브넷 분리
  - **예시 설계**:
    ```
    VPC: 10.0.0.0/16 (65,536개 IP)
    ├── Public Subnet A: 10.0.1.0/24 (251개 IP)
    ├── Public Subnet B: 10.0.2.0/24 (251개 IP)
    ├── Private Subnet A: 10.0.11.0/24 (251개 IP)
    ├── Private Subnet B: 10.0.12.0/24 (251개 IP)
    ├── DB Subnet A: 10.0.21.0/24 (251개 IP)
    └── DB Subnet B: 10.0.22.0/24 (251개 IP)
    ```

  **3. 라우팅 테이블 (Route Table)**

  **라우팅 메커니즘**
  - **목적지 기반 라우팅**: 패킷의 목적지 IP에 따라 경로 결정
  - **최장 접두사 매칭**: 가장 구체적인 경로 우선 선택
  - **라우팅 우선순위**: 로컬 > 정적 > 동적 라우팅 순서

  **주요 라우팅 대상**
  - **로컬 라우팅**: VPC 내부 통신 (자동 생성, 삭제 불가)
  - **인터넷 게이트웨이**: 0.0.0.0/0 → IGW (퍼블릭 서브넷)
  - **NAT 게이트웨이**: 0.0.0.0/0 → NAT-GW (프라이빗 서브넷)
  - **VPC 피어링**: 다른 VPC CIDR → PCX-xxxxx
  - **VPN 게이트웨이**: 온프레미스 네트워크 → VGW

  **4. 인터넷 게이트웨이 (Internet Gateway)**

  **기능 및 특성**
  - **양방향 인터넷 연결**: VPC와 인터넷 간 통신 브리지 역할
  - **NAT 기능**: 사설 IP와 공인 IP 간 주소 변환
  - **고가용성**: AWS가 관리하는 완전 관리형 서비스, 단일 장애점 없음
  - **대역폭 제한 없음**: 무제한 대역폭 제공

  **5. NAT 게이트웨이 vs NAT 인스턴스**

  **NAT 게이트웨이 (관리형)**
  - **장점**: 완전 관리형, 고가용성, 자동 확장, 보안 패치 자동 적용
  - **단점**: 비용 높음, 커스터마이징 제한
  - **성능**: 최대 45Gbps 대역폭 지원

  **NAT 인스턴스 (사용자 관리)**
  - **장점**: 비용 효율적, 완전한 제어권, 커스터마이징 가능
  - **단점**: 관리 부담, 단일 장애점, 수동 확장 필요
  - **성능**: 인스턴스 타입에 따라 제한

  **보안 및 네트워크 제어**

  **1. 보안 그룹 (Security Groups)**
  - **상태 기반 방화벽**: 연결 상태를 추적하여 응답 트래픽 자동 허용
  - **화이트리스트 방식**: 명시적으로 허용된 트래픽만 통과
  - **인바운드/아웃바운드 규칙**: 방향별 독립적인 규칙 설정
  - **동적 참조**: 다른 보안 그룹을 소스/대상으로 참조 가능

  **2. 네트워크 ACL (Access Control List)**
  - **무상태 방화벽**: 각 패킷을 독립적으로 평가
  - **블랙리스트 방식**: 명시적으로 거부된 트래픽 차단
  - **서브넷 레벨 적용**: 서브넷 전체에 적용되는 추가 보안 계층
  - **규칙 번호**: 낮은 번호부터 순차적으로 평가

  **3. VPC 플로우 로그**
  - **네트워크 트래픽 모니터링**: IP 트래픽 정보 수집 및 분석
  - **보안 분석**: 비정상적인 트래픽 패턴 감지
  - **규정 준수**: 네트워크 접근 로그 보관
  - **성능 분석**: 네트워크 병목 지점 식별

  **고급 VPC 기능**

  **1. VPC 피어링 (VPC Peering)**
  - **VPC 간 연결**: 서로 다른 VPC 간 사설 네트워크 연결
  - **전이적 라우팅 불가**: A-B, B-C 연결 시 A-C 직접 통신 불가
  - **CIDR 중복 불가**: 피어링하는 VPC 간 IP 대역 중복 금지
  - **리전 간 피어링**: 다른 리전의 VPC와도 연결 가능

  **2. Transit Gateway**
  - **중앙 집중식 연결**: 여러 VPC와 온프레미스 네트워크를 중앙에서 관리
  - **전이적 라우팅**: 모든 연결된 네트워크 간 통신 가능
  - **확장성**: 수천 개의 VPC 연결 지원
  - **라우팅 테이블**: 세밀한 라우팅 제어 가능

  **3. VPC 엔드포인트**
  - **게이트웨이 엔드포인트**: S3, DynamoDB 등 AWS 서비스 직접 접근
  - **인터페이스 엔드포인트**: ENI 기반으로 다양한 AWS 서비스 접근
  - **프라이빗 연결**: 인터넷을 거치지 않고 AWS 서비스 이용
  - **비용 절감**: NAT 게이트웨이 비용 절약

  **성능 최적화 및 모니터링**

  **1. 네트워크 성능 최적화**
  - **배치 그룹**: 동일 AZ 내 인스턴스 간 네트워크 성능 향상
  - **SR-IOV**: 하드웨어 가상화를 통한 네트워크 성능 개선
  - **Enhanced Networking**: 높은 PPS, 낮은 지연시간, 낮은 지터
  - **인스턴스 타입 선택**: 네트워크 성능에 따른 적절한 인스턴스 선택

  **2. 비용 최적화**
  - **데이터 전송 비용**: AZ 간, 리전 간 데이터 전송 비용 고려
  - **NAT 게이트웨이 최적화**: 필요한 AZ에만 배치, 트래픽 패턴 분석
  - **VPC 엔드포인트 활용**: S3, DynamoDB 접근 시 인터넷 게이트웨이 비용 절약
  - **예약 인스턴스**: NAT 인스턴스 사용 시 예약 인스턴스로 비용 절감

- **HTTP vs HTTPS**

  **HTTP (HyperText Transfer Protocol) 심화 분석**

  **핵심 특성**
  - **정의**: 웹에서 **클라이언트와 서버 간 데이터 교환**을 위한 애플리케이션 계층 프로토콜
  - **무상태(Stateless)**: 각 요청이 독립적, 이전 요청 정보를 서버가 기억하지 않음
  - **평문 통신**: 모든 데이터가 **암호화되지 않은 상태**로 전송
  - **기본 포트**: 80번 포트 사용

  **HTTP의 보안 취약점**
  - **도청(Eavesdropping)**: 네트워크 패킷 스니핑으로 데이터 내용 노출
  - **변조(Tampering)**: 중간자가 데이터 내용을 수정할 수 있음
  - **위장(Impersonation)**: 서버 신원 확인 불가, 피싱 사이트 위험
  - **재전송 공격(Replay Attack)**: 캡처된 요청을 재전송하여 악용 가능

  **HTTPS (HTTP Secure) 심화 분석**

  **핵심 개념**
  - **정의**: **TLS/SSL 암호화 계층** 위에서 동작하는 HTTP 프로토콜
  - **보안 목표**: **기밀성(Confidentiality)**, **무결성(Integrity)**, **인증(Authentication)** 보장
  - **기본 포트**: 443번 포트 사용
  - **프로토콜 스택**: HTTP → TLS/SSL → TCP → IP

  **TLS/SSL 암호화 메커니즘**

  **1. 대칭키 암호화 (Symmetric Encryption)**
  - **원리**: 동일한 키로 암호화와 복호화 수행
  - **장점**: 빠른 처리 속도, 낮은 CPU 오버헤드
  - **단점**: 키 배송 문제, 키 관리 복잡성
  - **알고리즘**: AES-128, AES-256, ChaCha20-Poly1305

  **2. 비대칭키 암호화 (Asymmetric Encryption)**
  - **원리**: 공개키와 개인키 쌍을 사용, 한 키로 암호화하면 다른 키로 복호화
  - **장점**: 키 배송 문제 해결, 디지털 서명 가능
  - **단점**: 느린 처리 속도, 높은 CPU 오버헤드
  - **알고리즘**: RSA, ECDSA, Ed25519

  **3. 하이브리드 암호화**
  - **핵심 아이디어**: 비대칭키로 대칭키를 안전하게 교환, 실제 데이터는 대칭키로 암호화
  - **성능 최적화**: 비대칭키의 보안성과 대칭키의 효율성 결합
  - **키 교환**: ECDHE (Elliptic Curve Diffie-Hellman Ephemeral)

  **TLS Handshake 상세 과정**

  **Phase 1: Hello 메시지 교환**
  ```
  Client Hello:
  - TLS 버전 (1.2, 1.3)
  - 클라이언트 랜덤 값 (32바이트)
  - 세션 ID (세션 재사용용)
  - 지원 암호 스위트 목록
  - 지원 압축 방법
  - 확장 필드 (SNI, ALPN 등)
  ```

  ```
  Server Hello:
  - 선택된 TLS 버전
  - 서버 랜덤 값 (32바이트)
  - 세션 ID
  - 선택된 암호 스위트
  - 선택된 압축 방법
  - 확장 필드 응답
  ```

  **Phase 2: 서버 인증 및 키 교환**
  ```
  Certificate:
  - 서버 인증서 체인 전송
  - 루트 CA → 중간 CA → 서버 인증서
  - 공개키 정보 포함
  ```

  ```
  Server Key Exchange (필요시):
  - DHE, ECDHE 등 키 교환 알고리즘 사용 시
  - 서버의 임시 공개키 매개변수
  - 디지털 서명으로 무결성 보장
  ```

  **Phase 3: 클라이언트 키 교환 및 검증**
  ```
  Client Key Exchange:
  - Pre-Master Secret 생성 (46바이트 랜덤 값)
  - 서버 공개키로 암호화하여 전송
  - 또는 ECDHE 매개변수 전송
  ```

  **Phase 4: 세션 키 생성**
  ```
  Master Secret 생성:
  Master Secret = PRF(Pre-Master Secret, 
                     "master secret", 
                     Client Random + Server Random)

  세션 키 유도:
  - 클라이언트 쓰기 키
  - 서버 쓰기 키  
  - 클라이언트 MAC 키
  - 서버 MAC 키
  - 초기화 벡터 (IV)
  ```

  **Phase 5: Handshake 완료**
  ```
  Change Cipher Spec:
  - 이후 메시지부터 암호화 적용 알림

  Finished:
  - 핸드셰이크 메시지들의 해시값
  - 새로 생성된 키로 암호화
  - 상호 검증 완료
  ```

  **인증서 검증 과정**

  **1. 인증서 체인 검증**
  - **루트 CA 신뢰성**: 브라우저/OS에 내장된 신뢰할 수 있는 루트 CA 목록 확인
  - **체인 연결성**: 루트 CA → 중간 CA → 서버 인증서 연결 검증
  - **디지털 서명**: 각 단계에서 상위 CA의 개인키로 서명된 내용을 공개키로 검증

  **2. 인증서 유효성 검증**
  - **유효 기간**: Not Before ~ Not After 범위 내 현재 시간 확인
  - **도메인 매칭**: 인증서의 CN(Common Name) 또는 SAN(Subject Alternative Name)과 요청 도메인 일치 확인
  - **폐기 상태**: CRL(Certificate Revocation List) 또는 OCSP(Online Certificate Status Protocol)로 폐기 여부 확인

  **3. 확장 검증 (Extended Validation)**
  - **EV 인증서**: 더 엄격한 신원 확인 과정을 거친 인증서
  - **시각적 표시**: 브라우저 주소창에 회사명 표시 (일부 브라우저)
  - **높은 신뢰도**: 피싱 방지 효과

  **암호 스위트 (Cipher Suite) 구성**

  **구성 요소**
  ```
  예시: TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
  - TLS: 프로토콜
  - ECDHE: 키 교환 알고리즘
  - RSA: 인증 알고리즘
  - AES_256_GCM: 대칭 암호화 알고리즘
  - SHA384: 해시 함수
  ```

  **보안 강도별 분류**
  - **강력**: ECDHE + AES-256 + SHA-384
  - **권장**: ECDHE + AES-128 + SHA-256
  - **취약**: RC4, DES, MD5 (사용 금지)

  **성능 최적화 기법**

  **1. 세션 재사용 (Session Resumption)**
  - **세션 ID**: 서버가 세션 정보를 메모리에 저장
  - **세션 티켓**: 암호화된 세션 정보를 클라이언트가 저장
  - **성능 향상**: 핸드셰이크 과정 단축, CPU 사용량 감소

  **2. OCSP Stapling**
  - **원리**: 서버가 미리 OCSP 응답을 받아서 클라이언트에게 전달
  - **장점**: 클라이언트의 OCSP 요청 불필요, 연결 속도 향상
  - **프라이버시**: 클라이언트가 CA에 직접 요청하지 않아 프라이버시 보호

  **3. HTTP/2 및 HTTP/3**
  - **HTTP/2**: 멀티플렉싱으로 여러 요청 동시 처리
  - **HTTP/3**: QUIC 프로토콜 기반, 0-RTT 연결 재개
  - **성능**: 핸드셰이크 최적화, 헤드 오브 라인 블로킹 해결

  **보안 헤더 및 추가 보안 기능**

  **1. HSTS (HTTP Strict Transport Security)**
  - **목적**: HTTP에서 HTTPS로 강제 리다이렉션
  - **헤더**: `Strict-Transport-Security: max-age=31536000; includeSubDomains`
  - **효과**: 프로토콜 다운그레이드 공격 방지

  **2. Certificate Pinning**
  - **공개키 피닝**: 특정 공개키만 신뢰하도록 설정
  - **인증서 피닝**: 특정 인증서만 신뢰하도록 설정
  - **보안 강화**: 중간자 공격 방지, CA 침해 대응

  **3. Perfect Forward Secrecy (PFS)**
  - **원리**: 각 세션마다 고유한 세션 키 생성
  - **구현**: ECDHE, DHE 키 교환 알고리즘 사용
  - **보안**: 개인키 유출 시에도 과거 통신 내용 보호

  **성능 비교 및 오버헤드**

  **연결 설정 시간**
  - **HTTP**: TCP 3-way handshake (1 RTT)
  - **HTTPS**: TCP handshake + TLS handshake (2-3 RTT)
  - **최적화**: TLS 1.3에서 1-RTT handshake 지원

  **처리 성능**
  - **CPU 오버헤드**: 암호화/복호화로 인한 10-15% CPU 사용량 증가
  - **메모리 사용**: 세션 정보 저장으로 인한 메모리 사용량 증가
  - **하드웨어 가속**: AES-NI 등 하드웨어 가속 기능 활용

  **대역폭 오버헤드**
  - **인증서 전송**: 초기 연결 시 2-4KB 추가 데이터
  - **암호화 헤더**: 각 레코드마다 5바이트 헤더 추가
  - **패딩**: 블록 암호화 시 패딩 바이트 추가

- **SSL/TLS Handshake 흐름**

  **SSL/TLS Handshake 심화 분석**

  **핵심 목적**
  - **상호 인증**: 클라이언트와 서버 간 신원 확인
  - **암호화 협상**: 사용할 암호화 알고리즘과 매개변수 결정
  - **키 교환**: 안전한 통신을 위한 세션 키 생성 및 교환
  - **보안 채널 설정**: 이후 모든 통신을 암호화하는 보안 채널 구축

  **TLS 1.2 Handshake 상세 과정**

  **Phase 1: 초기 협상 (Negotiation)**

  **1. ClientHello 메시지**
  ```
  구성 요소:
  - Protocol Version: 클라이언트가 지원하는 최고 TLS 버전
  - Random: 32바이트 랜덤 값 (4바이트 타임스탬프 + 28바이트 랜덤)
  - Session ID: 세션 재사용을 위한 식별자 (0-32바이트)
  - Cipher Suites: 지원하는 암호화 스위트 목록 (우선순위 순)
  - Compression Methods: 지원하는 압축 방법 (보통 null만 지원)
  - Extensions: 추가 기능 (SNI, ALPN, Supported Groups 등)
  ```

  **주요 확장 필드 (Extensions)**
  - **SNI (Server Name Indication)**: 가상 호스팅 지원, 도메인명 전송
  - **ALPN (Application Layer Protocol Negotiation)**: HTTP/2, HTTP/3 등 애플리케이션 프로토콜 협상
  - **Supported Groups**: 지원하는 타원곡선 그룹 (P-256, P-384 등)
  - **Signature Algorithms**: 지원하는 디지털 서명 알고리즘

  **2. ServerHello 메시지**
  ```
  구성 요소:
  - Protocol Version: 서버가 선택한 TLS 버전
  - Random: 32바이트 서버 랜덤 값
  - Session ID: 세션 재사용 시 동일 ID, 새 세션 시 새 ID
  - Cipher Suite: 선택된 단일 암호화 스위트
  - Compression Method: 선택된 압축 방법
  - Extensions: 클라이언트 확장에 대한 응답
  ```

  **Phase 2: 서버 인증 및 키 교환**

  **3. Certificate 메시지**
  ```
  인증서 체인 구조:
  - 서버 인증서 (End-Entity Certificate)
  - 중간 CA 인증서들 (Intermediate CA Certificates)
  - 루트 CA 인증서 (선택적, 보통 생략)

  인증서 정보:
  - 공개키 및 알고리즘
  - 유효 기간 (Not Before, Not After)
  - 주체 정보 (Subject DN)
  - 발급자 정보 (Issuer DN)
  - 디지털 서명
  ```

  **4. ServerKeyExchange 메시지 (조건부)**
  ```
  필요한 경우:
  - DHE (Diffie-Hellman Ephemeral) 키 교환
  - ECDHE (Elliptic Curve DHE) 키 교환
  - RSA 키 교환에서 인증서의 공개키와 다른 키 사용 시

  포함 내용:
  - 키 교환 매개변수 (DH 매개변수, EC 포인트 등)
  - 서버의 디지털 서명 (매개변수 무결성 보장)
  ```

  **5. CertificateRequest 메시지 (선택적)**
  ```
  클라이언트 인증이 필요한 경우:
  - 허용되는 인증서 타입
  - 지원하는 서명 알고리즘
  - 신뢰할 수 있는 CA 목록
  ```

  **6. ServerHelloDone 메시지**
  - 서버의 초기 메시지 전송 완료 알림
  - 클라이언트의 응답 대기 신호

  **Phase 3: 클라이언트 응답 및 키 교환**

  **7. Certificate 메시지 (클라이언트, 선택적)**
  - 클라이언트 인증이 요청된 경우 클라이언트 인증서 전송

  **8. ClientKeyExchange 메시지**
  ```
  RSA 키 교환:
  - Pre-Master Secret (48바이트) 생성
  - 서버 공개키로 암호화하여 전송

  DHE/ECDHE 키 교환:
  - 클라이언트의 공개키 매개변수 전송
  - 공유 비밀 계산을 위한 정보 교환
  ```

  **9. CertificateVerify 메시지 (선택적)**
  - 클라이언트 인증서를 전송한 경우
  - 클라이언트 개인키로 핸드셰이크 메시지들에 대한 디지털 서명

  **Phase 4: 세션 키 생성 및 검증**

  **10. Master Secret 생성**
  ```
  PRF (Pseudo-Random Function) 사용:
  Master Secret = PRF(Pre-Master Secret, 
                     "master secret",
                     ClientHello.random + ServerHello.random)

  길이: 48바이트 고정
  ```

  **11. 세션 키 유도**
  ```
  Key Block = PRF(Master Secret,
                  "key expansion",
                  ServerHello.random + ClientHello.random)

  유도되는 키들:
  - Client Write MAC Key
  - Server Write MAC Key  
  - Client Write Encryption Key
  - Server Write Encryption Key
  - Client Write IV (초기화 벡터)
  - Server Write IV
  ```

  **Phase 5: Handshake 완료**

  **12. ChangeCipherSpec 메시지 (클라이언트)**
  - 이후 메시지부터 협상된 암호화 적용 알림
  - 실제로는 TLS 레코드 프로토콜의 일부

  **13. Finished 메시지 (클라이언트)**
  ```
  구성:
  - 모든 핸드셰이크 메시지의 해시값
  - PRF로 생성된 검증 데이터
  - 새로 생성된 키로 암호화

  검증 데이터 = PRF(Master Secret,
                   "client finished",
                   Hash(모든 핸드셰이크 메시지))
  ```

  **14. ChangeCipherSpec 메시지 (서버)**
  - 서버도 암호화 모드로 전환 알림

  **15. Finished 메시지 (서버)**
  - 서버의 검증 데이터 전송
  - 핸드셰이크 완료 확인

  **TLS 1.3 Handshake 개선사항**

  **주요 변경점**
  - **1-RTT Handshake**: 기존 2-RTT에서 1-RTT로 단축
  - **0-RTT 재개**: 이전 세션 정보로 즉시 데이터 전송 가능
  - **Forward Secrecy 강제**: 모든 키 교환에서 PFS 보장
  - **약한 암호화 제거**: RC4, DES, MD5 등 취약한 알고리즘 완전 제거

  **TLS 1.3 Handshake 흐름**
  ```
  Client                                Server

  ClientHello
  + KeyShare              -------->
                                    ServerHello
                                    + KeyShare
                          <-------- {EncryptedExtensions}
                          <-------- {Certificate}
                          <-------- {CertificateVerify}
                          <-------- {Finished}
  {Certificate}
  {CertificateVerify}
  {Finished}              -------->

  [Application Data]      <------> [Application Data]
  ```

  **성능 최적화 기법**

  **1. 세션 재사용 (Session Resumption)**

  **세션 ID 방식**
  - 서버가 세션 상태를 메모리에 저장
  - 클라이언트가 동일한 세션 ID로 재연결 시 핸드셰이크 단축
  - 메모리 사용량 증가, 서버 확장성 제한

  **세션 티켓 방식 (RFC 5077)**
  - 서버가 세션 정보를 암호화하여 클라이언트에게 전달
  - 클라이언트가 티켓을 다시 제시하여 세션 재개
  - 서버 메모리 절약, 확장성 향상

  **2. False Start**
  - 클라이언트가 서버의 Finished 메시지를 기다리지 않고 애플리케이션 데이터 전송
  - 1-RTT 절약, 연결 설정 시간 단축
  - 보안 위험 존재, 신중한 구현 필요

  **3. OCSP Stapling**
  - 서버가 OCSP 응답을 미리 받아서 핸드셰이크 중 전달
  - 클라이언트의 추가 OCSP 요청 불필요
  - 연결 속도 향상, 프라이버시 보호

  **보안 고려사항**

  **1. 다운그레이드 공격 방지**
  - **Protocol Version Rollback**: 공격자가 낮은 버전으로 강제 협상 시도
  - **Cipher Suite Downgrade**: 약한 암호화 스위트로 강제 협상
  - **방어**: Finished 메시지에 협상된 매개변수 포함하여 검증

  **2. 중간자 공격 (MITM) 방지**
  - **인증서 검증**: 체인 검증, 도메인 매칭, 유효 기간 확인
  - **Certificate Pinning**: 특정 인증서나 공개키만 신뢰
  - **HSTS**: HTTP에서 HTTPS로 강제 리다이렉션

  **3. 재전송 공격 방지**
  - **랜덤 값 사용**: 클라이언트와 서버 모두 랜덤 값 생성
  - **세션별 고유 키**: 각 세션마다 다른 암호화 키 사용
  - **타임스탬프**: 메시지 신선도 확인

  **디버깅 및 모니터링**

  **1. Handshake 실패 원인 분석**
  - **인증서 문제**: 만료, 체인 불완전, 도메인 불일치
  - **암호화 스위트 불일치**: 클라이언트-서버 간 공통 스위트 없음
  - **프로토콜 버전 불일치**: 지원하지 않는 TLS 버전 사용

  **2. 성능 모니터링**
  - **핸드셰이크 시간**: RTT, 처리 시간 측정
  - **세션 재사용률**: 새 세션 vs 재사용 세션 비율
  - **암호화 오버헤드**: CPU 사용률, 처리량 영향

  **3. 보안 모니터링**
  - **약한 암호화 사용**: 취약한 스위트 사용 감지
  - **인증서 이상**: 만료 임박, 체인 문제 알림
  - **비정상 패턴**: 과도한 핸드셰이크 실패, 다운그레이드 시도

- **TCP 4-way Connection Termination**

  **TCP 연결 종료 심화 분석**

  **핵심 개념**
  - **정의**: TCP 연결을 **안전하고 신뢰성 있게 종료**하기 위한 4단계 핸드셰이크 과정
  - **양방향 종료**: TCP는 **전이중(Full-Duplex)** 통신이므로 각 방향별로 독립적인 종료 과정 필요
  - **우아한 종료(Graceful Shutdown)**: 데이터 손실 없이 모든 전송 중인 데이터의 완전한 전달 보장

  **4-Way Handshake 상세 과정**

  **Phase 1: 능동 종료 시작 (Active Close)**
  ```
  클라이언트 → 서버: FIN 세그먼트 전송
  - FIN 플래그 설정
  - 시퀀스 번호: 마지막 전송 데이터의 다음 번호
  - 클라이언트 상태: ESTABLISHED → FIN_WAIT_1
  - 의미: "더 이상 전송할 데이터가 없음"
  ```

  **Phase 2: 수동 종료 응답 (Passive Close Acknowledgment)**
  ```
  서버 → 클라이언트: ACK 세그먼트 전송
  - ACK 플래그 설정
  - 확인 번호: 받은 FIN의 시퀀스 번호 + 1
  - 서버 상태: ESTABLISHED → CLOSE_WAIT
  - 클라이언트 상태: FIN_WAIT_1 → FIN_WAIT_2
  - 의미: "FIN 수신 확인, 아직 전송할 데이터가 있을 수 있음"
  ```

  **Phase 3: 수동 종료 완료 (Passive Close Completion)**
  ```
  서버 → 클라이언트: FIN 세그먼트 전송
  - FIN 플래그 설정
  - 서버의 모든 데이터 전송 완료 후
  - 서버 상태: CLOSE_WAIT → LAST_ACK
  - 의미: "서버도 더 이상 전송할 데이터가 없음"
  ```

  **Phase 4: 최종 확인 (Final Acknowledgment)**
  ```
  클라이언트 → 서버: ACK 세그먼트 전송
  - ACK 플래그 설정
  - 확인 번호: 받은 FIN의 시퀀스 번호 + 1
  - 클라이언트 상태: FIN_WAIT_2 → TIME_WAIT
  - 서버 상태: LAST_ACK → CLOSED
  - 의미: "모든 종료 과정 완료 확인"
  ```

  **TCP 상태 전이 심화 분석**

  **1. FIN_WAIT_1 상태**
  - **진입 조건**: 애플리케이션이 `close()` 호출 후 FIN 전송
  - **특징**: 
    - 더 이상 데이터 전송 불가
    - 상대방으로부터 데이터 수신은 가능
    - ACK 대기 중
  - **타임아웃**: 일반적으로 60초, 재전송 메커니즘 적용

  **2. FIN_WAIT_2 상태**
  - **진입 조건**: FIN에 대한 ACK 수신
  - **특징**:
    - 상대방의 FIN 대기
    - 상대방으로부터 데이터 계속 수신 가능
    - **Half-Close** 상태 (반쪽 연결)
  - **위험성**: 상대방이 FIN을 보내지 않으면 무한 대기 가능
  - **타임아웃**: 시스템별로 다름 (Linux: 60초)

  **3. CLOSE_WAIT 상태**
  - **진입 조건**: 상대방으로부터 FIN 수신 후 ACK 전송
  - **특징**:
    - 애플리케이션이 아직 `close()` 호출하지 않음
    - 계속해서 데이터 전송 가능
    - **애플리케이션 레벨에서 종료 처리 필요**
  - **문제점**: 애플리케이션이 종료 처리하지 않으면 소켓 누수 발생

  **4. LAST_ACK 상태**
  - **진입 조건**: CLOSE_WAIT에서 애플리케이션이 `close()` 호출 후 FIN 전송
  - **특징**: 마지막 ACK 대기
  - **타임아웃**: 재전송 메커니즘 적용

  **5. TIME_WAIT 상태 심화**

  **TIME_WAIT의 핵심 목적**
  - **지연된 세그먼트 처리**: 네트워크에서 지연되어 도착하는 이전 연결의 세그먼트 방지
  - **마지막 ACK 재전송**: 서버가 마지막 ACK을 받지 못한 경우 FIN 재전송에 대한 ACK 재전송
  - **포트 재사용 방지**: 동일한 4-tuple (src_ip, src_port, dst_ip, dst_port) 재사용 방지

  **2MSL (Maximum Segment Lifetime) 대기**
  - **MSL 정의**: TCP 세그먼트가 네트워크에서 생존할 수 있는 최대 시간
  - **일반적 값**: 30초 ~ 2분 (시스템별 상이)
  - **2MSL 이유**: 
    - 1MSL: 마지막 ACK이 목적지에 도달하는 시간
    - 1MSL: 만약 ACK이 손실되어 FIN이 재전송되는 경우의 시간
  - **Linux 기본값**: 60초 (`net.ipv4.tcp_fin_timeout`)

  **TIME_WAIT 상태의 문제점과 해결책**

  **1. 포트 고갈 문제**
  - **원인**: 클라이언트가 많은 연결을 생성/종료할 때 TIME_WAIT 소켓이 포트 점유
  - **증상**: "Cannot assign requested address" 에러
  - **해결책**:
    - `SO_REUSEADDR` 소켓 옵션 사용
    - `net.ipv4.tcp_tw_reuse` 커널 파라미터 활성화
    - 연결 풀링으로 연결 재사용
    - 클라이언트 포트 범위 확장

  **2. 메모리 사용량**
  - **문제**: 대량의 TIME_WAIT 소켓이 메모리 점유
  - **모니터링**: `ss -tan state time-wait | wc -l`
  - **최적화**: `net.ipv4.tcp_max_tw_buckets` 조정

  **비정상 종료 시나리오**

  **1. RST (Reset) 세그먼트**
  - **발생 상황**:
    - 존재하지 않는 포트로 연결 시도
    - 이미 닫힌 소켓에 데이터 전송
    - 애플리케이션 강제 종료 (`kill -9`)
  - **특징**: 4-way handshake 없이 즉시 연결 종료
  - **상태 전이**: 어떤 상태에서든 → CLOSED

  **2. 타임아웃 종료**
  - **Keep-Alive 타임아웃**: 일정 시간 비활성 상태 시 연결 종료
  - **재전송 타임아웃**: 세그먼트 재전송 한계 초과 시 연결 종료
  - **사용자 타임아웃**: 애플리케이션 레벨 타임아웃

  **성능 최적화 및 튜닝**

  **1. 커널 파라미터 튜닝**
  ```
  # TIME_WAIT 재사용 활성화
  net.ipv4.tcp_tw_reuse = 1

  # TIME_WAIT 타임아웃 단축 (주의: RFC 위반)
  net.ipv4.tcp_fin_timeout = 30

  # TIME_WAIT 소켓 최대 개수
  net.ipv4.tcp_max_tw_buckets = 32768

  # Keep-Alive 설정
  net.ipv4.tcp_keepalive_time = 600
  net.ipv4.tcp_keepalive_probes = 3
  net.ipv4.tcp_keepalive_intvl = 60
  ```

  **2. 애플리케이션 레벨 최적화**
  - **연결 풀링**: 연결 재사용으로 종료 빈도 감소
  - **적절한 타임아웃**: 너무 짧거나 긴 타임아웃 방지
  - **우아한 종료**: `shutdown()` 후 `close()` 호출
  - **에러 처리**: 연결 오류 시 적절한 정리 작업

  **모니터링 및 디버깅**

  **1. 연결 상태 모니터링**
  ```bash
  # 상태별 연결 수 확인
  ss -tan | awk '{print $1}' | sort | uniq -c

  # TIME_WAIT 연결 수
  ss -tan state time-wait | wc -l

  # 특정 포트의 연결 상태
  ss -tan sport :80
  ```

  **2. 네트워크 패킷 분석**
  - **tcpdump**: 실제 FIN/ACK 패킷 캡처
  - **Wireshark**: GUI 기반 패킷 분석
  - **netstat**: 연결 상태 및 통계 확인

  **3. 애플리케이션 로그 분석**
  - **연결 생성/종료 로그**: 비정상적인 패턴 감지
  - **에러 로그**: 연결 종료 관련 오류 추적
  - **성능 메트릭**: 연결 지속 시간, 처리량 모니터링

  **실제 운영 환경 고려사항**

  **1. 로드 밸런서 환경**
  - **Connection Draining**: 서버 종료 시 기존 연결의 우아한 처리
  - **Health Check**: 연결 상태 기반 트래픽 라우팅
  - **Session Affinity**: 연결 유지 중 동일 서버 라우팅

  **2. 마이크로서비스 환경**
  - **Circuit Breaker**: 연결 실패 시 빠른 실패 처리
  - **Retry Logic**: 연결 종료 시 재시도 전략
  - **Service Mesh**: 연결 관리 추상화

  **3. 컨테이너 환경**
  - **Graceful Shutdown**: SIGTERM 신호 처리
  - **Init Process**: 좀비 프로세스 방지
  - **Resource Limits**: 연결 수 제한 설정

- **HTTP over TCP 이유 & 단점, HTTP/3 with UDP**

  **HTTP over TCP 선택 이유 심화 분석**

  **핵심 요구사항**
  - **신뢰성(Reliability)**: 웹 페이지, 이미지, 문서 등의 **완전한 전송** 보장 필요
  - **순서 보장(Ordering)**: HTML, CSS, JavaScript 등의 **정확한 순서** 유지 필요
  - **오류 복구(Error Recovery)**: 네트워크 오류 시 **자동 재전송** 메커니즘 필요
  - **플랫폼 독립성**: 다양한 운영체제와 네트워크 환경에서 **일관된 동작** 보장

  **TCP의 핵심 장점**

  **1. 신뢰성 보장 메커니즘**
  - **확인 응답(ACK)**: 모든 데이터 세그먼트에 대한 수신 확인
  - **재전송 메커니즘**: 손실된 패킷의 자동 재전송
  - **체크섬 검증**: 데이터 무결성 검사
  - **중복 제거**: 중복된 패킷 자동 제거
  - **순서 재정렬**: 순서가 바뀐 패킷의 올바른 재배열

  **2. 흐름 제어(Flow Control)**
  - **슬라이딩 윈도우**: 수신자의 처리 능력에 맞춘 전송 속도 조절
  - **윈도우 크기 조정**: 수신 버퍼 상태에 따른 동적 조정
  - **백프레셔(Backpressure)**: 수신자 과부하 방지
  - **버퍼 오버플로우 방지**: 메모리 보호

  **3. 혼잡 제어(Congestion Control)**
  - **슬로우 스타트**: 네트워크 상태 파악을 위한 점진적 속도 증가
  - **혼잡 회피**: 네트워크 혼잡 감지 시 전송 속도 감소
  - **빠른 재전송**: 중복 ACK 감지 시 즉시 재전송
  - **빠른 복구**: 혼잡 상황에서의 효율적 복구

  **TCP의 주요 단점 및 성능 제약**

  **1. 연결 설정 오버헤드**
  - **3-Way Handshake 지연**: 최소 1.5 RTT 소요
    ```
    클라이언트 → 서버: SYN (0.5 RTT)
    서버 → 클라이언트: SYN-ACK (1.0 RTT)
    클라이언트 → 서버: ACK (1.5 RTT)
    ```
  - **연결당 상태 유지**: 서버 메모리 사용량 증가
  - **동시 연결 제한**: 파일 디스크립터 한계
  - **연결 재사용 복잡성**: Keep-Alive 관리 부담

  **2. Head-of-Line (HOL) Blocking**
  - **TCP 레벨 HOL Blocking**: 
    - 하나의 패킷 손실이 전체 스트림 지연 야기
    - 순서 보장으로 인한 후속 패킷 대기
    - 애플리케이션 레벨에서 해결 불가
  - **HTTP/1.1의 추가적 HOL Blocking**:
    - 파이프라이닝에서 첫 번째 요청 지연 시 전체 지연
    - 연결당 순차 처리 강제

  **3. 프로토콜 오버헤드**
  - **TCP 헤더**: 최소 20바이트 (옵션 포함 시 최대 60바이트)
  - **IP 헤더**: 20바이트 (IPv4) 또는 40바이트 (IPv6)
  - **총 오버헤드**: 최소 40바이트 (IPv4), 60바이트 (IPv6)
  - **작은 메시지의 비효율성**: 헤더가 페이로드보다 큰 경우

  **4. 커널 공간 처리**
  - **시스템 콜 오버헤드**: 사용자-커널 공간 전환 비용
  - **컨텍스트 스위칭**: 블로킹 I/O로 인한 스레드 전환
  - **버퍼 복사**: 커널-사용자 공간 간 데이터 복사
  - **인터럽트 처리**: 네트워크 인터럽트 처리 오버헤드

  **HTTP/3과 QUIC 프로토콜 혁신**

  **QUIC (Quick UDP Internet Connections) 핵심 개념**
  - **정의**: **UDP 기반**의 **사용자 공간** 구현 전송 프로토콜
  - **목표**: TCP의 신뢰성을 유지하면서 성능 제약 해결
  - **설계 철학**: **연결 지향적 UDP**로 TCP의 장점과 UDP의 효율성 결합

  **QUIC의 혁신적 특징**

  **1. 0-RTT 연결 설정**
  - **초기 연결**: 1-RTT로 TLS 핸드셰이크와 연결 설정 동시 수행
  - **연결 재개**: 이전 세션 정보로 0-RTT 데이터 전송
  - **성능 향상**: TCP+TLS 대비 최대 2-RTT 절약
  - **구현 메커니즘**:
    ```
    클라이언트 → 서버: Initial + 0-RTT Data
    서버 → 클라이언트: Initial + Handshake + 1-RTT Data
    ```

  **2. 스트림 기반 멀티플렉싱**
  - **독립적 스트림**: 각 HTTP 요청이 독립적인 QUIC 스트림
  - **스트림별 흐름 제어**: 개별 스트림의 독립적 속도 조절
  - **HOL Blocking 해결**: 하나의 스트림 지연이 다른 스트림에 영향 없음
  - **우선순위 제어**: 스트림별 중요도에 따른 대역폭 할당

  **3. 사용자 공간 구현**
  - **커널 바이패스**: 시스템 콜 오버헤드 최소화
  - **빠른 반복 개발**: 커널 업데이트 없이 프로토콜 개선 가능
  - **애플리케이션 최적화**: 특정 용도에 맞춘 최적화 가능
  - **크로스 플랫폼**: 운영체제 독립적 구현

  **4. 연결 마이그레이션**
  - **Connection ID**: IP 주소 변경에도 연결 유지
  - **모바일 최적화**: WiFi ↔ 셀룰러 전환 시 연결 유지
  - **로드 밸런싱**: 서버 간 연결 이동 지원
  - **NAT 리바인딩**: NAT 환경에서의 연결 안정성

  **5. 향상된 보안**
  - **기본 암호화**: 모든 QUIC 연결이 TLS 1.3 기반 암호화
  - **헤더 보호**: 패킷 헤더 정보 암호화
  - **연결 ID 암호화**: 연결 추적 방지
  - **Forward Secrecy**: 모든 연결에서 완전 순방향 보안

  **성능 비교 분석**

  **연결 설정 시간**
  - **HTTP/1.1 over TCP+TLS**: 3-4 RTT
    - TCP 3-way handshake: 1.5 RTT
    - TLS handshake: 1-2 RTT
  - **HTTP/2 over TCP+TLS**: 3-4 RTT (동일)
  - **HTTP/3 over QUIC**: 0-1 RTT
    - 초기 연결: 1 RTT
    - 재연결: 0 RTT

  **처리량 및 지연시간**
  - **TCP**: 패킷 손실 시 전체 스트림 지연
  - **QUIC**: 패킷 손실 시 해당 스트림만 지연
  - **실제 성능**: 패킷 손실률 1% 환경에서 QUIC이 30% 빠름

  **메모리 사용량**
  - **TCP**: 커널 버퍼 + 소켓 상태
  - **QUIC**: 사용자 공간 버퍼 (더 효율적 관리 가능)

  **HTTP/3 프로토콜 스택**
  ```
  HTTP/3 Application
  ├── QPACK (Header Compression)
  ├── QUIC Transport
  │   ├── Stream Management
  │   ├── Flow Control
  │   ├── Congestion Control
  │   └── Loss Recovery
  ├── QUIC-TLS (Integrated Security)
  └── UDP (Unreliable Transport)
  ```

  **실제 배포 현황 및 도전과제**

  **1. 브라우저 지원**
  - **Chrome**: 2020년부터 기본 지원
  - **Firefox**: 2021년부터 지원
  - **Safari**: 2022년부터 지원
  - **Edge**: Chromium 기반으로 지원

  **2. 서버 지원**
  - **CDN**: Cloudflare, Fastly, AWS CloudFront
  - **웹 서버**: nginx (1.16+), Apache (실험적)
  - **로드 밸런서**: HAProxy, Envoy

  **3. 네트워크 인프라 도전과제**
  - **UDP 차단**: 일부 기업 방화벽에서 UDP 트래픽 차단
  - **NAT/방화벽 호환성**: UDP 기반 프로토콜의 NAT 통과 문제
  - **QoS 정책**: 기존 TCP 기반 QoS 정책과의 호환성
  - **모니터링 도구**: 기존 TCP 모니터링 도구의 QUIC 지원 부족

  **4. 운영 복잡성**
  - **디버깅 어려움**: 사용자 공간 구현으로 인한 디버깅 복잡성
  - **성능 튜닝**: 새로운 매개변수와 최적화 기법 학습 필요
  - **호환성 관리**: HTTP/1.1, HTTP/2와의 호환성 유지

  **마이그레이션 전략**

  **1. 점진적 도입**
  - **Alt-Svc 헤더**: HTTP/2에서 HTTP/3 지원 알림
  - **자동 폴백**: QUIC 연결 실패 시 TCP로 자동 전환
  - **A/B 테스트**: 일부 트래픽에 대해서만 HTTP/3 적용

  **2. 성능 모니터링**
  - **연결 성공률**: QUIC 연결 성공/실패 비율
  - **지연시간 개선**: TCP 대비 응답 시간 개선 정도
  - **오류율**: 프로토콜 전환으로 인한 오류 발생률

  **3. 인프라 준비**
  - **로드 밸런서 업그레이드**: QUIC 지원 로드 밸런서 도입
  - **모니터링 도구**: QUIC 트래픽 모니터링 도구 구축
  - **보안 정책**: UDP 기반 트래픽에 대한 보안 정책 수립

  **미래 전망**
  - **HTTP/3 표준화**: RFC 9114 (2022년 6월 표준화 완료)
  - **광범위한 채택**: 주요 웹사이트들의 HTTP/3 도입 가속화
  - **IoT 적용**: 저지연이 중요한 IoT 환경에서의 활용
  - **실시간 통신**: WebRTC, 게임, 스트리밍 서비스에서의 활용 확대

- **HTTP/2.0 주요 특징 (예: 헤더 압축)**
  - **HPACK**: 이전 헤더 기반 차등 압축
  - 그 외: 멀티플렉싱, 서버 푸시, 스트림 우선순위

- **웹 개발자가 주로 사용하는 OSI 5계층**
  1. **응용 계층**: HTTP 등
  2. **표현 계층**: 데이터 인코딩/압축(CSRF, TLS 제외)
  3. **세션 계층**: 세션 관리(쿠키, 세션ID)
  4. **전송 계층**: TCP/UDP
  5. **네트워크 계층**: IP 라우팅

- **IEEE 802.11 스펙 계층**
  - **물리 계층(1)**: 무선 전송 규격, 변조 방식
  - **데이터 링크 계층(2)**: MAC, 프레임 구조, CSMA/CA

- **쿠키 vs 세션**
  - **쿠키**: 클라이언트 저장, 만료 시간 설정 가능, 보안 취약
  - **세션**: 서버 저장, 브라우저 종료 시 소멸, 비교적 안전

- **SameSite 쿠키**
  - **Strict**: 동일 사이트 내 요청에만 전송
  - **Lax**: 상위 내비게이션 GET 요청에 허용
  - **None**: 모든 도메인 전송 (Secure 필수)

- **CORS (Cross-Origin Resource Sharing) 심화 분석**

  **CORS 핵심 개념**
  - **정의**: 웹 브라우저에서 **다른 도메인의 리소스**에 접근할 때 적용되는 **보안 정책**
  - **Same-Origin Policy**: 브라우저의 기본 보안 모델로, 동일한 출처(프로토콜, 도메인, 포트)에서만 리소스 접근 허용
  - **CORS의 목적**: Same-Origin Policy의 제약을 **안전하게 완화**하여 필요한 경우 크로스 도메인 요청 허용

  **Origin 정의 및 판별**
  ```
  Origin = Protocol + Domain + Port

  예시:
  - https://example.com:443/api/users
  - https://api.example.com:443/data
  - http://localhost:3000/app

  Same Origin 판별:
  - https://example.com:443 ↔ https://example.com:443 ✓ (동일)
  - https://example.com:443 ↔ http://example.com:80 ✗ (프로토콜, 포트 다름)
  - https://example.com:443 ↔ https://api.example.com:443 ✗ (서브도메인 다름)
  ```

  **CORS 동작 메커니즘**

  **1. Simple Request (단순 요청)**

  **조건**:
  - **HTTP 메서드**: GET, HEAD, POST 중 하나
  - **허용된 헤더만 사용**: Accept, Accept-Language, Content-Language, Content-Type
  - **Content-Type 제한**: application/x-www-form-urlencoded, multipart/form-data, text/plain

  **동작 과정**:
  ```
  1. 브라우저 → 서버: 실제 요청 전송 (Origin 헤더 포함)
     GET /api/data HTTP/1.1
     Host: api.example.com
     Origin: https://webapp.com

  2. 서버 → 브라우저: 응답 (CORS 헤더 포함)
     HTTP/1.1 200 OK
     Access-Control-Allow-Origin: https://webapp.com
     Content-Type: application/json

  3. 브라우저: CORS 헤더 검증 후 응답 처리
  ```

  **2. Preflight Request (사전 요청)**

  **발생 조건**:
  - **HTTP 메서드**: PUT, DELETE, PATCH 등
  - **커스텀 헤더**: Authorization, X-Requested-With 등
  - **Content-Type**: application/json, application/xml 등

  **동작 과정**:
  ```
  1. 브라우저 → 서버: OPTIONS 사전 요청
     OPTIONS /api/users HTTP/1.1
     Host: api.example.com
     Origin: https://webapp.com
     Access-Control-Request-Method: POST
     Access-Control-Request-Headers: Content-Type, Authorization

  2. 서버 → 브라우저: 사전 요청 응답
     HTTP/1.1 200 OK
     Access-Control-Allow-Origin: https://webapp.com
     Access-Control-Allow-Methods: GET, POST, PUT, DELETE
     Access-Control-Allow-Headers: Content-Type, Authorization
     Access-Control-Max-Age: 86400

  3. 브라우저: 사전 요청 승인 시 실제 요청 전송
     POST /api/users HTTP/1.1
     Host: api.example.com
     Origin: https://webapp.com
     Content-Type: application/json
     Authorization: Bearer token123

  4. 서버 → 브라우저: 실제 응답
     HTTP/1.1 201 Created
     Access-Control-Allow-Origin: https://webapp.com
  ```

  **CORS 헤더 상세 분석**

  **1. 응답 헤더 (서버 → 브라우저)**

  **Access-Control-Allow-Origin**
  - **목적**: 허용된 Origin 지정
  - **값**:
    - `*`: 모든 Origin 허용 (credentials 사용 불가)
    - `https://example.com`: 특정 Origin만 허용
    - `null`: Origin 없는 요청 허용 (보안 위험)
  - **동적 설정**: 요청의 Origin 헤더를 검증 후 동적으로 설정

  **Access-Control-Allow-Methods**
  - **목적**: 허용된 HTTP 메서드 지정
  - **예시**: `GET, POST, PUT, DELETE, OPTIONS`
  - **기본값**: Simple Request 메서드는 항상 허용

  **Access-Control-Allow-Headers**
  - **목적**: 허용된 요청 헤더 지정
  - **예시**: `Content-Type, Authorization, X-Requested-With`
  - **대소문자 무관**: 헤더 이름은 대소문자 구분 없음

  **Access-Control-Allow-Credentials**
  - **목적**: 쿠키, 인증 헤더 포함 요청 허용 여부
  - **값**: `true` (허용) 또는 생략 (불허용)
  - **제약**: `true` 설정 시 `Access-Control-Allow-Origin`에 `*` 사용 불가

  **Access-Control-Max-Age**
  - **목적**: Preflight 응답 캐시 시간 (초 단위)
  - **예시**: `86400` (24시간)
  - **효과**: 동일한 요청에 대한 Preflight 요청 생략

  **Access-Control-Expose-Headers**
  - **목적**: JavaScript에서 접근 가능한 응답 헤더 지정
  - **기본 노출 헤더**: Cache-Control, Content-Language, Content-Type, Expires, Last-Modified, Pragma
  - **예시**: `X-Total-Count, X-Page-Number`

  **2. 요청 헤더 (브라우저 → 서버)**

  **Origin**
  - **자동 추가**: 브라우저가 자동으로 추가
  - **값**: 요청을 보내는 페이지의 Origin
  - **보안**: JavaScript로 수정 불가

  **Access-Control-Request-Method**
  - **Preflight 전용**: 실제 요청에서 사용할 HTTP 메서드
  - **예시**: `POST`, `PUT`, `DELETE`

  **Access-Control-Request-Headers**
  - **Preflight 전용**: 실제 요청에서 사용할 커스텀 헤더 목록
  - **예시**: `Content-Type, Authorization`

  **CORS 해결 방법 심화**

  **1. 서버 측 헤더 설정**

  **정적 설정**
  ```javascript
  // Express.js 예시
  app.use((req, res, next) => {
    res.header('Access-Control-Allow-Origin', 'https://trusted-domain.com');
    res.header('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS');
    res.header('Access-Control-Allow-Headers', 'Content-Type, Authorization');
    res.header('Access-Control-Allow-Credentials', 'true');
    res.header('Access-Control-Max-Age', '86400');

    if (req.method === 'OPTIONS') {
      res.sendStatus(200);
    } else {
      next();
    }
  });
  ```

  **동적 설정**
  ```javascript
  // Origin 화이트리스트 기반 동적 설정
  const allowedOrigins = [
    'https://webapp.com',
    'https://admin.webapp.com',
    'http://localhost:3000'
  ];

  app.use((req, res, next) => {
    const origin = req.headers.origin;
    if (allowedOrigins.includes(origin)) {
      res.header('Access-Control-Allow-Origin', origin);
    }
    res.header('Access-Control-Allow-Credentials', 'true');
    next();
  });
  ```

  **2. Spring Boot 설정**

  **어노테이션 기반**
  ```java
  @RestController
  @CrossOrigin(
    origins = {"https://webapp.com", "http://localhost:3000"},
    methods = {RequestMethod.GET, RequestMethod.POST},
    allowedHeaders = {"Content-Type", "Authorization"},
    allowCredentials = "true",
    maxAge = 3600
  )
  public class ApiController {

    @GetMapping("/api/data")
    public ResponseEntity<Data> getData() {
      return ResponseEntity.ok(data);
    }
  }
  ```

  **글로벌 설정**
  ```java
  @Configuration
  public class CorsConfig implements WebMvcConfigurer {

    @Override
    public void addCorsMappings(CorsRegistry registry) {
      registry.addMapping("/api/**")
        .allowedOriginPatterns("https://*.webapp.com", "http://localhost:*")
        .allowedMethods("GET", "POST", "PUT", "DELETE", "OPTIONS")
        .allowedHeaders("*")
        .allowCredentials(true)
        .maxAge(3600);
    }
  }
  ```

  **필터 기반 설정**
  ```java
  @Component
  public class CorsFilter implements Filter {

    @Override
    public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) 
        throws IOException, ServletException {

      HttpServletRequest request = (HttpServletRequest) req;
      HttpServletResponse response = (HttpServletResponse) res;

      String origin = request.getHeader("Origin");
      if (isAllowedOrigin(origin)) {
        response.setHeader("Access-Control-Allow-Origin", origin);
        response.setHeader("Access-Control-Allow-Credentials", "true");
        response.setHeader("Access-Control-Allow-Methods", "GET, POST, PUT, DELETE, OPTIONS");
        response.setHeader("Access-Control-Allow-Headers", "Content-Type, Authorization");
        response.setHeader("Access-Control-Max-Age", "3600");
      }

      if ("OPTIONS".equalsIgnoreCase(request.getMethod())) {
        response.setStatus(HttpServletResponse.SC_OK);
      } else {
        chain.doFilter(req, res);
      }
    }
  }
  ```

  **3. 프록시 서버 활용**

  **개발 환경 프록시**
  ```javascript
  // webpack.config.js
  module.exports = {
    devServer: {
      proxy: {
        '/api': {
          target: 'https://api.example.com',
          changeOrigin: true,
          secure: true,
          pathRewrite: {
            '^/api': ''
          }
        }
      }
    }
  };
  ```

  **Nginx 프록시**
  ```nginx
  server {
    listen 80;
    server_name webapp.com;

    location /api/ {
      proxy_pass https://api.example.com/;
      proxy_set_header Host $host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $scheme;

      # CORS 헤더 추가
      add_header Access-Control-Allow-Origin https://webapp.com always;
      add_header Access-Control-Allow-Methods "GET, POST, PUT, DELETE, OPTIONS" always;
      add_header Access-Control-Allow-Headers "Content-Type, Authorization" always;
      add_header Access-Control-Allow-Credentials true always;

      if ($request_method = 'OPTIONS') {
        return 204;
      }
    }
  }
  ```

  **4. 클라이언트 측 구현**

  **Fetch API with Credentials**
  ```javascript
  fetch('https://api.example.com/data', {
    method: 'POST',
    credentials: 'include', // 쿠키 포함
    headers: {
      'Content-Type': 'application/json',
      'Authorization': 'Bearer ' + token
    },
    body: JSON.stringify(data)
  })
  .then(response => {
    if (!response.ok) {
      throw new Error('CORS error or network error');
    }
    return response.json();
  })
  .catch(error => {
    console.error('CORS Error:', error);
  });
  ```

  **XMLHttpRequest with CORS**
  ```javascript
  const xhr = new XMLHttpRequest();
  xhr.withCredentials = true; // 쿠키 포함
  xhr.open('POST', 'https://api.example.com/data');
  xhr.setRequestHeader('Content-Type', 'application/json');
  xhr.setRequestHeader('Authorization', 'Bearer ' + token);

  xhr.onreadystatechange = function() {
    if (xhr.readyState === 4) {
      if (xhr.status === 200) {
        console.log(xhr.responseText);
      } else {
        console.error('CORS Error:', xhr.status);
      }
    }
  };

  xhr.send(JSON.stringify(data));
  ```

  **보안 고려사항**

  **1. Origin 검증**
  - **화이트리스트 방식**: 허용된 Origin만 명시적으로 지정
  - **와일드카드 주의**: `*` 사용 시 모든 도메인에서 접근 가능
  - **동적 검증**: 요청 시점에 Origin 유효성 검사

  **2. Credentials 처리**
  - **최소 권한 원칙**: 필요한 경우에만 `allowCredentials: true` 설정
  - **HTTPS 강제**: 인증 정보 전송 시 HTTPS 사용 필수
  - **토큰 기반 인증**: 쿠키 대신 JWT 등 토큰 기반 인증 권장

  **3. 헤더 노출 제한**
  - **필요한 헤더만 노출**: `Access-Control-Expose-Headers`로 최소한의 헤더만 노출
  - **민감 정보 보호**: 인증 토큰, 세션 ID 등 민감 정보 헤더 노출 금지

  **디버깅 및 문제 해결**

  **1. 브라우저 개발자 도구**
  - **Network 탭**: CORS 관련 요청/응답 헤더 확인
  - **Console 탭**: CORS 오류 메시지 확인
  - **CORS 오류 유형**:
    - `Access to fetch at '...' from origin '...' has been blocked by CORS policy`
    - `Response to preflight request doesn't pass access control check`

  **2. 일반적인 CORS 오류**
  - **Origin 불일치**: 서버에서 허용하지 않은 Origin에서 요청
  - **Method 불허용**: Preflight에서 요청 메서드가 허용되지 않음
  - **Header 불허용**: 커스텀 헤더가 허용되지 않음
  - **Credentials 설정 오류**: `allowCredentials`와 `allowOrigin: *` 동시 사용

  **3. 테스트 도구**
  ```bash
  # curl을 이용한 CORS 테스트
  curl -H "Origin: https://webapp.com" \
       -H "Access-Control-Request-Method: POST" \
       -H "Access-Control-Request-Headers: Content-Type" \
       -X OPTIONS \
       https://api.example.com/data
  ```

  **성능 최적화**

  **1. Preflight 캐싱**
  - **Max-Age 설정**: 적절한 캐시 시간 설정으로 Preflight 요청 최소화
  - **헤더 최적화**: 불필요한 커스텀 헤더 사용 지양

  **2. Simple Request 활용**
  - **Content-Type 제한**: 가능한 경우 Simple Request 조건 만족
  - **HTTP 메서드 최적화**: GET, POST 우선 사용

  **실제 운영 환경 고려사항**
  - **CDN 설정**: CloudFront, CloudFlare 등에서 CORS 헤더 설정
  - **로드 밸런서**: ALB, NLB에서 CORS 헤더 처리
  - **API Gateway**: AWS API Gateway, Kong 등에서 CORS 정책 설정
  - **모니터링**: CORS 관련 오류 로그 수집 및 분석

- **HTTP 메시지 첫 줄 (HTTP Message Start Line) 심화 분석**

  **HTTP 메시지 구조 개요**
  - **정의**: HTTP 메시지의 **첫 번째 라인**으로, 요청의 의도나 응답의 상태를 나타내는 **핵심 정보**를 포함
  - **구성**: HTTP 메시지는 Start Line + Headers + Empty Line + Message Body로 구성
  - **파싱 중요성**: 웹 서버와 클라이언트가 통신을 위해 **가장 먼저 해석**하는 부분
  - **프로토콜 호환성**: HTTP/1.0, HTTP/1.1, HTTP/2, HTTP/3 간 호환성 보장

  **요청 라인 (Request Line) 상세 분석**

  **구문 구조**
  ```
  METHOD SP Request-URI SP HTTP-Version CRLF

  구성 요소:
  - METHOD: HTTP 메서드 (GET, POST, PUT, DELETE 등)
  - SP: 공백 문자 (Space, 0x20)
  - Request-URI: 요청 대상 리소스의 URI
  - HTTP-Version: 사용할 HTTP 프로토콜 버전
  - CRLF: 줄바꿈 문자 (Carriage Return + Line Feed, \r\n)
  ```

  **HTTP 메서드 심화**

  **1. 안전한 메서드 (Safe Methods)**
  - **GET**: 리소스 조회, 서버 상태 변경 없음
    - **캐싱 가능**: 브라우저와 프록시에서 응답 캐싱
    - **멱등성**: 동일한 요청의 반복 실행이 같은 결과
    - **URL 길이 제한**: 브라우저별 URL 길이 제한 (IE: 2083자, Chrome: 8192자)
  - **HEAD**: GET과 동일하지만 응답 본문 없이 헤더만 반환
    - **용도**: 리소스 존재 확인, 메타데이터 조회, 캐시 검증
    - **성능**: 대용량 파일의 메타정보만 필요할 때 효율적
  - **OPTIONS**: 서버가 지원하는 메서드 조회
    - **CORS Preflight**: 크로스 도메인 요청 전 사전 검사
    - **Allow 헤더**: 지원하는 메서드 목록 반환

  **2. 비안전한 메서드 (Unsafe Methods)**
  - **POST**: 리소스 생성, 데이터 처리
    - **비멱등성**: 동일 요청 반복 시 다른 결과 가능
    - **본문 데이터**: 요청 본문에 데이터 포함 가능
    - **용도**: 폼 제출, 파일 업로드, 데이터 생성
  - **PUT**: 리소스 생성 또는 전체 교체
    - **멱등성**: 동일 요청 반복 시 같은 결과
    - **전체 교체**: 기존 리소스를 완전히 대체
  - **PATCH**: 리소스 부분 수정
    - **부분 업데이트**: 리소스의 일부만 수정
    - **JSON Patch**: RFC 6902 표준 패치 형식
  - **DELETE**: 리소스 삭제
    - **멱등성**: 이미 삭제된 리소스 재삭제 시도도 같은 결과

  **Request-URI 구성 요소**

  **1. 절대 URI (Absolute URI)**
  ```
  https://example.com:8080/api/users/123?filter=active&sort=name#section1

  구성:
  - 스키마: https
  - 호스트: example.com
  - 포트: 8080 (생략 시 기본 포트)
  - 경로: /api/users/123
  - 쿼리: filter=active&sort=name
  - 프래그먼트: section1 (서버로 전송되지 않음)
  ```

  **2. 상대 URI (Relative URI)**
  ```
  /api/users/123?filter=active

  특징:
  - 호스트 정보 생략
  - Host 헤더로 호스트 정보 제공
  - HTTP/1.1에서 Host 헤더 필수
  ```

  **3. 특수 URI 형태**
  - **asterisk-form**: `OPTIONS * HTTP/1.1` (서버 전체 옵션 조회)
  - **authority-form**: `CONNECT example.com:443 HTTP/1.1` (터널링)
  - **origin-form**: `/path/to/resource` (일반적인 형태)

  **HTTP 버전 호환성**

  **1. HTTP/1.0**
  - **연결 모델**: 요청-응답 후 연결 종료
  - **Host 헤더**: 선택적 (가상 호스팅 제한)
  - **캐싱**: 기본적인 캐싱 지원

  **2. HTTP/1.1**
  - **지속 연결**: Keep-Alive 기본 활성화
  - **Host 헤더**: 필수 (가상 호스팅 지원)
  - **청크 전송**: Transfer-Encoding: chunked
  - **파이프라이닝**: 여러 요청 동시 전송 (실제로는 잘 사용되지 않음)

  **3. HTTP/2**
  - **바이너리 프로토콜**: 텍스트 기반에서 바이너리로 변경
  - **멀티플렉싱**: 단일 연결에서 여러 스트림 동시 처리
  - **헤더 압축**: HPACK 알고리즘 사용

  **응답 라인 (Status Line) 상세 분석**

  **구문 구조**
  ```
  HTTP-Version SP Status-Code SP Reason-Phrase CRLF

  예시:
  HTTP/1.1 200 OK
  HTTP/1.1 404 Not Found
  HTTP/1.1 500 Internal Server Error
  ```

  **상태 코드 분류 및 심화**

  **1xx: 정보성 응답 (Informational)**
  - **100 Continue**: 클라이언트가 요청 본문 전송 계속 진행
    - **Expect: 100-continue**: 대용량 데이터 전송 전 서버 확인
    - **사용 사례**: 파일 업로드, 대용량 POST 요청
  - **101 Switching Protocols**: 프로토콜 전환
    - **WebSocket 업그레이드**: HTTP에서 WebSocket으로 전환
    - **HTTP/2 업그레이드**: HTTP/1.1에서 HTTP/2로 전환

  **2xx: 성공 (Success)**
  - **200 OK**: 요청 성공
    - **GET**: 리소스 조회 성공
    - **POST**: 데이터 처리 성공
  - **201 Created**: 리소스 생성 성공
    - **Location 헤더**: 생성된 리소스 위치
    - **POST, PUT**: 새 리소스 생성 시
  - **202 Accepted**: 요청 접수, 처리 중
    - **비동기 처리**: 백그라운드 작업 시작
    - **배치 작업**: 시간이 오래 걸리는 작업
  - **204 No Content**: 성공, 응답 본문 없음
    - **DELETE**: 삭제 성공
    - **PUT**: 업데이트 성공, 반환할 내용 없음

  **3xx: 리다이렉션 (Redirection)**
  - **301 Moved Permanently**: 영구 이동
    - **SEO**: 검색 엔진이 새 URL로 인덱싱
    - **캐싱**: 브라우저가 리다이렉션 캐싱
  - **302 Found**: 임시 이동
    - **일시적 리다이렉션**: 원본 URL 유지
    - **로그인 후 리다이렉션**: 인증 후 원래 페이지로
  - **304 Not Modified**: 캐시된 버전 사용
    - **조건부 요청**: If-Modified-Since, If-None-Match
    - **대역폭 절약**: 변경되지 않은 리소스 재전송 방지

  **4xx: 클라이언트 오류 (Client Error)**
  - **400 Bad Request**: 잘못된 요청 구문
    - **JSON 파싱 오류**: 잘못된 JSON 형식
    - **필수 매개변수 누락**: API 요청 시 필수 필드 부재
  - **401 Unauthorized**: 인증 필요
    - **WWW-Authenticate 헤더**: 인증 방법 명시
    - **Bearer 토큰**: JWT, OAuth 토큰 인증
  - **403 Forbidden**: 권한 부족
    - **인증은 성공**: 사용자 식별 완료
    - **권한 부족**: 해당 리소스 접근 권한 없음
  - **404 Not Found**: 리소스 없음
    - **존재하지 않는 경로**: URL 경로 오류
    - **삭제된 리소스**: 이미 삭제된 리소스 접근
  - **429 Too Many Requests**: 요청 한도 초과
    - **Rate Limiting**: API 호출 제한
    - **Retry-After 헤더**: 재시도 가능 시간

  **5xx: 서버 오류 (Server Error)**
  - **500 Internal Server Error**: 서버 내부 오류
    - **애플리케이션 오류**: 코드 실행 중 예외
    - **데이터베이스 오류**: DB 연결 실패, 쿼리 오류
  - **502 Bad Gateway**: 게이트웨이 오류
    - **프록시 서버**: 업스트림 서버 응답 오류
    - **로드 밸런서**: 백엔드 서버 연결 실패
  - **503 Service Unavailable**: 서비스 이용 불가
    - **서버 과부하**: 일시적 서버 부하
    - **점검 중**: 서버 유지보수
  - **504 Gateway Timeout**: 게이트웨이 타임아웃
    - **업스트림 타임아웃**: 백엔드 서버 응답 지연
    - **프록시 타임아웃**: 설정된 시간 내 응답 없음

  **파싱 및 검증 고려사항**

  **1. 구문 검증**
  - **공백 문자 검증**: SP는 정확히 하나의 공백 문자
  - **CRLF 처리**: Windows(\r\n), Unix(\n), Mac(\r) 호환성
  - **대소문자 처리**: 메서드는 대소문자 구분, URI는 서버 구현에 따라 다름

  **2. 보안 고려사항**
  - **HTTP 메서드 제한**: 불필요한 메서드 비활성화
  - **URI 길이 제한**: DoS 공격 방지를 위한 길이 제한
  - **특수 문자 처리**: URL 인코딩, 경로 순회 공격 방지
  - **버전 다운그레이드**: 프로토콜 다운그레이드 공격 방지

  **3. 성능 최적화**
  - **메서드별 캐싱**: GET, HEAD는 캐싱 가능
  - **조건부 요청**: 304 응답으로 대역폭 절약
  - **압축**: gzip, deflate 등 응답 압축
  - **Keep-Alive**: 연결 재사용으로 오버헤드 감소

  **실제 구현 예시**

  **1. 웹 서버 파싱**
  ```
  요청 라인 파싱 과정:
  1. 첫 번째 공백까지 → HTTP 메서드 추출
  2. 두 번째 공백까지 → Request-URI 추출
  3. CRLF까지 → HTTP 버전 추출
  4. 각 구성 요소 유효성 검증
  5. 지원하지 않는 메서드/버전 시 오류 응답
  ```

  **2. 클라이언트 구현**
  ```
  응답 라인 파싱 과정:
  1. 첫 번째 공백까지 → HTTP 버전 추출
  2. 두 번째 공백까지 → 상태 코드 추출
  3. CRLF까지 → Reason Phrase 추출
  4. 상태 코드에 따른 후속 처리 결정
  ```

  **디버깅 및 모니터링**
  - **로그 분석**: 요청/응답 라인 로깅으로 트래픽 패턴 분석
  - **상태 코드 분포**: 4xx, 5xx 오류율 모니터링
  - **메서드 사용 패턴**: API 사용 현황 분석
  - **프로토콜 버전**: HTTP/1.1, HTTP/2 사용 비율 추적

- **RESTful API (Representational State Transfer) 심화 분석**

  **REST 아키텍처 핵심 개념**
  - **정의**: **자원(Resource)**을 **URI**로 식별하고, **HTTP 메서드**를 통해 자원에 대한 **행위(Action)**를 정의하는 아키텍처 스타일
  - **창시자**: Roy Fielding이 2000년 박사 논문에서 제안
  - **목적**: 웹의 기존 기술과 HTTP 프로토콜을 그대로 활용하여 **확장 가능하고 단순한** 아키텍처 구현
  - **적용 범위**: 웹 서비스, 마이크로서비스, 모바일 API, IoT 통신 등

  **REST 6가지 제약 조건 (Architectural Constraints)**

  **1. 클라이언트-서버 (Client-Server)**
  - **관심사 분리**: UI와 데이터 저장 관심사 분리
  - **독립적 진화**: 클라이언트와 서버가 독립적으로 개발 및 배포 가능
  - **확장성**: 서버 컴포넌트 단순화로 확장성 향상
  - **이식성**: 클라이언트 이식성 향상

  **2. 무상태성 (Stateless)**
  - **세션 상태 없음**: 서버가 클라이언트 상태 정보를 저장하지 않음
  - **요청 완전성**: 각 요청은 처리에 필요한 모든 정보를 포함
  - **확장성**: 서버 간 로드 밸런싱 용이
  - **신뢰성**: 부분적 실패 복구 단순화
  - **구현 예시**:
    ```
    // Stateful (잘못된 예)
    POST /login → 서버에 세션 저장
    GET /profile → 세션 기반 사용자 식별

    // Stateless (올바른 예)
    POST /auth → JWT 토큰 반환
    GET /profile
    Authorization: Bearer eyJhbGciOiJIUzI1NiIs...
    ```

  **3. 캐시 가능성 (Cacheable)**
  - **응답 캐싱**: 응답 데이터에 캐시 가능 여부 명시
  - **성능 향상**: 네트워크 효율성과 확장성 개선
  - **캐시 제어**: Cache-Control, ETag, Last-Modified 헤더 활용
  - **구현 예시**:
    ```
    HTTP/1.1 200 OK
    Cache-Control: public, max-age=3600
    ETag: "33a64df551425fcc55e4d42a148795d9f25f89d4"
    Last-Modified: Wed, 21 Oct 2015 07:28:00 GMT
    ```

  **4. 계층화 시스템 (Layered System)**
  - **중간 계층**: 프록시, 게이트웨이, 방화벽 등 중간 계층 허용
  - **캡슐화**: 클라이언트는 최종 서버와 직접 연결되었는지 알 수 없음
  - **확장성**: 로드 밸런싱, 공유 캐시 등으로 확장성 향상
  - **보안**: 보안 정책 적용 계층 추가 가능

  **5. 코드 온 디맨드 (Code-On-Demand) - 선택적**
  - **실행 코드 전송**: 서버가 클라이언트에 실행 가능한 코드 전송
  - **기능 확장**: 클라이언트 기능을 일시적으로 확장
  - **예시**: JavaScript, Java 애플릿, Flash
  - **선택적 제약**: 유일하게 선택적인 제약 조건

  **6. 통합 인터페이스 (Uniform Interface)**
  - **인터페이스 일관성**: 컴포넌트 간 통합된 인터페이스
  - **4가지 하위 제약**:
    - **자원 식별**: URI를 통한 자원 식별
    - **표현을 통한 자원 조작**: HTTP 메서드로 자원 조작
    - **자기 서술적 메시지**: 메시지만으로 처리 방법 이해 가능
    - **애플리케이션 상태 엔진으로서의 하이퍼미디어 (HATEOAS)**

  **HTTP 메서드별 상세 분석**

  **1. GET - 자원 조회**
  - **특성**: 안전(Safe), 멱등(Idempotent), 캐시 가능
  - **용도**: 데이터 조회, 검색, 필터링
  - **설계 원칙**:
    ```
    GET /users              # 사용자 목록 조회
    GET /users/123          # 특정 사용자 조회
    GET /users/123/orders   # 사용자의 주문 목록
    GET /users?role=admin   # 쿼리 파라미터로 필터링
    ```
  - **응답 코드**: 200 (성공), 404 (없음), 304 (변경 없음)

  **2. POST - 자원 생성**
  - **특성**: 비안전(Unsafe), 비멱등(Non-Idempotent)
  - **용도**: 새 자원 생성, 데이터 처리, 액션 실행
  - **설계 원칙**:
    ```
    POST /users             # 새 사용자 생성
    POST /users/123/orders  # 사용자의 새 주문 생성
    POST /auth/login        # 로그인 처리
    POST /users/123/activate # 사용자 활성화 액션
    ```
  - **응답 코드**: 201 (생성), 200 (처리 완료), 202 (비동기 처리)

  **3. PUT - 자원 생성/전체 교체**
  - **특성**: 비안전(Unsafe), 멱등(Idempotent)
  - **용도**: 자원 전체 교체, 없으면 생성
  - **설계 원칙**:
    ```
    PUT /users/123          # 사용자 123 전체 교체
    PUT /users/123/profile  # 사용자 프로필 전체 교체
    ```
  - **응답 코드**: 200 (교체), 201 (생성), 204 (성공, 본문 없음)

  **4. PATCH - 자원 부분 수정**
  - **특성**: 비안전(Unsafe), 비멱등(일반적으로)
  - **용도**: 자원의 부분적 수정
  - **설계 원칙**:
    ```
    PATCH /users/123        # 사용자 일부 필드 수정
    Content-Type: application/json-patch+json
    [
      {"op": "replace", "path": "/email", "value": "new@example.com"},
      {"op": "add", "path": "/phone", "value": "010-1234-5678"}
    ]
    ```
  - **응답 코드**: 200 (수정 완료), 204 (성공, 본문 없음)

  **5. DELETE - 자원 삭제**
  - **특성**: 비안전(Unsafe), 멱등(Idempotent)
  - **용도**: 자원 삭제
  - **설계 원칙**:
    ```
    DELETE /users/123       # 사용자 123 삭제
    DELETE /users/123/orders/456 # 특정 주문 삭제
    ```
  - **응답 코드**: 200 (삭제 완료), 204 (삭제 완료, 본문 없음), 404 (이미 없음)

  **URI 설계 원칙 및 베스트 프랙티스**

  **1. 자원 중심 설계**
  - **명사 사용**: 동사가 아닌 명사로 자원 표현
    ```
    ✓ GET /users/123
    ✗ GET /getUser/123

    ✓ POST /orders
    ✗ POST /createOrder
    ```

  **2. 계층적 구조**
  - **중첩 자원**: 자원 간 관계를 URI로 표현
    ```
    /users/123/orders/456/items/789
    /companies/abc/departments/hr/employees
    ```

  **3. 복수형 사용**
  - **일관성**: 컬렉션은 복수형으로 통일
    ```
    ✓ /users, /orders, /products
    ✗ /user, /order, /product (혼재 사용)
    ```

  **4. 소문자와 하이픈**
  - **가독성**: 소문자와 하이픈 사용
    ```
    ✓ /user-profiles, /order-items
    ✗ /userProfiles, /User_Profiles
    ```

  **5. 쿼리 파라미터 활용**
  - **필터링, 정렬, 페이징**:
    ```
    GET /users?role=admin&status=active
    GET /products?category=electronics&sort=price&order=desc
    GET /orders?page=2&size=20&from=2023-01-01
    ```

  **응답 형식 및 상태 코드**

  **1. JSON 응답 구조**
  ```json
  {
    "data": {
      "id": 123,
      "name": "John Doe",
      "email": "john@example.com"
    },
    "meta": {
      "timestamp": "2023-12-01T10:00:00Z",
      "version": "1.0"
    },
    "links": {
      "self": "/users/123",
      "orders": "/users/123/orders"
    }
  }
  ```

  **2. 컬렉션 응답**
  ```json
  {
    "data": [
      {"id": 1, "name": "User 1"},
      {"id": 2, "name": "User 2"}
    ],
    "pagination": {
      "page": 1,
      "size": 20,
      "total": 100,
      "totalPages": 5
    },
    "links": {
      "first": "/users?page=1",
      "next": "/users?page=2",
      "last": "/users?page=5"
    }
  }
  ```

  **3. 오류 응답**
  ```json
  {
    "error": {
      "code": "VALIDATION_ERROR",
      "message": "Invalid input data",
      "details": [
        {
          "field": "email",
          "message": "Invalid email format"
        }
      ]
    },
    "timestamp": "2023-12-01T10:00:00Z",
    "path": "/users"
  }
  ```

  **HATEOAS (Hypermedia as the Engine of Application State)**

  **핵심 개념**
  - **하이퍼미디어 링크**: 응답에 관련 액션들의 링크 포함
  - **동적 탐색**: 클라이언트가 서버 응답을 통해 가능한 액션 발견
  - **결합도 감소**: 클라이언트가 URL을 하드코딩하지 않음

  **구현 예시**
  ```json
  {
    "id": 123,
    "name": "John Doe",
    "status": "active",
    "_links": {
      "self": {"href": "/users/123"},
      "edit": {"href": "/users/123", "method": "PUT"},
      "delete": {"href": "/users/123", "method": "DELETE"},
      "orders": {"href": "/users/123/orders"},
      "deactivate": {
        "href": "/users/123/deactivate",
        "method": "POST",
        "condition": "status == 'active'"
      }
    }
  }
  ```

  **REST API 보안 고려사항**

  **1. 인증 및 인가**
  - **JWT 토큰**: 무상태 인증
    ```
    Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
    ```
  - **OAuth 2.0**: 제3자 인증
  - **API 키**: 간단한 인증 방식
    ```
    X-API-Key: your-api-key-here
    ```

  **2. HTTPS 사용**
  - **전송 암호화**: 모든 API 통신을 HTTPS로
  - **인증서 검증**: 유효한 SSL/TLS 인증서 사용

  **3. 입력 검증**
  - **데이터 검증**: 모든 입력 데이터 검증
  - **SQL 인젝션 방지**: 파라미터화된 쿼리 사용
  - **XSS 방지**: 출력 데이터 이스케이프

  **4. Rate Limiting**
  - **요청 제한**: API 호출 빈도 제한
    ```
    HTTP/1.1 429 Too Many Requests
    X-RateLimit-Limit: 1000
    X-RateLimit-Remaining: 0
    X-RateLimit-Reset: 1640995200
    Retry-After: 3600
    ```

  **성능 최적화 전략**

  **1. 캐싱 전략**
  - **HTTP 캐싱**: Cache-Control, ETag 활용
  - **CDN**: 정적 리소스 캐싱
  - **애플리케이션 캐싱**: Redis, Memcached

  **2. 페이징 및 필터링**
  - **커서 기반 페이징**: 대용량 데이터 효율적 처리
    ```
    GET /users?cursor=eyJpZCI6MTIzfQ&limit=20
    ```
  - **필드 선택**: 필요한 필드만 반환
    ```
    GET /users?fields=id,name,email
    ```

  **3. 압축**
  - **gzip 압축**: 응답 데이터 압축
    ```
    Accept-Encoding: gzip, deflate
    Content-Encoding: gzip
    ```

  **4. 비동기 처리**
  - **긴 작업**: 비동기 처리 후 상태 조회
    ```
    POST /reports/generate
    → 202 Accepted
    Location: /reports/status/abc123

    GET /reports/status/abc123
    → {"status": "processing", "progress": 45}
    ```

  **REST API 문서화**

  **1. OpenAPI (Swagger)**
  ```yaml
  openapi: 3.0.0
  info:
    title: User API
    version: 1.0.0
  paths:
    /users:
      get:
        summary: Get users
        parameters:
          - name: role
            in: query
            schema:
              type: string
        responses:
          200:
            description: Success
            content:
              application/json:
                schema:
                  type: array
                  items:
                    $ref: '#/components/schemas/User'
  ```

  **2. API 문서 도구**
  - **Swagger UI**: 인터랙티브 API 문서
  - **Postman**: API 테스트 및 문서화
  - **Insomnia**: REST 클라이언트
  - **curl**: 명령줄 테스트

  **REST vs GraphQL vs gRPC 비교**

  **REST 장점**
  - **단순성**: 이해하기 쉬운 구조
  - **캐싱**: HTTP 캐싱 메커니즘 활용
  - **도구 지원**: 풍부한 도구와 라이브러리
  - **디버깅**: 표준 HTTP 도구로 디버깅 용이

  **REST 단점**
  - **Over-fetching**: 불필요한 데이터 전송
  - **Under-fetching**: 여러 요청 필요
  - **버전 관리**: API 버전 관리 복잡성

  **실제 구현 예시 (Spring Boot)**
  ```java
  @RestController
  @RequestMapping("/api/users")
  public class UserController {

    @GetMapping
    public ResponseEntity<Page<User>> getUsers(
        @RequestParam(defaultValue = "0") int page,
        @RequestParam(defaultValue = "20") int size,
        @RequestParam(required = false) String role) {

      Pageable pageable = PageRequest.of(page, size);
      Page<User> users = userService.findUsers(role, pageable);

      return ResponseEntity.ok()
        .header("X-Total-Count", String.valueOf(users.getTotalElements()))
        .body(users);
    }

    @PostMapping
    public ResponseEntity<User> createUser(@Valid @RequestBody CreateUserRequest request) {
      User user = userService.createUser(request);

      return ResponseEntity.created(
        URI.create("/api/users/" + user.getId())
      ).body(user);
    }

    @PutMapping("/{id}")
    public ResponseEntity<User> updateUser(
        @PathVariable Long id,
        @Valid @RequestBody UpdateUserRequest request) {

      User user = userService.updateUser(id, request);
      return ResponseEntity.ok(user);
    }
  }
  ```

  **모니터링 및 로깅**
  - **API 메트릭**: 응답 시간, 처리량, 오류율
  - **로그 구조화**: JSON 형태의 구조화된 로그
  - **분산 추적**: 마이크로서비스 환경에서 요청 추적
  - **헬스 체크**: API 상태 모니터링 엔드포인트


# CS – 데이터베이스 및 자료구조·알고리즘

## 데이터베이스

- **ACID 트랜잭션 특성 및 격리 수준 심화 분석**

  **ACID 트랜잭션 특성 개요**
  - **정의**: 데이터베이스 트랜잭션이 **안전하게 수행**되기 위해 보장해야 하는 **4가지 핵심 특성**
  - **목적**: 데이터 무결성과 일관성을 보장하면서 **동시성 제어**를 통한 성능 최적화
  - **적용 범위**: 관계형 데이터베이스, NoSQL 일부, 분산 시스템, 메시지 큐 등

  **ACID 4가지 특성 상세 분석**

  **1. 원자성 (Atomicity)**
  - **핵심 개념**: 트랜잭션의 **모든 연산이 완전히 수행되거나 전혀 수행되지 않음**을 보장
  - **All-or-Nothing**: 부분적 실행 상태는 존재하지 않음
  - **구현 메커니즘**:
    - **Undo 로그**: 트랜잭션 실행 전 원본 데이터 백업
    - **Shadow Paging**: 별도 페이지에 변경사항 기록 후 커밋 시 원자적 교체
    - **Write-Ahead Logging (WAL)**: 변경사항을 로그에 먼저 기록
  - **실패 시나리오**:
    - **시스템 크래시**: 전원 장애, 하드웨어 오류
    - **애플리케이션 오류**: 예외 발생, 비즈니스 로직 실패
    - **데드락**: 트랜잭션 간 상호 대기로 인한 교착 상태
  - **복구 과정**:
    ```sql
    BEGIN TRANSACTION;
    UPDATE accounts SET balance = balance - 100 WHERE id = 1;
    UPDATE accounts SET balance = balance + 100 WHERE id = 2;
    -- 시스템 크래시 발생 시 모든 변경사항 롤백
    ROLLBACK; -- 또는 자동 롤백
    ```

  **2. 일관성 (Consistency)**
  - **핵심 개념**: 트랜잭션 실행 전후에 **데이터베이스가 일관된 상태**를 유지
  - **무결성 제약조건**: Primary Key, Foreign Key, Check, Unique 제약 준수
  - **비즈니스 규칙**: 도메인별 비즈니스 로직 일관성 유지
  - **구현 방법**:
    - **제약조건 검사**: 트랜잭션 커밋 전 모든 제약조건 검증
    - **트리거**: 데이터 변경 시 자동 실행되는 비즈니스 로직
    - **저장 프로시저**: 복잡한 비즈니스 규칙을 데이터베이스 레벨에서 구현
  - **일관성 위반 예시**:
    ```sql
    -- 잘못된 예: 계좌 잔액 합계 불일치
    UPDATE accounts SET balance = balance - 100 WHERE id = 1;
    -- 시스템 오류로 두 번째 UPDATE 실행 안됨
    -- UPDATE accounts SET balance = balance + 100 WHERE id = 2;
    ```

  **3. 격리성 (Isolation)**
  - **핵심 개념**: **동시 실행되는 트랜잭션들이 서로 간섭하지 않도록** 보장
  - **동시성 제어**: 성능과 일관성 간의 균형점 찾기
  - **격리 수준**: 4단계 격리 수준으로 세밀한 제어

  **4. 지속성 (Durability)**
  - **핵심 개념**: **커밋된 트랜잭션의 결과는 영구적으로 저장**되어 시스템 장애에도 유지
  - **구현 메커니즘**:
    - **Write-Ahead Logging**: 변경사항을 먼저 로그에 기록
    - **Force 정책**: 커밋 시 모든 변경사항을 디스크에 강제 기록
    - **체크포인트**: 주기적으로 메모리 내용을 디스크에 동기화
  - **복구 시나리오**:
    - **시스템 재시작**: 로그를 이용한 Redo/Undo 복구
    - **미디어 장애**: 백업과 로그를 이용한 Point-in-Time 복구

  **트랜잭션 격리 수준 (Isolation Levels) 심화**

  **1. Read Uncommitted (레벨 0)**

  **특징**
  - **가장 낮은 격리 수준**: 다른 트랜잭션의 **커밋되지 않은 변경사항**도 읽기 가능
  - **최고 동시성**: 락을 거의 사용하지 않아 동시 처리 성능 최대
  - **데이터 일관성 최저**: 다양한 이상 현상 발생 가능

  **발생 가능한 이상 현상**
  - **Dirty Read**: 커밋되지 않은 데이터 읽기
    ```sql
    -- Transaction A
    UPDATE products SET price = 1000 WHERE id = 1;
    -- 아직 커밋하지 않음

    -- Transaction B (동시 실행)
    SELECT price FROM products WHERE id = 1; -- 1000 읽음 (Dirty Read)

    -- Transaction A
    ROLLBACK; -- 실제로는 가격이 변경되지 않았음
    ```

  **적용 사례**
  - **실시간 대시보드**: 정확성보다 속도가 중요한 모니터링
  - **로그 분석**: 대략적인 통계 정보 수집
  - **임시 보고서**: 정확성이 크게 중요하지 않은 임시 분석

  **2. Read Committed (레벨 1)**

  **특징**
  - **대부분 DBMS의 기본값**: Oracle, PostgreSQL, SQL Server 기본 설정
  - **커밋된 데이터만 읽기**: Dirty Read 방지
  - **읽기 시 공유락**: 읽는 동안만 락 유지, 읽기 완료 후 즉시 해제

  **구현 메커니즘**
  - **공유락(Shared Lock)**: 읽기 시 다른 트랜잭션의 쓰기 차단
  - **배타락(Exclusive Lock)**: 쓰기 시 다른 트랜잭션의 읽기/쓰기 차단
  - **락 해제**: 읽기 완료 즉시 공유락 해제 (쓰기락은 커밋까지 유지)

  **발생 가능한 이상 현상**
  - **Non-Repeatable Read**: 동일 트랜잭션 내에서 같은 데이터를 여러 번 읽을 때 다른 결과
    ```sql
    -- Transaction A
    SELECT balance FROM accounts WHERE id = 1; -- 1000

    -- Transaction B (동시 실행)
    UPDATE accounts SET balance = 1500 WHERE id = 1;
    COMMIT;

    -- Transaction A
    SELECT balance FROM accounts WHERE id = 1; -- 1500 (다른 결과)
    ```

  **3. Repeatable Read (레벨 2)**

  **특징**
  - **MySQL InnoDB 기본값**: MySQL의 기본 격리 수준
  - **반복 읽기 보장**: 동일 트랜잭션 내에서 같은 데이터는 항상 동일한 결과
  - **공유락 유지**: 트랜잭션 종료까지 읽기 락 유지

  **구현 메커니즘**
  - **MVCC (Multi-Version Concurrency Control)**: 스냅샷 기반 읽기
  - **Gap Lock**: 범위 검색 시 해당 범위에 새로운 레코드 삽입 방지
  - **Next-Key Lock**: 레코드 락 + Gap 락 조합

  **발생 가능한 이상 현상**
  - **Phantom Read**: 범위 검색 시 새로운 레코드가 나타나거나 사라짐
    ```sql
    -- Transaction A
    SELECT COUNT(*) FROM orders WHERE amount > 1000; -- 5개

    -- Transaction B (동시 실행)
    INSERT INTO orders (amount) VALUES (1500);
    COMMIT;

    -- Transaction A
    SELECT COUNT(*) FROM orders WHERE amount > 1000; -- 6개 (Phantom Read)
    ```

  **4. Serializable (레벨 3)**

  **특징**
  - **최고 격리 수준**: 완전한 직렬화 실행과 동일한 결과 보장
  - **모든 이상 현상 방지**: Dirty Read, Non-Repeatable Read, Phantom Read 모두 방지
  - **최저 동시성**: 높은 락 경합으로 인한 성능 저하

  **구현 방법**
  - **2PL (Two-Phase Locking)**: 락 획득 단계와 해제 단계 분리
  - **범위 락**: 조건에 해당하는 모든 범위에 락 설정
  - **직렬화 검증**: 트랜잭션 실행 순서 검증

  **성능 영향**
  - **데드락 증가**: 락 경합으로 인한 교착 상태 빈발
  - **처리량 감소**: 직렬화로 인한 동시성 저하
  - **응답 시간 증가**: 락 대기 시간 증가

  **격리 수준별 성능 vs 일관성 트레이드오프**

  **성능 지표**
  ```
  동시성 (높음 → 낮음): Read Uncommitted > Read Committed > Repeatable Read > Serializable
  일관성 (낮음 → 높음): Read Uncommitted < Read Committed < Repeatable Read < Serializable
  ```

  **선택 기준**
  - **Read Uncommitted**: 실시간 모니터링, 로그 분석
  - **Read Committed**: 일반적인 OLTP 애플리케이션
  - **Repeatable Read**: 보고서 생성, 배치 처리
  - **Serializable**: 금융 거래, 재고 관리 등 높은 일관성 요구

  **DBMS별 기본 격리 수준**
  - **MySQL InnoDB**: Repeatable Read
  - **PostgreSQL**: Read Committed
  - **Oracle**: Read Committed
  - **SQL Server**: Read Committed
  - **SQLite**: Serializable

  **격리 수준 설정 방법**
  ```sql
  -- 세션 레벨 설정
  SET TRANSACTION ISOLATION LEVEL READ COMMITTED;

  -- 트랜잭션별 설정
  BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ;

  -- 글로벌 설정 (MySQL)
  SET GLOBAL transaction_isolation = 'READ-COMMITTED';
  ```

  **실제 운영 환경 고려사항**

  **1. 애플리케이션 설계**
  - **낙관적 락**: 버전 필드를 이용한 충돌 감지
  - **비관적 락**: 명시적 락 획득으로 충돌 방지
  - **재시도 로직**: 데드락 발생 시 자동 재시도

  **2. 성능 모니터링**
  - **락 대기 시간**: 트랜잭션별 락 대기 시간 측정
  - **데드락 발생률**: 데드락 발생 빈도 모니터링
  - **동시 트랜잭션 수**: 활성 트랜잭션 수 추적

  **3. 튜닝 전략**
  - **트랜잭션 크기 최소화**: 짧은 트랜잭션으로 락 경합 감소
  - **인덱스 최적화**: 락 범위 최소화를 위한 인덱스 설계
  - **배치 처리 분리**: 대용량 처리는 별도 시간대에 실행

- **데이터베이스 인덱스 (Database Index) 심화 분석**

  **인덱스 핵심 개념**
  - **정의**: 테이블의 **특정 컬럼 값과 해당 레코드의 물리적 위치**를 매핑하는 **별도의 자료구조**
  - **목적**: 데이터 검색 성능을 **획기적으로 향상**시키기 위한 데이터베이스 최적화 기법
  - **비유**: 책의 목차나 색인과 같은 역할로, 원하는 정보를 빠르게 찾을 수 있게 도움
  - **트레이드오프**: 검색 성능 향상 vs 저장 공간 및 쓰기 성능 비용

  **인덱스 동작 원리**

  **1. 검색 과정**
  ```sql
  -- 인덱스 없는 경우 (Full Table Scan)
  SELECT * FROM users WHERE email = 'john@example.com';
  -- 모든 레코드를 순차적으로 검사 (O(n))

  -- 인덱스 있는 경우 (Index Seek)
  CREATE INDEX idx_users_email ON users(email);
  SELECT * FROM users WHERE email = 'john@example.com';
  -- 인덱스를 통해 직접 레코드 위치 찾기 (O(log n))
  ```

  **2. 인덱스 구조**
  ```
  인덱스 테이블:
  ┌─────────────────┬──────────────┐
  │ 인덱스 키 값    │ 레코드 포인터│
  ├─────────────────┼──────────────┤
  │ alice@test.com  │ Row ID: 1001 │
  │ bob@test.com    │ Row ID: 1003 │
  │ john@example.com│ Row ID: 1002 │
  └─────────────────┴──────────────┘
  ```

  **인덱스 유형별 상세 분석**

  **1. 클러스터드 인덱스 (Clustered Index)**

  **핵심 특징**
  - **물리적 정렬**: 테이블 데이터가 인덱스 키 순서로 **물리적으로 정렬**되어 저장
  - **테이블당 하나**: 데이터의 물리적 순서는 하나만 가능하므로 테이블당 최대 1개
  - **Primary Key 기본**: 대부분 DBMS에서 Primary Key에 자동으로 클러스터드 인덱스 생성

  **장점**
  - **범위 검색 최적화**: 연속된 데이터가 물리적으로 인접하여 I/O 효율성 극대화
  - **정렬된 결과**: ORDER BY 절 사용 시 추가 정렬 작업 불필요
  - **커버링 인덱스**: 인덱스만으로 쿼리 결과 반환 가능

  **단점**
  - **삽입 성능 저하**: 정렬 순서 유지를 위한 데이터 재배치 필요
  - **페이지 분할**: 중간 삽입 시 페이지 분할로 인한 성능 저하
  - **업데이트 비용**: 키 값 변경 시 물리적 위치 이동 필요

  **구현 예시**
  ```sql
  -- SQL Server
  CREATE CLUSTERED INDEX idx_orders_date ON orders(order_date);

  -- MySQL InnoDB (Primary Key가 자동으로 클러스터드)
  CREATE TABLE users (
    id INT PRIMARY KEY,  -- 자동으로 클러스터드 인덱스
    name VARCHAR(100)
  );
  ```

  **2. 비클러스터드 인덱스 (Non-Clustered Index)**

  **핵심 특징**
  - **논리적 정렬**: 인덱스는 정렬되지만 실제 테이블 데이터는 물리적으로 정렬되지 않음
  - **별도 구조**: 인덱스가 테이블과 **독립적인 별도 자료구조**로 존재
  - **다중 생성 가능**: 테이블당 여러 개의 비클러스터드 인덱스 생성 가능

  **동작 과정**
  ```
  1. 인덱스 검색: 키 값으로 인덱스에서 레코드 포인터 찾기
  2. 테이블 접근: 포인터를 이용해 실제 테이블 데이터 접근
  3. 데이터 반환: 필요한 컬럼 값 추출하여 반환
  ```

  **장점**
  - **유연성**: 다양한 컬럼 조합으로 여러 인덱스 생성 가능
  - **삽입 성능**: 물리적 재배치 없이 삽입 가능
  - **선택적 적용**: 필요한 컬럼에만 선택적으로 적용

  **단점**
  - **추가 I/O**: 인덱스 접근 후 테이블 접근으로 2번의 I/O 필요
  - **저장 공간**: 별도 인덱스 구조로 인한 추가 저장 공간 필요

  **3. 복합 인덱스 (Composite Index)**

  **핵심 개념**
  - **다중 컬럼**: 2개 이상의 컬럼을 조합한 인덱스
  - **컬럼 순서 중요**: 인덱스 생성 시 컬럼 순서가 성능에 큰 영향
  - **최좌측 접두사 규칙**: 인덱스의 첫 번째 컬럼부터 순서대로 사용해야 효과적

  **설계 원칙**
  ```sql
  -- 복합 인덱스 생성
  CREATE INDEX idx_orders_customer_date ON orders(customer_id, order_date);

  -- 효과적인 쿼리 (최좌측 접두사 규칙 준수)
  SELECT * FROM orders WHERE customer_id = 123;                    -- ✓ 인덱스 사용
  SELECT * FROM orders WHERE customer_id = 123 AND order_date > '2023-01-01'; -- ✓ 인덱스 사용

  -- 비효과적인 쿼리 (최좌측 접두사 규칙 위반)
  SELECT * FROM orders WHERE order_date > '2023-01-01';           -- ✗ 인덱스 미사용
  ```

  **컬럼 순서 결정 기준**
  1. **선택도(Selectivity)**: 고유값이 많은 컬럼을 앞에 배치
  2. **사용 빈도**: 자주 사용되는 조건 컬럼을 앞에 배치
  3. **범위 검색**: 범위 검색 컬럼은 뒤에 배치

  **4. 커버링 인덱스 (Covering Index)**

  **핵심 개념**
  - **완전 포함**: 쿼리에 필요한 **모든 컬럼이 인덱스에 포함**
  - **테이블 접근 불필요**: 인덱스만으로 쿼리 결과 반환 가능
  - **성능 극대화**: 테이블 I/O 제거로 최고 성능 달성

  **구현 방법**
  ```sql
  -- 일반 인덱스
  CREATE INDEX idx_orders_customer ON orders(customer_id);

  -- 커버링 인덱스 (INCLUDE 절 사용)
  CREATE INDEX idx_orders_customer_covering 
  ON orders(customer_id) 
  INCLUDE (order_date, total_amount);

  -- 이 쿼리는 테이블 접근 없이 인덱스만으로 처리
  SELECT customer_id, order_date, total_amount 
  FROM orders 
  WHERE customer_id = 123;
  ```

  **인덱스 자료구조 심화**

  **1. B+Tree (가장 일반적)**

  **구조적 특징**
  - **균형 트리**: 모든 리프 노드가 동일한 깊이
  - **리프 노드 데이터**: 실제 데이터(또는 포인터)는 리프 노드에만 저장
  - **내부 노드 키**: 내부 노드는 탐색을 위한 키 값만 저장
  - **연결 리스트**: 리프 노드들이 연결 리스트로 연결되어 순차 접근 최적화

  **동작 과정**
  ```
  B+Tree 구조 예시:
                    [50]
                   /    \
              [25, 40]   [75, 90]
             /   |   \   /   |   \
          [10] [30] [45] [60] [80] [95]
           |    |    |    |    |    |
         Data  Data Data Data Data Data
  ```

  **성능 특성**
  - **검색**: O(log n) - 트리 높이에 비례
  - **삽입**: O(log n) - 분할 연산 포함
  - **삭제**: O(log n) - 병합 연산 포함
  - **범위 검색**: 리프 노드 연결 리스트로 효율적

  **2. 해시 인덱스 (Hash Index)**

  **특징**
  - **해시 함수**: 키 값을 해시 함수로 변환하여 버킷에 저장
  - **등가 검색 최적화**: = 조건 검색에 최적화 (O(1))
  - **범위 검색 불가**: >, <, BETWEEN 등 범위 검색 지원 안함
  - **정렬 불가**: ORDER BY 절에 도움 안됨

  **적용 사례**
  ```sql
  -- MySQL Memory 엔진에서 해시 인덱스 사용
  CREATE TABLE cache_table (
    key_col VARCHAR(50),
    value_col TEXT,
    INDEX USING HASH (key_col)
  ) ENGINE=MEMORY;
  ```

  **3. 비트맵 인덱스 (Bitmap Index)**

  **특징**
  - **비트맵 구조**: 각 고유값에 대해 비트맵 생성
  - **낮은 카디널리티**: 고유값이 적은 컬럼에 효과적
  - **논리 연산 최적화**: AND, OR, NOT 연산 효율적

  **적용 사례**
  - **성별**: M/F 두 값만 존재
  - **상태**: Active/Inactive/Pending 등 제한된 값
  - **지역**: 제한된 지역 코드

  **인덱스 설계 전략**

  **1. 인덱스 생성 기준**

  **생성해야 하는 경우**
  - **WHERE 절 자주 사용**: 검색 조건으로 자주 사용되는 컬럼
  - **JOIN 조건**: 테이블 조인에 사용되는 컬럼
  - **ORDER BY**: 정렬에 자주 사용되는 컬럼
  - **GROUP BY**: 그룹핑에 사용되는 컬럼
  - **높은 선택도**: 고유값이 많은 컬럼 (카디널리티가 높은 컬럼)

  **생성하지 말아야 하는 경우**
  - **낮은 선택도**: 고유값이 적은 컬럼 (성별, 불린 값 등)
  - **자주 변경되는 컬럼**: UPDATE가 빈번한 컬럼
  - **작은 테이블**: 레코드 수가 적은 테이블 (보통 1000건 미만)
  - **배치 처리 전용**: 실시간 검색이 없는 배치 처리 전용 테이블

  **2. 인덱스 최적화 기법**

  **선택도 계산**
  ```sql
  -- 선택도 = 고유값 수 / 전체 레코드 수
  SELECT 
    COUNT(DISTINCT column_name) / COUNT(*) as selectivity
  FROM table_name;

  -- 선택도가 0.1 이상이면 인덱스 효과적
  ```

  **인덱스 사용률 모니터링**
  ```sql
  -- MySQL: 인덱스 사용 통계
  SELECT 
    table_schema,
    table_name,
    index_name,
    cardinality,
    seq_in_index
  FROM information_schema.statistics
  WHERE table_schema = 'your_database';
  ```

  **3. 파티셔닝과 인덱스**
  - **로컬 인덱스**: 각 파티션별로 독립적인 인덱스
  - **글로벌 인덱스**: 모든 파티션을 아우르는 통합 인덱스
  - **파티션 프루닝**: 조건에 맞는 파티션만 검색하여 성능 향상

  **인덱스 유지보수**

  **1. 인덱스 재구성 (Rebuild)**
  ```sql
  -- SQL Server
  ALTER INDEX idx_name ON table_name REBUILD;

  -- MySQL
  ALTER TABLE table_name ENGINE=InnoDB;

  -- Oracle
  ALTER INDEX idx_name REBUILD;
  ```

  **2. 인덱스 통계 업데이트**
  ```sql
  -- SQL Server
  UPDATE STATISTICS table_name idx_name;

  -- MySQL
  ANALYZE TABLE table_name;

  -- PostgreSQL
  ANALYZE table_name;
  ```

  **3. 인덱스 조각화 모니터링**
  - **논리적 조각화**: 인덱스 페이지의 논리적 순서와 물리적 순서 불일치
  - **물리적 조각화**: 인덱스 페이지가 디스크에 분산되어 저장
  - **임계값**: 조각화율 30% 이상 시 재구성 권장

  **실제 운영 환경 고려사항**

  **1. 인덱스 전략**
  - **읽기 중심**: 많은 인덱스로 검색 성능 최적화
  - **쓰기 중심**: 최소한의 인덱스로 삽입/수정 성능 확보
  - **혼합 워크로드**: 핵심 쿼리 분석 후 선택적 인덱스 적용

  **2. 모니터링 지표**
  - **인덱스 사용률**: 생성된 인덱스의 실제 사용 빈도
  - **쿼리 실행 계획**: EXPLAIN을 통한 인덱스 사용 여부 확인
  - **I/O 통계**: 인덱스로 인한 I/O 감소 효과 측정

  **3. 성능 튜닝**
  - **쿼리 최적화**: 인덱스를 효과적으로 사용하는 쿼리 작성
  - **인덱스 힌트**: 옵티마이저가 잘못된 인덱스 선택 시 힌트 사용
  - **커버링 인덱스**: 자주 사용되는 쿼리에 대한 커버링 인덱스 고려

- **인덱스 사용 장단점 및 성능 영향 심화 분석**

  **인덱스 사용의 주요 장점**

  **1. 검색 성능 획기적 향상**
  - **시간 복잡도 개선**: O(n) → O(log n)으로 검색 시간 대폭 단축
  - **I/O 연산 최소화**: 필요한 데이터 페이지만 읽어 디스크 I/O 크게 감소
  - **대용량 데이터 처리**: 수백만 건 이상의 데이터에서도 빠른 검색 가능
  - **성능 개선 사례**:
    ```sql
    -- 인덱스 없는 경우: 1,000,000건 테이블에서 평균 500,000번 비교
    SELECT * FROM users WHERE email = 'john@example.com';
    -- 실행 시간: 약 2-3초

    -- 인덱스 있는 경우: 평균 20번 비교 (log₂ 1,000,000 ≈ 20)
    CREATE INDEX idx_users_email ON users(email);
    SELECT * FROM users WHERE email = 'john@example.com';
    -- 실행 시간: 약 0.001초 (2000-3000배 향상)
    ```

  **2. 정렬 및 집계 연산 최적화**
  - **ORDER BY 성능**: 인덱스가 이미 정렬된 상태이므로 추가 정렬 작업 불필요
  - **MIN/MAX 함수**: 인덱스의 첫 번째/마지막 값을 즉시 반환
  - **GROUP BY 최적화**: 정렬된 데이터로 그룹핑 효율성 증대
  - **범위 검색**: BETWEEN, >, < 조건에서 연속된 데이터 블록 접근
  - **성능 비교**:
    ```sql
    -- 인덱스 없는 경우
    SELECT MIN(created_at), MAX(created_at) FROM orders;
    -- 전체 테이블 스캔 필요 (O(n))

    -- 인덱스 있는 경우
    CREATE INDEX idx_orders_created_at ON orders(created_at);
    SELECT MIN(created_at), MAX(created_at) FROM orders;
    -- 인덱스 첫/마지막 값만 접근 (O(1))
    ```

  **3. 조인 성능 향상**
  - **Nested Loop Join**: 내부 테이블 인덱스로 빠른 매칭
  - **Hash Join**: 작은 테이블의 해시 테이블 구성 시 인덱스 활용
  - **Sort-Merge Join**: 정렬된 인덱스로 병합 조인 효율성 증대
  - **조인 최적화 예시**:
    ```sql
    -- 인덱스 없는 경우: Cartesian Product 위험
    SELECT u.name, o.total 
    FROM users u JOIN orders o ON u.id = o.user_id;
    -- 실행 시간: users 수 × orders 수

    -- 인덱스 있는 경우: 효율적 조인
    CREATE INDEX idx_orders_user_id ON orders(user_id);
    -- 실행 시간: users 수 × log(orders 수)
    ```

  **4. 전체 시스템 부하 절감**
  - **CPU 사용률 감소**: 불필요한 데이터 비교 작업 제거
  - **메모리 효율성**: 필요한 데이터만 메모리에 로드
  - **동시성 향상**: 빠른 쿼리 실행으로 락 보유 시간 단축
  - **네트워크 트래픽 감소**: 정확한 데이터만 전송

  **5. 유니크 제약조건 지원**
  - **중복 방지**: UNIQUE 인덱스로 데이터 무결성 보장
  - **빠른 중복 검사**: 삽입/수정 시 O(log n) 시간에 중복 확인
  - **Primary Key 지원**: 기본키 제약조건 구현의 기반

  **인덱스 사용의 주요 단점**

  **1. 추가 저장 공간 필요**
  - **인덱스 크기**: 일반적으로 테이블 크기의 10-30% 추가 공간 필요
  - **복합 인덱스**: 여러 컬럼 인덱스는 더 많은 공간 소모
  - **저장 공간 계산**:
    ```sql
    -- 예시: 1,000,000건 users 테이블
    -- 테이블 크기: 약 100MB
    -- email 인덱스: 약 15MB (15% 추가)
    -- name 인덱스: 약 20MB (20% 추가)
    -- 복합 인덱스 (email, name): 약 25MB (25% 추가)
    -- 총 저장 공간: 160MB (60% 증가)
    ```

  **2. DML 연산 시 성능 오버헤드**
  - **INSERT 성능 저하**: 새 레코드 삽입 시 모든 인덱스 업데이트 필요
  - **UPDATE 성능 영향**: 인덱스 컬럼 수정 시 인덱스 재구성 필요
  - **DELETE 성능 영향**: 레코드 삭제 시 모든 인덱스에서 해당 항목 제거
  - **성능 영향 측정**:
    ```sql
    -- 인덱스 없는 테이블
    INSERT INTO users_no_index (name, email) VALUES ('John', 'john@test.com');
    -- 실행 시간: 0.001초

    -- 5개 인덱스가 있는 테이블
    INSERT INTO users_with_indexes (name, email) VALUES ('John', 'john@test.com');
    -- 실행 시간: 0.005초 (5배 증가)
    ```

  **3. 인덱스 유지보수 비용**
  - **조각화 문제**: 시간이 지나면서 인덱스 페이지 조각화 발생
  - **재구성 필요**: 주기적인 인덱스 재구성 작업 필요
  - **통계 업데이트**: 옵티마이저를 위한 인덱스 통계 정보 갱신
  - **유지보수 작업**:
    ```sql
    -- 인덱스 조각화 확인 (SQL Server)
    SELECT 
        index_name,
        avg_fragmentation_in_percent
    FROM sys.dm_db_index_physical_stats(DB_ID(), OBJECT_ID('users'), NULL, NULL, NULL);

    -- 조각화율 30% 이상 시 재구성
    ALTER INDEX idx_users_email ON users REBUILD;
    ```

  **4. 낮은 카디널리티 컬럼의 비효율성**
  - **선택도 문제**: 고유값이 적은 컬럼은 인덱스 효과 제한적
  - **비트맵 인덱스 고려**: Oracle 등에서 낮은 카디널리티용 비트맵 인덱스 제공
  - **카디널리티 분석**:
    ```sql
    -- 성별 컬럼 (카디널리티 = 2)
    SELECT gender, COUNT(*) FROM users GROUP BY gender;
    -- M: 500,000건, F: 500,000건
    -- 인덱스 사용 시에도 50% 데이터 스캔 필요 → 비효율적

    -- 이메일 컬럼 (카디널리티 = 1,000,000)
    SELECT COUNT(DISTINCT email) FROM users;
    -- 1,000,000 (100% 고유) → 인덱스 매우 효과적
    ```

  **5. 메모리 사용량 증가**
  - **버퍼 풀 점유**: 인덱스 페이지가 메모리 버퍼 풀 점유
  - **캐시 경합**: 테이블 데이터와 인덱스 데이터 간 메모리 경합
  - **메모리 계획**: 충분한 메모리 확보 필요

  **인덱스 효과성 판단 기준**

  **1. 선택도 (Selectivity) 기준**
  ```sql
  -- 선택도 계산 공식
  Selectivity = COUNT(DISTINCT column) / COUNT(*)

  -- 선택도별 인덱스 효과
  -- 0.8 이상: 매우 효과적
  -- 0.3 - 0.8: 효과적
  -- 0.1 - 0.3: 보통
  -- 0.1 미만: 비효과적
  ```

  **2. 쿼리 사용 빈도**
  - **자주 사용되는 WHERE 조건**: 인덱스 생성 우선순위 높음
  - **가끔 사용되는 조건**: 저장 공간 대비 효과 검토 필요
  - **사용되지 않는 조건**: 인덱스 불필요

  **3. 데이터 변경 빈도**
  - **읽기 중심 테이블**: 많은 인덱스 생성 가능
  - **쓰기 중심 테이블**: 최소한의 필수 인덱스만 생성
  - **배치 처리 테이블**: 처리 전 인덱스 삭제, 처리 후 재생성 고려

  **인덱스 성능 모니터링**

  **1. 사용률 모니터링**
  ```sql
  -- MySQL: 인덱스 사용 통계
  SELECT 
      table_name,
      index_name,
      cardinality,
      (cardinality / table_rows) * 100 as selectivity_percent
  FROM information_schema.statistics s
  JOIN information_schema.tables t ON s.table_name = t.table_name
  WHERE s.table_schema = 'your_database';
  ```

  **2. 성능 영향 측정**
  ```sql
  -- 쿼리 실행 계획 분석
  EXPLAIN SELECT * FROM users WHERE email = 'john@example.com';

  -- 실행 시간 측정
  SET profiling = 1;
  SELECT * FROM users WHERE email = 'john@example.com';
  SHOW PROFILES;
  ```

  **3. 인덱스 효율성 분석**
  - **Index Seek vs Index Scan**: Seek가 효율적, Scan은 비효율적
  - **Key Lookups**: 커버링 인덱스로 개선 가능
  - **Index Usage Ratio**: 인덱스 사용 비율 모니터링

  **최적화 전략**

  **1. 인덱스 통합**
  ```sql
  -- 개별 인덱스 (비효율적)
  CREATE INDEX idx_users_name ON users(name);
  CREATE INDEX idx_users_email ON users(email);

  -- 복합 인덱스로 통합 (효율적)
  CREATE INDEX idx_users_name_email ON users(name, email);
  -- 두 조건을 모두 만족하는 쿼리에 최적화
  ```

  **2. 부분 인덱스 (Partial Index)**
  ```sql
  -- PostgreSQL: 조건부 인덱스
  CREATE INDEX idx_active_users_email 
  ON users(email) 
  WHERE status = 'active';
  -- 활성 사용자만 인덱싱하여 크기 절약
  ```

  **3. 함수 기반 인덱스**
  ```sql
  -- Oracle: 함수 기반 인덱스
  CREATE INDEX idx_users_upper_name 
  ON users(UPPER(name));
  -- 대소문자 구분 없는 검색 최적화
  ```

  **실제 운영 환경 고려사항**

  **1. 인덱스 전략 수립**
  - **워크로드 분석**: 실제 쿼리 패턴 분석
  - **성능 테스트**: 인덱스 추가 전후 성능 비교
  - **점진적 적용**: 한 번에 많은 인덱스 생성 지양

  **2. 모니터링 체계**
  - **성능 지표**: 쿼리 응답 시간, 처리량 모니터링
  - **리소스 사용량**: CPU, 메모리, 디스크 I/O 모니터링
  - **인덱스 효율성**: 사용되지 않는 인덱스 식별 및 제거

  **3. 유지보수 계획**
  - **정기 점검**: 인덱스 조각화 상태 점검
  - **통계 갱신**: 옵티마이저 통계 정보 최신화
  - **용량 관리**: 인덱스 증가에 따른 저장 공간 계획

- **트랜잭션 격리수준 & Serializable 구현 & MVCC**
  <aside>  
   **트랜잭션 격리수준 (Transaction Isolation Levels)**
  - **READ UNCOMMITTED**: Dirty Read 허용, 가장 낮은 격리수준
  - **READ COMMITTED**: 커밋된 데이터만 읽기, Non-Repeatable Read 발생 가능
  - **REPEATABLE READ**: 동일 트랜잭션 내 반복 읽기 보장, Phantom Read 발생 가능
  - **SERIALIZABLE**: 가장 높은 격리수준, 완전한 직렬화 보장

  **Serializable 구현 방법**
  - **2PL (Two-Phase Locking)**: 확장 단계 → 수축 단계로 락 관리
    - Growing Phase: 락 획득만 가능
    - Shrinking Phase: 락 해제만 가능
    - 데드락 위험성 존재
  - **MVCC (Multi-Version Concurrency Control)**: 버전 기반 동시성 제어
    - 읽기 작업은 락 없이 스냅샷 사용
    - 쓰기 작업만 락 사용 → 동시성 향상

  **MVCC (Multi-Version Concurrency Control) 상세**
  - **스냅샷 격리**: 트랜잭션 시작 시점의 데이터 스냅샷 제공
  - **버전 체인**: 각 데이터 행의 여러 버전을 시간순으로 관리
  - **가시성 규칙**: 트랜잭션 ID와 커밋 시점으로 읽을 수 있는 버전 결정
  - **Undo 로그**: 이전 버전 데이터 보관 → 롤백 및 일관된 읽기 지원
  - **장점**: 읽기-쓰기 간 블로킹 최소화, 높은 동시성
  - **단점**: 저장 공간 오버헤드, 가비지 컬렉션 필요
  </aside>

- **샤딩(Sharding)**
  <aside>  
   데이터베이스 분할로 성능·확장성 개선  
  - DB 서버별 샤딩  
  - 테이블 샤딩  
  - 행(Row) 샤딩  
  - 예: MySQL Vitess  
  </aside>

- **Outer Join vs Inner Join**
  <aside>  
    
  - Inner Join: 조인 조건 만족 레코드만  
  - Outer Join: 조건 불만족 레코드도 포함 (LEFT/RIGHT/FULL)  
  </aside>

- **정규화 vs 비정규화**
  <aside>  
    
  - 정규화: 중복 최소화, 무결성 보장  
  - 비정규화: 쿼리 단순화·성능 위해 중복 허용  
  </aside>

- **NoSQL vs RDB**
  <aside>  
    
  - RDB: SQL, 정적 스키마, 테이블, 수직 확장, 트랜잭션 강점  
  - NoSQL: 동적 스키마, 문서/Key-Value/그래프, 수평 확장, 비정형 데이터 적합  
  </aside>


## 자료구조 및 알고리즘

- **Java Collections Framework**
  <aside>  
   주요 인터페이스:  
  - List: 순서O, 중복O (ArrayList, LinkedList)  
  - Set: 순서X, 중복X (HashSet, TreeSet)  
  - Map: 키-값 쌍, 키 중복X (HashMap, TreeMap)  

  자주 사용하는 컬렉션: ArrayList, HashMap, HashSet
  </aside>

- **ArrayList vs LinkedList**
  <aside>  
    
  - ArrayList: 배열 기반, 인덱스 접근 O(1), 중간 삽입/삭제 O(n)  
  - LinkedList: 노드 기반, 순차 탐색 O(n), 삽입/삭제 O(1)  
  </aside>

- **Set vs List vs Map**
  <aside>  
    
  - List: 순서O, 중복O  
  - Set: 순서X, 중복X  
  - Map: 키-값, 키 중복X, 값 중복O  
  </aside>

- **Hashtable vs HashMap**
  <aside>  
    
  - Hashtable: 동기화, null 키/값 불허, 성능 저하  
  - HashMap: 비동기, null 키/값 허용, 빠름  
  </aside>

- **Queue vs Stack**
  <aside>  
    
  - Queue(FIFO): 선입선출 (프린터 대기열, 메시징 시스템)  
  - Stack(LIFO): 후입선출 (함수 호출 스택, UNDO/REDO)  
  </aside>

- **Array vs List vs HashTable vs BST**
  <aside>  
    
  - Array: 고정 크기  
  - List: 가변 크기  
  - 해시테이블(HashTable): 해시 함수 → O(1) 탐색  
  - 이진탐색트리(BST): 평균 O(log n) (균형 트리 시)  
  </aside>

- **Thread-Safety: ArrayList & HashMap**
  <aside>  
    
  - ArrayList, HashMap: 비동기  
  - Thread-safe 대체: Vector, Hashtable, ConcurrentHashMap  
  </aside>

- **Hashtable vs ConcurrentHashMap & Lock Striping**
  <aside>  
    
  - Hashtable: 클래스 레벨 락  
  - ConcurrentHashMap: 세그먼트/버킷별 락 (Lock Striping)  
  - Lock Striping: 락을 여러 버킷에 분산 → 동시성 향상  
  </aside>


# 자바 & 스프링 관련

## 1. 자바

### 멀티 쓰레드 환경에서 Thread-Safe 설계
- `synchronized` 키워드로 메서드/블록 단위 동기화
- `ReentrantLock` 등 명시적 락 사용
- 불변 객체(Immutable) 설계
- `AtomicInteger`, `AtomicReference` 등 원자성 제공 클래스
- 동시성 컬렉션: `HashTable`, `ConcurrentHashMap`

### Exception & 사용자 정의 예외
- **Checked Exception**: 컴파일 시 처리 강제
- **Unchecked Exception**: 런타임에만 발생
- **사용자 정의 예외**: 도메인 오류 식별용, 명확한 예외 타입 제공

### Java 8 → 11 주요 변화
- **Java 8**: 람다, 스트림 API, 함수형 인터페이스
- **Java 9**: 모듈 시스템, JShell
- **Java 10**: `var` 타입 추론
- **Java 11**: `var` 람다 파라미터, ZGC 추가

### Java 7 → 8 변경점 (JVM 포함)
- G1 GC 기본값 전환
- PermGen 제거 → Metaspace 도입

### Stream 중간연산 vs 최종연산
```java
 List list = Arrays. asList("a","b","c"); Stream  s = list. stream().map(String::toUpperCase); // 중간연산 List  out = s. collect(Collectors. toList()); // 최종연산
```

- **map()**: 1:1 매핑
- **flatMap()**: 1:N 평탄화
- 중간연산만으로는 원본 컬렉션 불변, 최종연산 시 실제 실행

### GC 알고리즘
- **ZGC**: Java 11+, 저지연, 멀티스레드 마킹·컴팩트
- **G1 GC**: 영역(Region) 단위 회수, Pause time 최소화
- **Parallel GC**: Serial GC 알고리즘에 멀티스레드 적용

### 콜바이 값 vs 콜바이 레퍼런스
- **Java**: 참조 값 자체를 복사 전달 → Call by Value

### 리플렉션 API
- 런타임 클래스·메서드·필드 정보 조회·호출
- **사용례**: Spring 빈 생성·DI, JUnit 테스트 메서드 자동 실행

### 추상클래스 vs 인터페이스
- **추상클래스**: 일부 구현 가능, 단일 상속
- **인터페이스**: 완전 추상(자바 8+ default/static 허용), 다중 구현

### JVM 메모리 구조
- **Heap**: 객체 저장
- **Method Area**: 클래스 메타데이터
- **Stack**: 각 스레드 호출 스택
- **PC Register**: 명령어 주소
- **Native Method Stack**: 네이티브 호출

### 제네릭(Generic)
- 컴파일 시 타입 안정성, 런타임 시 타입 소거

### 람다 vs 익명 클래스
- **람다**: 함수형 인터페이스 구현, 외부 this 참조
- **익명 클래스**: 별도 클래스 생성, this는 해당 인스턴스

### Major GC vs Minor GC
- **Minor**: Young 영역 대상, 빠르고 빈번
- **Major**: Old+Young 대상, 느리고 STW

### Java I/O vs NIO
- **NIO**: 비블로킹, 버퍼·채널, Selector(select/poll/epoll)

### Linux tail 구현 예
```java
Deque<String> dq = new ArrayDeque<>(10);
try (BufferedReader br = new BufferedReader(new FileReader("file.txt"))) {
    String line;
    while ((line = br.readLine()) != null) {
        if (dq.size() == 10) {
            dq.removeFirst();
        }
        dq.addLast(line);
    }
}
dq.forEach(System.out::println);
```


### Static 영역 vs Heap
- **Static**: 클래스 변수·메서드 상주, 애플리케이션 종료 시 소멸
- **Heap**: 런타임 객체 동적 할당, GC 관리

### main()이 static인 이유
- 인스턴스 생성 없이 JVM 진입점 호출

### 스레드별 스택·힙
- 각 스레드별 스택 생성(-Xss)
- 힙은 모든 스레드 공유(-Xms/-Xmx)

### Throwable vs Error vs Exception
- **Throwable**: 최상위
- **Error**: JVM 레벨 오류
- **Exception**: 애플리케이션 예외

## 2. 객체지향 프로그래밍 및 아키텍처

### SOLID 원칙
- **S**: Single Responsibility
- **O**: Open–Closed
- **L**: Liskov Substitution
- **I**: Interface Segregation
- **D**: Dependency Inversion

### TDD (Test-Driven Development)
- 테스트 작성 → 구현 → 리팩토링
- 초기 느림, 장기적 품질·유지보수 혜택

### SRP & Utils 클래스 지양
- 책임 하나, 변경 이유 하나
- Utils는 범용 책임 과다 → 유지보수 어려움

### OCP (개방-폐쇄 원칙)
- 확장에는 열려있고 변경에는 닫혀야

### DIP (의존성 역전 원칙)
- 추상화 의존, 구체화 독립
- DDD: 인프라 추상화, 애그리거트 설계

### 도메인 분리 & 책임 배분
- 복잡도 기준, Bounded Context, 애그리거트 경계

### 싱글톤 패턴 & 전역 필드
- 전역 상태 주의, 무상태(singleton stateless) 권장
- 멀티스레드 동시 접근 문제

### 디자인 패턴
- 전략패턴, 팩토리, 템플릿, 책임 연쇄, 빌더 등
- Spring: 캐싱, 메시징, 로그, 메일 발송

### equals & hashCode
- 동등성 비교, 해시 기반 컬렉션 필수

### DDD (Domain-Driven Design)
- 엔티티, 밸류 오브젝트, 애그리거트, 리포지토리, 도메인 서비스

### 클린 아키텍처 vs 헥사고날
- **Clean**: 레이어, 의존성 안쪽으로
- **Hexagonal**: Port & Adapter, 도메인 중심

### MSA 분산 트랜잭션
- **2PC**: 원자성 보장, 지연
- **SAGA**: 최종 일관성, 보상 트랜잭션

### DTO 사용 이유
- 엔티티 노출 방지, 민감 정보 숨김, API 스펙 일관성

## 3. 스프링 프레임워크

### Spring 요약
- IoC/DI 기반 경량 엔터프라이즈 프레임워크
- 모듈화: Core, Context, Web, Security, Batch, Cloud 등

### 요청→응답 처리 흐름
1. WAS → Filter Chain
2. DispatcherServlet
3. HandlerMapping → Controller
4. ViewResolver → View 렌더링

### Servlet & DispatcherServlet
- **Servlet**: HttpServlet 상속, 요청/응답 처리
- **DispatcherServlet**: Front Controller

### Spring Thread-Safe 기법
- synchronized, 불변 객체, ThreadLocal, 동시성 컬렉션
- @Version(낙관적 락), @Transactional(비관적 락)

### @Transactional & Propagation
- 경계 설정, 속성: propagation, isolation, timeout, readOnly, rollbackFor
- **전파**: REQUIRED, REQUIRES_NEW, SUPPORTS, NOT_SUPPORTED, NEVER, NESTED

### Bean Scope: Singleton vs Prototype
- **Singleton**: 컨테이너당 1개
- **Prototype**: 요청 시마다 새 인스턴스

### Spring 싱글톤 vs 디자인 패턴 싱글톤
- **Spring**: 컨테이너 관리, DI, 외부 설정
- **패턴**: 클래스 내부 관리

### 싱글톤 레지스트리
- ApplicationContext가 Bean 인스턴스 관리

### Spring에서 싱글톤 사용 시기
- DataSource, SecurityContextHolder, 설정 빈 등

### Filter vs Interceptor
- **Filter**: Servlet Spec, doFilter()
- **Interceptor**: Spring MVC, preHandle/postHandle/afterCompletion

### 순환참조 해결
- @Lazy, 설계 개선(의존 분리)

### ThreadLocal
- 스레드별 저장, 로깅, 사용자 컨텍스트, 종료 시 remove()

### AOP: Aspect, JoinPoint, Advice, Target
- **Aspect**: 공통 관심사 모듈
- **JoinPoint**: 실행 지점
- **Advice**: 실행 코드(Before/After/Around)
- **Pointcut**: JoinPoint 선택 규칙
- **Target**: Advice 대상 객체

### Weaving: CTW, LTW, RTW
- **CTW**: 컴파일
- **LTW**: 로드 시
- **RTW**: 런타임 프록시(Dynamic Proxy/CGLIB)

### DI 방식 & 생성자 주입 장점
- 생성자, Setter, 필드, 일반 메서드
- **생성자 주입**: 불변성, 순환참조 조기 발견

### ApplicationContext & Aware
- IoC 컨테이너, 빈 생명주기·이벤트·국제화
- ApplicationContextAware: 컨테이너 참조

### Spring 모듈화 & Boot Auto-Configuration
- **모듈**: Core, Beans, AOP, JDBC, ORM, Web, Test
- **Boot**: Starter → 자동 설정, @ConfigurationProperties, @Value
# 스프링 Data JPA 및 queryDSL


## 1. JPA 동시성 제어 기능
- **트랜잭션 격리 수준**: `@Transactional(isolation = …)`으로 `READ_UNCOMMITTED`, `READ_COMMITTED`, `REPEATABLE_READ`, `SERIALIZABLE` 설정
- **낙관적 락(Optimistic Lock)**: `@Version` 애노테이션으로 버전 관리 → 충돌 시 `ObjectOptimisticLockingFailureException`
- **비관적 락(Pessimistic Lock)**: `@Lock(LockModeType.PESSIMISTIC_WRITE)` 또는 `entityManager.lock()`
- **Select for Update**: `@Query("… FOR UPDATE")` 또는 `@Lock(LockModeType.PESSIMISTIC_READ)`
- **EntityGraph**: `@EntityGraph(attributePaths = {…})`로 연관 엔티티 즉시 페치

## 2. 영속성 컨텍스트
- 애플리케이션 ↔ DB 사이 1차 캐시
- **1차 캐시**: 조회된 엔티티를 영속 컨텍스트에 보관 → 동일성 보장
- **더티 체킹**: 트랜잭션 커밋 시 변경 감지 → 자동 UPDATE
- **쓰기 지연**: 변경 쿼리 모아뒀다가 플러시 시점에 실행

## 3. OSIV(Open Session/EntityManager In View)
- 기본 `true`: 뷰 렌더링 시점까지 EntityManager 열림
- 장점: 뷰에서 LAZY 로딩 가능
- 단점: DB 커넥션 장시간 점유 → 커넥션 풀 고갈 위험
- 해제: `spring.jpa.open-in-view=false` → 서비스 레이어 내에서 모든 연관 조회 완료 필요

## 4. JPA 성능 vs 다른 ORM
- **단점**: 표준 추상화 계층 오버헤드, 복잡한 쿼리 튜닝 어려움
- **이점**: 표준 준수, 벤더 독립성, 영속성 관리(캐시·더티체킹), 개발 생산성

## 5. JPA + queryDSL 사용 이유
- JPA: 객체지향 모델 ↔ 관계형 매핑, 영속성 관리 자동화
- queryDSL: 타입 안전한 동적 쿼리, 컴파일 시 문법 검증, 문자열 JPQL 대체

## 6. N+1 문제 & 해결
- **원인**: LAZY 연관 엔티티 접근 시 추가 SELECT N회
- **Fetch Join**: `@Query("SELECT o FROM Order o JOIN FETCH o.items")` → INNER JOIN
- **EntityGraph**: `@EntityGraph(attributePaths = {"items"})` → OUTER JOIN
- **SUBSELECT**: `@Fetch(FetchMode.SUBSELECT)`
- **BatchSize**: `@BatchSize(size = N)` → IN절 반복

## 7. 영속 상태 vs 준영속 상태
- **영속(Persistent)**: 영속성 컨텍스트 관리, 변경 감지 대상
- **준영속(Detached)**: 컨텍스트 분리, 변경 감지 안 됨
- **병합(Merge)**: `entityManager.merge(detachedEntity)` → 영속화
- **사용례**: DTO로 변환 후 다시 병합 시 버전 관리

## 8. QueryDSL 코드 리팩토링 포인트
- 중복 쿼리 조립 로직 메서드화
- `BooleanBuilder` 또는 `Where` 절 체이닝
- 프로젝션: `Projections.constructor()` 대신 DTO 생성자 표현

## 9. 다대다 순환참조 해결
- **DTO 변환**: 엔티티 노출 방지, 필요한 필드만 맵핑
- **@JsonIgnore**: 한 쪽 필드 무시
- **@JsonManagedReference / @JsonBackReference**: 부모·자식 관계 명시

## 10. MyBatis vs JPA
- **MyBatis**: SQL 직접 작성, XML 매핑, 튜닝 자유
- **JPA**: 추상화 CRUD, 영속성 관리, 표준 호환
- **Trade-off**: 유연성 vs 생산성·유지보수

## 11. JPA 서브쿼리 사용
- JPQL: `WHERE x IN (SELECT y …)` 가능
- FROM/SELECT 절 서브쿼리: Hibernate `@Subselect`, `@Immutable` 사용

## 12. 양방향 연관관계 문제
- **순환 참조**: JSON 직렬화 무한 루프
- **데이터 무결성**: 양쪽 동기화 누락 시 불일치
- **N+1 이슈**: 추가 쿼리 발생

## 13. 엔티티 설계 시 주의
- 클래스·필드명과 테이블·컬럼명 일치 또는 `@Table`/`@Column` 지정
- 기본 생성자(no-arg) 필수
- 직렬화 불필요 시 `Serializable` 생략 가능

## 14. 서비스 레이어 도메인 반환 문제
- OSIV 꺼짐 → LAZY 로딩 예외
- 도메인 노출 → 민감 정보 유출
- 해결: DTO 반환, 필요한 연관 미리 조회  
# 스프링 시큐리티 및 암·복호화 관련

## 1. SecurityContext 정보 삭제 이유
- **세션 하이재킹 방지**: SecurityContext에 인증 정보가 남아 있으면 악의적 접근 시 탈취 가능
- **메모리 누수 방지**: ThreadLocal에 바인딩된 SecurityContext가 남아 GC 대상에서 제외
- **스레드 재사용 이슈**: ThreadPool 스레드 재사용 시 이전 요청의 인증 정보 노출

## 2. 인증(Authentication) vs 인가(Authorization)
- **인증(Authentication)**: 사용자 신원 확인 (로그인, 자격 증명 검증)
- **인가(Authorization)**: 인증된 사용자의 권한 확인 및 리소스 접근 제어

## 3. JWT(Json Web Token) 사용 이유
- **무상태(stateless)**: 서버에 토큰 저장 불필요, 수평 확장 용이
- **다양한 프로토콜 지원**: JSON 형식으로 HTTP 외 다른 프로토콜에도 사용 가능
- **SSO(싱글 사인온)**: 분산 시스템 간 토큰 공유로 단일 로그인 구현
- **확장성**: 사용자 정의 클레임(roles, permissions 등) 포함 가능

## 4. 로컬 세션 vs JWT Stateless 전환 이유
- **로컬 세션**: 서버 메모리·DB 기반 세션 관리 → 상태 저장(상태풀)
- **JWT**: 클라이언트에 토큰 저장 → 서버 무상태(상태리스)
    - 세션 동기화·확장성 이슈 해소
    - API 게이트웨이, 마이크로서비스 환경에서 효율적

## 5. OAuth 없이 JWT 선택 이유
- **간결성**: 별도 인증 서버 불필요, 직접 토큰 생성·검증
- **부하 감소**: 세션 저장소 조회 없이 토큰만으로 인증 처리
- **프라이버시 보호**: 클라이언트에 토큰 저장, 서버에 사용자 데이터 비저장
- **프로토콜 독립적**: OAuth 복잡도 없이 다양한 서비스에 적용

## 6. JWT 토큰 탈취 위험 대응 방안
- **HTTPS 적용**: 네트워크 중간 탈취 방지
- **토큰 만료 설정**: 액세스/리프레시 토큰 별도 만료시간
- **토큰 최소화**: 클레임 정보 최소화로 탈취 피해 축소
- **SameSite/CORS 설정**: CSRF 방지
- **리프레시 토큰 블랙리스트**: 탈취 시 강제 만료 처리
- **토큰 재발급 로직**: 비정상 요청 시 재발급 차단

## 7. 대칭키 암호화 vs 비대칭키 암호화
- **대칭키 암호화**
    - 동일 키로 암호화·복호화
    - 알고리즘: AES, DES, Blowfish
    - 장점: 빠르고 대용량 데이터 처리 적합
- **비대칭키 암호화**
    - 공개키(암호화) + 개인키(복호화)
    - 알고리즘: RSA, ECC
    - 장점: 키 교환 안전, 디지털 서명 사용

## 8. HTTPS 암호화 방식
1. **TLS 핸드셰이크**
    - 비대칭키 암호화(ECDHE/RSA)로 세션 키 교환
2. **세션 키(대칭키)**
    - AES 등 대칭키로 본문 데이터 암호화  


# 인프라 관련

## 프록시 (Proxy)
- **정의**: 클라이언트와 서버 사이의 중개 역할을 수행하는 네트워크 엔티티
- **Forward Proxy**
    - 클라이언트 측에 위치
    - 클라이언트의 실제 IP 감춤, 요청 캐싱, 접근 제어
    - 사용 예: 사내 네트워크의 인터넷 접속 제어, 캐싱 프록시(server-side cache)
- **Reverse Proxy**
    - 서버 측에 위치 (WAF, 로드밸런서)
    - 서버의 실제 IP 감춤, SSL 종료, 로드밸런싱, 캐싱
    - 사용 예: CDN 앞단, Nginx/HAProxy를 통한 요청 분산

## Nginx vs Tomcat
- **Nginx**
    - **아키텍처**: 이벤트 드리븐 비동기 I/O 모델
        - Master Process: 설정 읽기, Worker Process 관리
        - Worker Process: 실제 요청 처리 (CPU 코어 수만큼 생성)
        - 단일 스레드가 이벤트 루프로 다수 연결 처리
    - **성능 특성**
        - 낮은 메모리 사용량 (연결당 ~2.5KB)
        - C10K 문제 해결 (10,000개 동시 연결 처리)
        - CPU 집약적 작업에는 부적합
    - **주요 기능**
        - 정적 파일 서빙 최적화
        - 리버스 프록시 & 로드밸런서
        - SSL/TLS 종료, HTTP/2 지원
        - 캐싱, 압축, Rate Limiting
    - **설정 예시**
        ```nginx
        upstream backend {
            server 127.0.0.1:8080;
            server 127.0.0.1:8081;
        }
        server {
            listen 80;
            location / {
                proxy_pass http://backend;
            }
        }
        ```

- **Tomcat**
    - **아키텍처**: 스레드 풀 기반 동기 I/O 모델
        - Connector: HTTP 요청 수신 (NIO, APR 커넥터 지원)
        - Thread Pool: 요청별 스레드 할당 처리
        - Servlet Container: 서블릿 생명주기 관리
    - **성능 특성**
        - 연결당 스레드 할당 → 메모리 사용량 높음
        - 동적 컨텐츠 처리에 최적화
        - 스레드 풀 크기에 따른 동시성 제한
    - **주요 기능**
        - 서블릿/JSP 컨테이너
        - JNDI, JTA 트랜잭션 지원
        - 클러스터링, 세션 복제
        - JMX 모니터링
    - **설정 예시**
        ```xml
        <Connector port="8080" protocol="HTTP/1.1"
                   maxThreads="200" minSpareThreads="10"
                   connectionTimeout="20000" />
        ```

- **성능 비교**
    - **정적 컨텐츠**: Nginx >> Tomcat
    - **동적 컨텐츠**: Tomcat > Nginx (FastCGI/uWSGI 필요)
    - **동시 연결**: Nginx >> Tomcat
    - **메모리 효율성**: Nginx >> Tomcat

- **실제 운영 패턴**
    - **Nginx + Tomcat**: 가장 일반적인 구성
        - Nginx: 정적 파일, SSL 종료, 로드밸런싱
        - Tomcat: Java 애플리케이션 처리
    - **단독 Tomcat**: 소규모 애플리케이션
    - **Nginx만**: 정적 사이트, API Gateway

## 메시지 큐, 메시지 브로커, 스트림

### 메시지 큐(Message Queue)
- **핵심 개념**
    - **FIFO 순서 보장**: 메시지가 큐에 들어간 순서대로 처리
    - **Point-to-Point 모델**: 하나의 메시지는 하나의 소비자만 처리
    - **비동기 통신**: 생산자와 소비자 간 시간적 분리
- **주요 특징**
    - **내구성(Durability)**: 메시지 영속 저장으로 시스템 장애 시에도 보존
    - **가시성 타임아웃**: 메시지 처리 중 장애 시 다른 소비자가 재처리
    - **Dead Letter Queue**: 처리 실패 메시지 별도 보관
- **구현 예시 (Amazon SQS)**
    ```python
    # 메시지 전송
    sqs.send_message(
        QueueUrl='https://sqs.region.amazonaws.com/account/queue',
        MessageBody='{"orderId": 12345, "status": "pending"}'
    )

    # 메시지 수신 및 처리
    messages = sqs.receive_message(QueueUrl=queue_url, MaxNumberOfMessages=10)
    for message in messages.get('Messages', []):
        # 메시지 처리 로직
        process_order(message['Body'])
        # 처리 완료 후 삭제
        sqs.delete_message(QueueUrl=queue_url, ReceiptHandle=message['ReceiptHandle'])
    ```

### 메시지 브로커(Message Broker)
- **고급 메시징 패턴**
    - **Publish/Subscribe**: 하나의 메시지를 여러 구독자에게 전달
    - **Request/Reply**: 동기식 요청-응답 패턴
    - **Routing**: 메시지 헤더/내용 기반 라우팅
- **핵심 기능**
    - **Exchange & Binding**: 메시지 라우팅 규칙 정의
    - **메시지 변환**: 프로토콜/포맷 변환 (JSON ↔ XML)
    - **트랜잭션 지원**: ACID 속성 보장
    - **클러스터링**: 고가용성 및 확장성
- **RabbitMQ 예시**
    ```python
    # Exchange 선언 및 바인딩
    channel.exchange_declare(exchange='order_events', exchange_type='topic')
    channel.queue_declare(queue='payment_queue', durable=True)
    channel.queue_bind(exchange='order_events', queue='payment_queue', routing_key='order.payment.*')

    # 메시지 발행
    channel.basic_publish(
        exchange='order_events',
        routing_key='order.payment.created',
        body=json.dumps({'orderId': 12345, 'amount': 100.0}),
        properties=pika.BasicProperties(delivery_mode=2)  # 영속성
    )
    ```

### 스트림 처리(Stream Processing)
- **실시간 데이터 처리**
    - **무한 데이터 스트림**: 끝이 없는 연속적인 데이터 흐름
    - **낮은 지연시간**: 밀리초 단위 실시간 처리
    - **상태 관리**: 윈도우 기반 집계, 조인 연산
- **처리 패턴**
    - **Windowing**: 시간/개수 기반 데이터 그룹핑
        - Tumbling Window: 겹치지 않는 고정 크기 윈도우
        - Sliding Window: 겹치는 이동 윈도우
        - Session Window: 비활성 기간 기반 동적 윈도우
    - **Event Time vs Processing Time**: 이벤트 발생 시간 vs 처리 시간
- **Apache Kafka Streams 예시**
    ```java
    StreamsBuilder builder = new StreamsBuilder();
    KStream<String, String> orders = builder.stream("orders");

    // 5분 윈도우로 주문 금액 집계
    orders
        .groupByKey()
        .windowedBy(TimeWindows.of(Duration.ofMinutes(5)))
        .aggregate(
            () -> 0.0,
            (key, value, aggregate) -> aggregate + parseAmount(value),
            Materialized.as("order-amounts-store")
        )
        .toStream()
        .to("order-aggregates");
    ```

### 아키텍처 패턴 비교
- **메시지 큐**: 작업 분산, 부하 평준화, 장애 복구
    - 사용 사례: 이메일 발송, 이미지 처리, 배치 작업
- **메시지 브로커**: 복잡한 라우팅, 시스템 통합, 이벤트 기반 아키텍처
    - 사용 사례: 마이크로서비스 통신, EAI, 워크플로우 관리
- **스트림 처리**: 실시간 분석, 이벤트 스트림 처리, 복합 이벤트 처리
    - 사용 사례: 실시간 대시보드, 이상 탐지, 개인화 추천

### 성능 및 확장성 고려사항
- **처리량(Throughput)**: Kafka > RabbitMQ > SQS
- **지연시간(Latency)**: Redis Streams < Kafka < RabbitMQ < SQS
- **내구성**: SQS ≈ RabbitMQ > Kafka > Redis
- **운영 복잡도**: SQS < RabbitMQ < Kafka < Apache Flink

## AWS VPC 및 Subnet/NAT 설정
- **Public Subnet**: 인터넷 게이트웨이(IGW) 연결 → 퍼블릭 IP로 직접 액세스
- **Private Subnet**: IGW 미연결 → NAT Gateway 통해 아웃바운드 인터넷 액세스
- **설정 절차**
    1. VPC 생성 → CIDR 블록 지정
    2. Public/Private Subnet 생성
    3. IGW 연결 → Public Subnet 라우팅 테이블에 0.0.0.0/0 → IGW
    4. NAT Gateway 생성(공용 Elastic IP) → Private Subnet 라우팅 테이블에 0.0.0.0/0 → NAT GW

## CI/CD – Blue/Green 배포

### 핵심 개념
- **환경 분리**: 동일한 프로덕션 환경을 두 개(Blue/Green) 병렬 운영
- **원자적 전환**: 트래픽을 한 번에 새 환경으로 완전 전환
- **즉시 롤백**: 문제 발생 시 이전 환경으로 즉시 복구

### 상세 배포 절차
1. **준비 단계**
   - Green 환경 프로비저닝 (Blue와 동일한 인프라)
   - 데이터베이스 마이그레이션 스크립트 준비
   - 헬스체크 엔드포인트 구성

2. **배포 단계**
   ```bash
   # Green 환경에 새 버전 배포
   kubectl apply -f green-deployment.yaml
   kubectl rollout status deployment/app-green

   # 헬스체크 확인
   curl -f http://green-env/health || exit 1
   ```

3. **검증 단계**
   - **스모크 테스트**: 핵심 기능 동작 확인
   - **성능 테스트**: 응답시간, 처리량 검증
   - **통합 테스트**: 외부 시스템 연동 확인
   ```yaml
   # Kubernetes 헬스체크 예시
   livenessProbe:
     httpGet:
       path: /health
       port: 8080
     initialDelaySeconds: 30
     periodSeconds: 10
   readinessProbe:
     httpGet:
       path: /ready
       port: 8080
     initialDelaySeconds: 5
     periodSeconds: 5
   ```

4. **트래픽 전환**
   - **DNS 기반**: Route53 Weighted Routing
   - **로드밸런서 기반**: ALB Target Group 전환
   - **Service Mesh**: Istio Virtual Service 가중치 조정
   ```yaml
   # Istio 트래픽 전환 예시
   apiVersion: networking.istio.io/v1beta1
   kind: VirtualService
   spec:
     http:
     - match:
       - headers:
           canary:
             exact: "true"
       route:
       - destination:
           host: app-service
           subset: green
         weight: 100
     - route:
       - destination:
           host: app-service
           subset: blue
         weight: 0  # 전체 트래픽을 Green으로
   ```

5. **모니터링 & 롤백**
   ```bash
   # 메트릭 모니터링
   kubectl top pods -l version=green

   # 에러율 확인
   curl -s "http://prometheus:9090/api/v1/query?query=rate(http_requests_total{status=~'5..'}[5m])"

   # 롤백 (필요시)
   kubectl patch service app-service -p '{"spec":{"selector":{"version":"blue"}}}'
   ```

### 구현 패턴

#### 1. 인프라 레벨 Blue/Green
- **AWS**: Auto Scaling Group + ALB Target Group 전환
- **Kubernetes**: Deployment + Service Selector 전환
- **Docker**: Container 교체 + Nginx Upstream 전환

#### 2. 애플리케이션 레벨 Blue/Green
```java
@Component
public class FeatureToggleService {
    @Value("${deployment.version}")
    private String deploymentVersion;

    public boolean isNewFeatureEnabled() {
        return "green".equals(deploymentVersion);
    }
}
```

#### 3. 데이터베이스 고려사항
- **Forward Compatible Schema**: 하위 호환성 유지
- **Database Migration**: 점진적 스키마 변경
```sql
-- 안전한 컬럼 추가 (NULL 허용)
ALTER TABLE users ADD COLUMN new_field VARCHAR(255) NULL;

-- 기본값 설정 후 NOT NULL 변경
UPDATE users SET new_field = 'default_value' WHERE new_field IS NULL;
ALTER TABLE users MODIFY new_field VARCHAR(255) NOT NULL;
```

### 고급 배포 전략

#### Canary with Blue/Green
```yaml
# 1단계: 5% 트래픽을 Green으로
- route:
  - destination: { host: app, subset: green }
    weight: 5
  - destination: { host: app, subset: blue }
    weight: 95

# 2단계: 문제없으면 100% 전환
- route:
  - destination: { host: app, subset: green }
    weight: 100
```

#### Feature Flag 통합
```javascript
// 런타임 기능 토글
const featureFlags = {
  newPaymentFlow: process.env.DEPLOYMENT_ENV === 'green',
  enhancedUI: process.env.FEATURE_ENHANCED_UI === 'true'
};

if (featureFlags.newPaymentFlow) {
  return processPaymentV2(request);
} else {
  return processPaymentV1(request);
}
```

### 모니터링 및 알림
- **핵심 메트릭**
  - 응답시간 (P95, P99)
  - 에러율 (4xx, 5xx)
  - 처리량 (RPS)
  - 리소스 사용률 (CPU, Memory)

- **알림 설정**
```yaml
# Prometheus Alert 예시
- alert: HighErrorRate
  expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
  for: 2m
  annotations:
    summary: "High error rate detected in {{ $labels.version }} environment"
```

### 장단점 분석
- **장점**
  - **무중단 배포**: 서비스 중단 없이 배포
  - **즉시 롤백**: 문제 발생 시 빠른 복구 (초 단위)
  - **위험 최소화**: 전체 트래픽 전환 전 충분한 검증
  - **A/B 테스트**: 두 버전 동시 운영으로 성능 비교

- **단점**
  - **인프라 비용**: 2배 리소스 필요 (일시적)
  - **복잡성**: 배포 파이프라인 복잡도 증가
  - **데이터 동기화**: 상태 저장 애플리케이션 처리 복잡
  - **트랜잭션 처리**: 배포 중 진행 중인 트랜잭션 관리

### 적용 사례
- **적합한 경우**: 무상태 웹 애플리케이션, API 서버, 마이크로서비스
- **부적합한 경우**: 데이터베이스, 상태 저장 서비스, 레거시 모놀리스

## Apache Httpd vs Nginx
- **Apache**
    - MPM(Multi-Process Module) 기반 → 프로세스/스레드 풀
    - 모듈 확장성, .htaccess 지원, 동적 컨텐츠 처리 용이
    - 동시 연결 처리 시 메모리·CPU 부담
- **Nginx**
    - 이벤트 드리븐 비동기 모델 → 적은 스레드로 다수 연결 처리
    - 정적 컨텐츠, 리버스 프록시, 캐싱 최적
    - 동적 컨텐츠는 백엔드 WAS 연동 필요

## Jenkins를 통한 배포

### Pipeline as Code (Jenkinsfile)
- **선언적 파이프라인 (Declarative Pipeline)**
```groovy
pipeline {
    agent any

    environment {
        DOCKER_REGISTRY = 'your-registry.com'
        APP_NAME = 'my-app'
        KUBECONFIG = credentials('kubeconfig')
    }

    stages {
        stage('Checkout') {
            steps {
                git branch: 'main', url: 'https://github.com/your-org/your-repo.git'
            }
        }

        stage('Build') {
            steps {
                sh 'mvn clean compile'
            }
        }

        stage('Test') {
            parallel {
                stage('Unit Tests') {
                    steps {
                        sh 'mvn test'
                    }
                    post {
                        always {
                            publishTestResults testResultsPattern: 'target/surefire-reports/*.xml'
                        }
                    }
                }
                stage('Integration Tests') {
                    steps {
                        sh 'mvn verify -Pintegration-tests'
                    }
                }
            }
        }

        stage('Code Quality') {
            steps {
                withSonarQubeEnv('SonarQube') {
                    sh 'mvn sonar:sonar'
                }
            }
        }

        stage('Package') {
            steps {
                sh 'mvn package -DskipTests'
                archiveArtifacts artifacts: 'target/*.jar', fingerprint: true
            }
        }

        stage('Docker Build') {
            steps {
                script {
                    def image = docker.build("${DOCKER_REGISTRY}/${APP_NAME}:${BUILD_NUMBER}")
                    docker.withRegistry("https://${DOCKER_REGISTRY}", 'docker-registry-credentials') {
                        image.push()
                        image.push('latest')
                    }
                }
            }
        }

        stage('Deploy to Staging') {
            steps {
                sh """
                    helm upgrade --install ${APP_NAME}-staging ./helm-chart \
                        --set image.tag=${BUILD_NUMBER} \
                        --set environment=staging \
                        --namespace staging
                """
            }
        }

        stage('Smoke Tests') {
            steps {
                sh 'curl -f http://staging.your-app.com/health || exit 1'
            }
        }

        stage('Deploy to Production') {
            when {
                branch 'main'
            }
            steps {
                input message: 'Deploy to production?', ok: 'Deploy'
                sh """
                    helm upgrade --install ${APP_NAME} ./helm-chart \
                        --set image.tag=${BUILD_NUMBER} \
                        --set environment=production \
                        --namespace production
                """
            }
        }
    }

    post {
        always {
            cleanWs()
        }
        failure {
            emailext (
                subject: "Build Failed: ${env.JOB_NAME} - ${env.BUILD_NUMBER}",
                body: "Build failed. Check console output at ${env.BUILD_URL}",
                to: "${env.CHANGE_AUTHOR_EMAIL}"
            )
        }
        success {
            slackSend channel: '#deployments',
                     color: 'good',
                     message: "✅ ${env.JOB_NAME} #${env.BUILD_NUMBER} deployed successfully"
        }
    }
}
```

### 스크립트 파이프라인 (Scripted Pipeline)
```groovy
node {
    try {
        stage('Checkout') {
            checkout scm
        }

        stage('Build & Test') {
            parallel(
                'Build': {
                    sh 'mvn clean package -DskipTests'
                },
                'Unit Tests': {
                    sh 'mvn test'
                    publishTestResults testResultsPattern: 'target/surefire-reports/*.xml'
                }
            )
        }

        stage('Deploy') {
            if (env.BRANCH_NAME == 'main') {
                sh 'kubectl apply -f k8s/'
                sh 'kubectl rollout status deployment/my-app'
            }
        }

    } catch (Exception e) {
        currentBuild.result = 'FAILURE'
        throw e
    } finally {
        // 정리 작업
        sh 'docker system prune -f'
    }
}
```

### 고급 배포 패턴

#### 1. Blue/Green 배포 with Jenkins
```groovy
stage('Blue/Green Deploy') {
    steps {
        script {
            def currentColor = sh(
                script: "kubectl get service my-app -o jsonpath='{.spec.selector.version}'",
                returnStdout: true
            ).trim()

            def newColor = currentColor == 'blue' ? 'green' : 'blue'

            // 새 버전 배포
            sh """
                kubectl set image deployment/my-app-${newColor} \
                    app=${DOCKER_REGISTRY}/${APP_NAME}:${BUILD_NUMBER}
                kubectl rollout status deployment/my-app-${newColor}
            """

            // 헬스체크
            sh "curl -f http://my-app-${newColor}.staging.svc.cluster.local/health"

            // 트래픽 전환
            sh """
                kubectl patch service my-app \
                    -p '{"spec":{"selector":{"version":"${newColor}"}}}'
            """

            // 이전 버전 정리 (선택적)
            timeout(time: 5, unit: 'MINUTES') {
                input message: "Delete old ${currentColor} deployment?", ok: 'Delete'
                sh "kubectl delete deployment my-app-${currentColor}"
            }
        }
    }
}
```

#### 2. Canary 배포
```groovy
stage('Canary Deploy') {
    steps {
        script {
            // 10% 트래픽으로 Canary 배포
            sh """
                kubectl apply -f - <<EOF
apiVersion: argoproj.io/v1alpha1
kind: Rollout
spec:
  strategy:
    canary:
      steps:
      - setWeight: 10
      - pause: {duration: 5m}
      - setWeight: 50
      - pause: {duration: 10m}
      - setWeight: 100
EOF
            """
        }
    }
}
```

### 멀티브랜치 파이프라인
```groovy
// Jenkinsfile
pipeline {
    agent any

    stages {
        stage('Build') {
            steps {
                sh 'mvn clean package'
            }
        }

        stage('Deploy') {
            when {
                anyOf {
                    branch 'main'
                    branch 'develop'
                    branch 'PR-*'
                }
            }
            steps {
                script {
                    def environment = env.BRANCH_NAME == 'main' ? 'production' : 
                                    env.BRANCH_NAME == 'develop' ? 'staging' : 'review'

                    sh """
                        helm upgrade --install my-app-${environment} ./helm-chart \
                            --set image.tag=${BUILD_NUMBER} \
                            --set environment=${environment} \
                            --namespace ${environment}
                    """
                }
            }
        }
    }
}
```

### Jenkins 플러그인 활용

#### 1. 핵심 플러그인
- **Pipeline**: 파이프라인 기능
- **Git**: Git 저장소 연동
- **Docker Pipeline**: Docker 이미지 빌드/푸시
- **Kubernetes**: K8s 클러스터 배포
- **SonarQube Scanner**: 코드 품질 분석
- **Slack Notification**: 알림 발송

#### 2. 보안 관리
```groovy
// Credentials 사용
withCredentials([
    usernamePassword(credentialsId: 'docker-registry', 
                    usernameVariable: 'DOCKER_USER', 
                    passwordVariable: 'DOCKER_PASS'),
    file(credentialsId: 'kubeconfig', variable: 'KUBECONFIG_FILE')
]) {
    sh 'docker login -u $DOCKER_USER -p $DOCKER_PASS'
    sh 'kubectl --kubeconfig=$KUBECONFIG_FILE apply -f deployment.yaml'
}
```

### 성능 최적화

#### 1. 병렬 처리
```groovy
stage('Parallel Tasks') {
    parallel {
        'Unit Tests': {
            sh 'mvn test'
        },
        'Static Analysis': {
            sh 'mvn spotbugs:check'
        },
        'Security Scan': {
            sh 'mvn dependency-check:check'
        }
    }
}
```

#### 2. 캐싱 전략
```groovy
stage('Build with Cache') {
    steps {
        // Maven 의존성 캐싱
        sh '''
            if [ ! -d "$HOME/.m2/repository" ]; then
                mkdir -p $HOME/.m2/repository
            fi
            mvn clean package -Dmaven.repo.local=$HOME/.m2/repository
        '''
    }
}
```

### 모니터링 및 알림
```groovy
post {
    always {
        // 테스트 결과 발행
        publishTestResults testResultsPattern: 'target/surefire-reports/*.xml'

        // 코드 커버리지
        publishCoverage adapters: [jacocoAdapter('target/site/jacoco/jacoco.xml')]

        // 아티팩트 보관
        archiveArtifacts artifacts: 'target/*.jar', allowEmptyArchive: true
    }

    failure {
        // 실패 시 알림
        emailext (
            subject: "❌ Build Failed: ${env.JOB_NAME} #${env.BUILD_NUMBER}",
            body: """
                Build failed for ${env.JOB_NAME} #${env.BUILD_NUMBER}

                Branch: ${env.BRANCH_NAME}
                Commit: ${env.GIT_COMMIT}

                Console Output: ${env.BUILD_URL}console
            """,
            to: "${env.CHANGE_AUTHOR_EMAIL}"
        )

        slackSend channel: '#ci-cd',
                 color: 'danger',
                 message: "❌ ${env.JOB_NAME} #${env.BUILD_NUMBER} failed"
    }

    success {
        slackSend channel: '#deployments',
                 color: 'good',
                 message: "✅ ${env.JOB_NAME} #${env.BUILD_NUMBER} deployed to ${env.DEPLOY_ENV}"
    }
}
```

### 베스트 프랙티스
- **파이프라인 버전 관리**: Jenkinsfile을 Git으로 관리
- **환경별 설정 분리**: 환경변수와 ConfigMap 활용
- **시크릿 관리**: Jenkins Credentials Store 사용
- **빌드 최적화**: 병렬 처리와 캐싱 활용
- **실패 빠른 감지**: 단계별 검증과 조기 실패
- **롤백 전략**: 이전 버전으로 빠른 복구 방안
- **모니터링**: 배포 후 헬스체크와 메트릭 확인

## 로드밸런싱 (Load Balancing)

### 핵심 개념
- **목적**: 트래픽 분산을 통한 서버 부하 균등화, 가용성 및 확장성 확보
- **고가용성**: 단일 장애점(SPOF) 제거
- **확장성**: 수평적 스케일링 지원
- **성능 최적화**: 응답시간 단축 및 처리량 증대

### 로드밸런서 유형

#### 1. Layer 4 (Network Load Balancer)
- **동작 레벨**: TCP/UDP 전송 계층
- **라우팅 기준**: IP 주소, 포트 번호
- **특징**
    - 빠른 처리 속도 (패킷 헤더만 검사)
    - 프로토콜 독립적
    - SSL 터미네이션 불가
    - 세션 유지 어려움
- **사용 사례**: 고성능 TCP 서비스, 게임 서버, IoT 디바이스 통신

```nginx
# Nginx L4 로드밸런싱 예시
stream {
    upstream backend {
        server 192.168.1.10:3306 weight=3;
        server 192.168.1.11:3306 weight=1;
        server 192.168.1.12:3306 backup;
    }

    server {
        listen 3306;
        proxy_pass backend;
        proxy_timeout 1s;
        proxy_responses 1;
    }
}
```

#### 2. Layer 7 (Application Load Balancer)
- **동작 레벨**: HTTP/HTTPS 애플리케이션 계층
- **라우팅 기준**: URL 경로, HTTP 헤더, 쿠키
- **특징**
    - 콘텐츠 기반 라우팅
    - SSL 터미네이션 지원
    - 세션 어피니티 제공
    - 상대적으로 높은 지연시간
- **사용 사례**: 웹 애플리케이션, REST API, 마이크로서비스

```nginx
# Nginx L7 로드밸런싱 예시
upstream api_servers {
    server api1.example.com:8080 weight=3;
    server api2.example.com:8080 weight=2;
    server api3.example.com:8080 weight=1;
}

upstream web_servers {
    server web1.example.com:80;
    server web2.example.com:80;
}

server {
    listen 80;

    location /api/ {
        proxy_pass http://api_servers;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }

    location / {
        proxy_pass http://web_servers;
    }
}
```

### 로드밸런싱 알고리즘

#### 1. Round Robin
- **동작**: 서버 목록을 순차적으로 순환
- **장점**: 구현 단순, 균등 분배
- **단점**: 서버 성능 차이 미고려
```python
class RoundRobinBalancer:
    def __init__(self, servers):
        self.servers = servers
        self.current = 0

    def get_server(self):
        server = self.servers[self.current]
        self.current = (self.current + 1) % len(self.servers)
        return server
```

#### 2. Weighted Round Robin
- **동작**: 서버별 가중치에 따라 요청 분배
- **장점**: 서버 성능 차이 반영
- **단점**: 정적 가중치, 실시간 부하 미반영
```python
class WeightedRoundRobinBalancer:
    def __init__(self, servers_weights):
        self.servers = []
        for server, weight in servers_weights:
            self.servers.extend([server] * weight)
        self.current = 0

    def get_server(self):
        server = self.servers[self.current]
        self.current = (self.current + 1) % len(self.servers)
        return server
```

#### 3. Least Connections
- **동작**: 현재 연결 수가 가장 적은 서버 선택
- **장점**: 실시간 부하 반영
- **단점**: 연결 수 추적 오버헤드
```python
class LeastConnectionsBalancer:
    def __init__(self, servers):
        self.servers = {server: 0 for server in servers}

    def get_server(self):
        return min(self.servers, key=self.servers.get)

    def add_connection(self, server):
        self.servers[server] += 1

    def remove_connection(self, server):
        self.servers[server] -= 1
```

#### 4. IP Hash
- **동작**: 클라이언트 IP 해시값으로 서버 결정
- **장점**: 세션 어피니티 보장
- **단점**: 불균등 분배 가능성
```python
import hashlib

class IPHashBalancer:
    def __init__(self, servers):
        self.servers = servers

    def get_server(self, client_ip):
        hash_value = int(hashlib.md5(client_ip.encode()).hexdigest(), 16)
        return self.servers[hash_value % len(self.servers)]
```

#### 5. Least Response Time
- **동작**: 응답시간과 연결 수를 종합 고려
- **장점**: 성능 기반 최적 분배
- **단점**: 복잡한 메트릭 수집 필요

### 고급 로드밸런싱 기법

#### 1. Health Check
```yaml
# HAProxy Health Check 설정
backend web_servers
    balance roundrobin
    option httpchk GET /health
    http-check expect status 200
    server web1 192.168.1.10:80 check inter 5s fall 3 rise 2
    server web2 192.168.1.11:80 check inter 5s fall 3 rise 2
```

#### 2. Session Affinity (Sticky Sessions)
```nginx
# Nginx Session Affinity
upstream backend {
    ip_hash;  # IP 기반 세션 유지
    server server1.example.com;
    server server2.example.com;
}

# 쿠키 기반 세션 유지
map $cookie_jsessionid $backend_pool {
    ~.{32}$ backend_a;
    default backend_b;
}
```

#### 3. Circuit Breaker Pattern
```java
@Component
public class CircuitBreakerLoadBalancer {
    private final Map<String, CircuitBreaker> circuitBreakers = new HashMap<>();

    public String selectServer(List<String> servers) {
        return servers.stream()
            .filter(server -> !circuitBreakers.get(server).isOpen())
            .findFirst()
            .orElse(servers.get(0)); // Fallback
    }

    public void recordSuccess(String server) {
        circuitBreakers.get(server).recordSuccess();
    }

    public void recordFailure(String server) {
        circuitBreakers.get(server).recordFailure();
    }
}
```

### 클라우드 로드밸런서

#### AWS Application Load Balancer (ALB)
```yaml
# ALB Target Group 설정
Resources:
  MyTargetGroup:
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties:
      Port: 80
      Protocol: HTTP
      VpcId: !Ref MyVPC
      HealthCheckPath: /health
      HealthCheckIntervalSeconds: 30
      HealthyThresholdCount: 2
      UnhealthyThresholdCount: 3

  MyLoadBalancer:
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties:
      Type: application
      Scheme: internet-facing
      Subnets:
        - !Ref PublicSubnet1
        - !Ref PublicSubnet2
```

#### Kubernetes Service
```yaml
# Kubernetes LoadBalancer Service
apiVersion: v1
kind: Service
metadata:
  name: my-app-service
spec:
  type: LoadBalancer
  selector:
    app: my-app
  ports:
  - port: 80
    targetPort: 8080
  sessionAffinity: ClientIP  # IP 기반 세션 유지
```

### 성능 최적화

#### 1. Connection Pooling
```nginx
# Nginx Upstream Connection Pooling
upstream backend {
    server backend1.example.com;
    server backend2.example.com;
    keepalive 32;  # 연결 풀 크기
}

server {
    location / {
        proxy_pass http://backend;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
    }
}
```

#### 2. 캐싱 통합
```nginx
# Nginx 캐싱과 로드밸런싱
proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=my_cache:10m;

upstream backend {
    server app1.example.com;
    server app2.example.com;
}

server {
    location / {
        proxy_cache my_cache;
        proxy_cache_valid 200 1h;
        proxy_cache_key "$scheme$request_method$host$request_uri";
        proxy_pass http://backend;
    }
}
```

### 모니터링 및 메트릭

#### 핵심 메트릭
- **처리량**: 초당 요청 수 (RPS)
- **응답시간**: P50, P95, P99 지연시간
- **에러율**: 4xx, 5xx 응답 비율
- **서버 상태**: 활성/비활성 서버 수
- **연결 수**: 동시 연결 및 대기 연결

#### Prometheus 메트릭 수집
```yaml
# Nginx Prometheus Exporter
- job_name: 'nginx'
  static_configs:
  - targets: ['nginx-exporter:9113']

# HAProxy Prometheus Exporter  
- job_name: 'haproxy'
  static_configs:
  - targets: ['haproxy-exporter:8404']
```

### 장애 대응 전략

#### 1. Graceful Degradation
```python
def handle_request(request):
    try:
        # 1차: 주 서버 시도
        return primary_server.process(request)
    except ServerException:
        try:
            # 2차: 백업 서버 시도
            return backup_server.process(request)
        except ServerException:
            # 3차: 캐시된 응답 반환
            return get_cached_response(request)
```

#### 2. Auto Scaling 연동
```yaml
# Kubernetes HPA와 연동
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: my-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

### 베스트 프랙티스
- **헬스체크 구현**: 애플리케이션 상태 정확한 반영
- **점진적 배포**: 트래픽 비율 조절로 위험 최소화
- **모니터링 강화**: 실시간 메트릭 수집 및 알림
- **장애 격리**: Circuit Breaker 패턴 적용
- **캐싱 활용**: 백엔드 부하 감소
- **SSL 최적화**: 로드밸런서에서 SSL 터미네이션
- **지리적 분산**: 글로벌 로드밸런싱 고려

## Redis 캐시

### 핵심 개념
- **In-Memory 데이터 구조 저장소**: 메모리 기반 고성능 키-값 저장소
- **다양한 데이터 타입**: String, Hash, List, Set, Sorted Set, Stream 등
- **영속성 옵션**: RDB 스냅샷, AOF 로그 기반 데이터 보존
- **고가용성**: 마스터-슬레이브 복제, Redis Sentinel, Redis Cluster

### Redis 데이터 구조 및 활용

#### 1. String (문자열)
```redis
# 기본 문자열 연산
SET user:1000:name "John Doe"
GET user:1000:name
INCR user:1000:views
EXPIRE user:1000:session 3600

# 원자적 연산
SET counter 0
INCR counter    # 1
INCRBY counter 5    # 6
DECR counter    # 5
```

#### 2. Hash (해시)
```redis
# 사용자 정보 저장
HSET user:1000 name "John" email "john@example.com" age 30
HGET user:1000 name
HGETALL user:1000
HINCRBY user:1000 age 1

# 애플리케이션 설정
HMSET app:config db_host "localhost" db_port 5432 cache_ttl 300
```

#### 3. List (리스트)
```redis
# 최근 활동 로그 (FIFO 큐)
LPUSH user:1000:activities "login"
LPUSH user:1000:activities "view_profile"
LRANGE user:1000:activities 0 9  # 최근 10개 활동

# 작업 큐 구현
RPUSH job_queue "process_payment:12345"
BLPOP job_queue 0  # 블로킹 팝
```

#### 4. Set (집합)
```redis
# 태그 시스템
SADD article:100:tags "redis" "cache" "performance"
SMEMBERS article:100:tags
SINTER article:100:tags article:101:tags  # 공통 태그

# 온라인 사용자 추적
SADD online_users "user:1000" "user:1001"
SCARD online_users  # 온라인 사용자 수
```

#### 5. Sorted Set (정렬된 집합)
```redis
# 리더보드
ZADD leaderboard 1500 "player1" 1200 "player2" 1800 "player3"
ZREVRANGE leaderboard 0 9 WITHSCORES  # 상위 10명
ZRANK leaderboard "player1"  # 순위 조회

# 시간 기반 데이터
ZADD user:1000:timeline 1640995200 "event1" 1640995260 "event2"
ZRANGEBYSCORE user:1000:timeline 1640995200 1640995300
```

### 캐싱 전략

#### 1. Cache-Aside (Lazy Loading)
```python
def get_user(user_id):
    # 1. 캐시에서 조회
    cached_user = redis.get(f"user:{user_id}")
    if cached_user:
        return json.loads(cached_user)

    # 2. 캐시 미스 시 DB 조회
    user = database.get_user(user_id)
    if user:
        # 3. 캐시에 저장 (TTL 설정)
        redis.setex(f"user:{user_id}", 3600, json.dumps(user))

    return user

def update_user(user_id, user_data):
    # 1. DB 업데이트
    database.update_user(user_id, user_data)

    # 2. 캐시 무효화
    redis.delete(f"user:{user_id}")
```

#### 2. Write-Through
```python
def update_user_write_through(user_id, user_data):
    # 1. DB 업데이트
    database.update_user(user_id, user_data)

    # 2. 캐시 동시 업데이트
    redis.setex(f"user:{user_id}", 3600, json.dumps(user_data))
```

#### 3. Write-Behind (Write-Back)
```python
class WriteBehindCache:
    def __init__(self):
        self.dirty_keys = set()
        self.scheduler = BackgroundScheduler()
        self.scheduler.add_job(self.flush_dirty_data, 'interval', seconds=30)
        self.scheduler.start()

    def update_user(self, user_id, user_data):
        # 1. 캐시만 업데이트
        redis.setex(f"user:{user_id}", 3600, json.dumps(user_data))

        # 2. Dirty 마킹
        self.dirty_keys.add(f"user:{user_id}")

    def flush_dirty_data(self):
        for key in list(self.dirty_keys):
            user_data = redis.get(key)
            if user_data:
                user_id = key.split(':')[1]
                database.update_user(user_id, json.loads(user_data))
                self.dirty_keys.remove(key)
```

### 메모리 관리 및 제거 정책

#### 1. 제거 정책 (Eviction Policies)
```redis
# Redis 설정
maxmemory 2gb
maxmemory-policy allkeys-lru

# 정책 옵션:
# noeviction: 메모리 부족 시 쓰기 거부
# allkeys-lru: 모든 키 중 LRU 제거
# allkeys-lfu: 모든 키 중 LFU 제거
# volatile-lru: TTL 설정된 키 중 LRU 제거
# volatile-lfu: TTL 설정된 키 중 LFU 제거
# volatile-random: TTL 설정된 키 중 랜덤 제거
# volatile-ttl: TTL이 가장 짧은 키 제거
```

#### 2. TTL 관리
```python
# 동적 TTL 설정
def cache_with_adaptive_ttl(key, data, base_ttl=3600):
    access_count = redis.get(f"{key}:access_count") or 0

    # 접근 빈도에 따른 TTL 조정
    if access_count > 100:
        ttl = base_ttl * 2  # 자주 사용되는 데이터는 더 오래 보관
    elif access_count < 10:
        ttl = base_ttl // 2  # 적게 사용되는 데이터는 빨리 제거
    else:
        ttl = base_ttl

    redis.setex(key, ttl, json.dumps(data))
    redis.incr(f"{key}:access_count")
```

### 성능 최적화

#### 1. KEYS vs SCAN 명령어
```python
# 위험한 방법 - 프로덕션에서 사용 금지
def get_user_keys_dangerous():
    return redis.keys("user:*")  # 블로킹, 성능 저하

# 안전한 방법 - SCAN 사용
def get_user_keys_safe():
    keys = []
    cursor = 0
    while True:
        cursor, partial_keys = redis.scan(cursor, match="user:*", count=100)
        keys.extend(partial_keys)
        if cursor == 0:
            break
    return keys
```

#### 2. 파이프라이닝
```python
# 개별 명령어 (비효율적)
def update_multiple_counters_slow(counters):
    for counter_name, value in counters.items():
        redis.incr(counter_name, value)

# 파이프라이닝 (효율적)
def update_multiple_counters_fast(counters):
    pipe = redis.pipeline()
    for counter_name, value in counters.items():
        pipe.incr(counter_name, value)
    pipe.execute()
```

#### 3. 연결 풀링
```python
import redis

# 연결 풀 설정
pool = redis.ConnectionPool(
    host='localhost',
    port=6379,
    db=0,
    max_connections=20,
    socket_connect_timeout=5,
    socket_timeout=5,
    retry_on_timeout=True
)

redis_client = redis.Redis(connection_pool=pool)
```

### Redis 6+ 멀티스레드

#### 설정 및 고려사항
```redis
# Redis 6.0+ 멀티스레드 I/O 설정
io-threads 4
io-threads-do-reads yes

# 주의사항:
# - 메인 스레드는 여전히 단일 스레드
# - I/O 작업만 멀티스레드로 처리
# - CPU 코어 수보다 적게 설정 권장
```

### 고가용성 구성

#### 1. 마스터-슬레이브 복제
```redis
# 슬레이브 설정
replicaof 192.168.1.100 6379
replica-read-only yes
replica-serve-stale-data yes
```

#### 2. Redis Sentinel
```python
from redis.sentinel import Sentinel

sentinel = Sentinel([
    ('sentinel1', 26379),
    ('sentinel2', 26379),
    ('sentinel3', 26379)
])

# 마스터 연결
master = sentinel.master_for('mymaster', socket_timeout=0.1)
master.set('key', 'value')

# 슬레이브 연결 (읽기 전용)
slave = sentinel.slave_for('mymaster', socket_timeout=0.1)
value = slave.get('key')
```

#### 3. Redis Cluster
```python
from rediscluster import RedisCluster

startup_nodes = [
    {"host": "127.0.0.1", "port": "7000"},
    {"host": "127.0.0.1", "port": "7001"},
    {"host": "127.0.0.1", "port": "7002"}
]

cluster = RedisCluster(startup_nodes=startup_nodes, decode_responses=True)
cluster.set("key", "value")
```

### 모니터링 및 운영

#### 1. 핵심 메트릭
```redis
# Redis 정보 조회
INFO memory
INFO stats
INFO replication
INFO persistence

# 주요 메트릭:
# - used_memory: 사용 중인 메모리
# - keyspace_hits/keyspace_misses: 캐시 히트율
# - connected_clients: 연결된 클라이언트 수
# - ops_per_sec: 초당 연산 수
```

#### 2. 슬로우 로그 모니터링
```redis
# 슬로우 로그 설정
CONFIG SET slowlog-log-slower-than 10000  # 10ms 이상
CONFIG SET slowlog-max-len 128

# 슬로우 로그 조회
SLOWLOG GET 10
```

#### 3. 메모리 분석
```python
def analyze_redis_memory():
    info = redis.info('memory')

    print(f"Used Memory: {info['used_memory_human']}")
    print(f"Peak Memory: {info['used_memory_peak_human']}")
    print(f"Memory Fragmentation Ratio: {info['mem_fragmentation_ratio']}")

    # 키 공간 분석
    for db_name, db_info in redis.info('keyspace').items():
        print(f"{db_name}: {db_info}")
```

### 캐시 무효화 전략

#### 1. 태그 기반 무효화
```python
class TaggedCache:
    def set_with_tags(self, key, value, tags, ttl=3600):
        # 데이터 저장
        redis.setex(key, ttl, json.dumps(value))

        # 태그별 키 목록 관리
        for tag in tags:
            redis.sadd(f"tag:{tag}", key)
            redis.expire(f"tag:{tag}", ttl + 60)  # 태그는 조금 더 오래 보관

    def invalidate_by_tag(self, tag):
        # 태그에 속한 모든 키 조회
        keys = redis.smembers(f"tag:{tag}")

        # 키들 삭제
        if keys:
            redis.delete(*keys)

        # 태그 자체도 삭제
        redis.delete(f"tag:{tag}")

# 사용 예시
cache = TaggedCache()
cache.set_with_tags("user:1000", user_data, ["user", "profile"], 3600)
cache.invalidate_by_tag("user")  # 모든 사용자 캐시 무효화
```

#### 2. 버전 기반 무효화
```python
def versioned_cache_set(key, value, ttl=3600):
    version = redis.incr("cache_version")
    versioned_key = f"{key}:v{version}"
    redis.setex(versioned_key, ttl, json.dumps(value))
    redis.set(f"{key}:current_version", version)

def versioned_cache_get(key):
    current_version = redis.get(f"{key}:current_version")
    if current_version:
        versioned_key = f"{key}:v{current_version}"
        return redis.get(versioned_key)
    return None
```

### 베스트 프랙티스
- **적절한 데이터 구조 선택**: 용도에 맞는 Redis 데이터 타입 사용
- **TTL 설정**: 모든 캐시 키에 적절한 만료시간 설정
- **메모리 모니터링**: 메모리 사용량과 조각화 비율 지속 관찰
- **연결 풀 사용**: 연결 오버헤드 최소화
- **파이프라이닝 활용**: 다중 명령어 배치 처리
- **슬로우 로그 분석**: 성능 병목 지점 식별
- **적절한 제거 정책**: 애플리케이션 특성에 맞는 eviction policy 선택
- **고가용성 구성**: 프로덕션 환경에서 복제 및 센티넬 구성
- **보안 설정**: AUTH, 네트워크 격리, SSL/TLS 적용

## Kafka
- **Offset**: 파티션 내 메시지 인덱스, 순서 보장
- **ISR (In-Sync Replica)**
    - 리더와 동기화된 팔로워 집합
    - ISR 탈락 시 가용성 저하 주의
- **Auto Commit**
    - `enable.auto.commit=true`: 메시지 처리 여부와 무관하게 주기적 커밋 → 데이터 손실 위험
    - `false`: 수동 커밋 → 처리 보장성↑, 구현 복잡도↑
- **순서 보장**
    - 단일 파티션 + 단일 컨슈머 그룹
    - 키 기반 파티셔닝: 동일 키 메시지 같은 파티션 할당
- **Acks 옵션**
    - `0`: 비동기, 빠르나 손실 위험
    - `1`: 리더만 ACK, 복제본 손실 가능
    - `all`(-1): ISR 전체 ACK, 가장 안전
- **멱등성 프로듀서 (Idempotent Producer)**
    - **설정**: `enable.idempotence=true`
    - **핵심 메커니즘**
        - **PID (Producer ID)**: 프로듀서별 고유 식별자
        - **Sequence Number**: 메시지별 순차 번호
        - **중복 감지**: 브로커가 PID + Sequence 조합으로 중복 메시지 식별
    - **동작 원리**
        - 프로듀서가 메시지 전송 시 PID + Sequence 번호 포함
        - 브로커가 이미 처리된 Sequence 번호 확인 → 중복 시 무시
        - 네트워크 재전송, 프로듀서 재시도 시에도 정확히 한 번만 처리
    - **제약사항**
        - `max.in.flight.requests.per.connection ≤ 5`
        - `retries > 0` (기본값 Integer.MAX_VALUE)
        - `acks = all` (모든 ISR 확인 필요)
    - **장점**: Exactly-once 전송 보장, 중복 메시지 방지
    - **단점**: 약간의 성능 오버헤드, 설정 제약


---

## 용어 정리: "시분할 데이터"?

- 결론: "시분할 데이터"라는 표현은 널리 통용되는 표준 용어가 아닙니다. 문맥에 따라 다음 두 가지 중 하나를 의미하는 경우가 많습니다.
  1) 시분할(Time Sharing): 운영체제 스케줄링 기법으로, CPU 시간을 작은 타임 슬라이스로 나누어 여러 프로세스/스레드가 번갈아 실행되도록 하는 것. 관련: [프로세스와 스레드의 컨텍스트 스위칭](../CS/OperatingSystems/process_thread_context_switching.md)
  2) 시계열 데이터(Time-Series Data): 시간(타임스탬프)을 기준 인덱스로 갖는 데이터. 예: CPU 사용률, 요청 QPS, 주가, 센서값, 로그 카운트 등.

- 시계열 데이터 핵심 개념
  - 시간 인덱스(규칙/비규칙 간격), 추세/계절성/이상치 분석
  - 대표 저장소/도구: TSDB(Prometheus, InfluxDB 등), 시각화(Grafana)
  - 전형적 연산: 다운샘플링, 윈도우 집계, 롤링 평균, 예측(ARIMA, Prophet 등)

- 요약 비교
  - 시분할: 운영체제의 CPU 스케줄링 개념(프로세스/스레드 실행 방식)
  - 시계열 데이터: 데이터 모델/저장/분석의 대상(시간에 따른 값들의 집합)
